{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Practice on Keras Functional API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db106a0ce89886c6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:39:26.294252600Z",
     "start_time": "2023-08-15T22:39:22.564254300Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# for types hints\n",
    "from typing import Tuple, Callable, List\n",
    "from tensorflow import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# mnist dataset\n",
    "def load_and_preprocess_mnist() -> Tuple[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor]]:\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset, preprocess images, and perform one-hot encoding of labels.\n",
    "\n",
    "    :return: Tuple of training data (x_train, y_train) and testing data (x_test, y_test).\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) =  keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Reshape and normalize images\n",
    "    x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "    x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "    # One-hot encoding of labels\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:39:26.310252900Z",
     "start_time": "2023-08-15T22:39:26.298253Z"
    }
   },
   "id": "235572d8aa183bc7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:39:26.666252800Z",
     "start_time": "2023-08-15T22:39:26.312752900Z"
    }
   },
   "id": "42ff4c5d4d8c22ec"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# building the model\n",
    "def build_model() -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build a simple MLP model for MNIST classification.\n",
    "    :return: A Keras Model with inputs and outputs defined.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(784,), name='input')  # input layer\n",
    "    x = layers.Dense(64, activation='relu', name='hidden1')(inputs)  # hidden layer\n",
    "    x = layers.Dense(64, activation='relu', name='hidden2')(x)  # hidden layer\n",
    "    outputs = layers.Dense(10, activation='softmax', name='output')(x)  # output layer\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:39:26.867752600Z",
     "start_time": "2023-08-15T22:39:26.670753400Z"
    }
   },
   "id": "5a49bafd834711d3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 1.1003 - categorical_accuracy: 0.7094 - val_loss: 0.5039 - val_categorical_accuracy: 0.8724\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.4460 - categorical_accuracy: 0.8769 - val_loss: 0.3618 - val_categorical_accuracy: 0.8986\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3588 - categorical_accuracy: 0.8980 - val_loss: 0.3167 - val_categorical_accuracy: 0.9090\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.3200 - categorical_accuracy: 0.9081 - val_loss: 0.2891 - val_categorical_accuracy: 0.9166\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2933 - categorical_accuracy: 0.9159 - val_loss: 0.2716 - val_categorical_accuracy: 0.9217\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2727 - categorical_accuracy: 0.9221 - val_loss: 0.2522 - val_categorical_accuracy: 0.9277\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2554 - categorical_accuracy: 0.9264 - val_loss: 0.2389 - val_categorical_accuracy: 0.9324\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2409 - categorical_accuracy: 0.9310 - val_loss: 0.2291 - val_categorical_accuracy: 0.9351\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2277 - categorical_accuracy: 0.9350 - val_loss: 0.2201 - val_categorical_accuracy: 0.9367\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.2161 - categorical_accuracy: 0.9373 - val_loss: 0.2102 - val_categorical_accuracy: 0.9410\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.2064 - categorical_accuracy: 0.9403 - val_loss: 0.2039 - val_categorical_accuracy: 0.9428\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1967 - categorical_accuracy: 0.9434 - val_loss: 0.1965 - val_categorical_accuracy: 0.9447\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.1883 - categorical_accuracy: 0.9460 - val_loss: 0.1910 - val_categorical_accuracy: 0.9482\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1806 - categorical_accuracy: 0.9477 - val_loss: 0.1858 - val_categorical_accuracy: 0.9481\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.1735 - categorical_accuracy: 0.9500 - val_loss: 0.1793 - val_categorical_accuracy: 0.9512\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1667 - categorical_accuracy: 0.9518 - val_loss: 0.1751 - val_categorical_accuracy: 0.9508\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1608 - categorical_accuracy: 0.9535 - val_loss: 0.1740 - val_categorical_accuracy: 0.9507\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.1551 - categorical_accuracy: 0.9552 - val_loss: 0.1664 - val_categorical_accuracy: 0.9528\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1501 - categorical_accuracy: 0.9564 - val_loss: 0.1634 - val_categorical_accuracy: 0.9537\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.1452 - categorical_accuracy: 0.9582 - val_loss: 0.1579 - val_categorical_accuracy: 0.9555\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.1405 - categorical_accuracy: 0.9592 - val_loss: 0.1569 - val_categorical_accuracy: 0.9567\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1363 - categorical_accuracy: 0.9607 - val_loss: 0.1521 - val_categorical_accuracy: 0.9568\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.1321 - categorical_accuracy: 0.9620 - val_loss: 0.1504 - val_categorical_accuracy: 0.9573\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.1283 - categorical_accuracy: 0.9624 - val_loss: 0.1483 - val_categorical_accuracy: 0.9597\n",
      "Epoch 25/100\n",
      "510/750 [===================>..........] - ETA: 0s - loss: 0.1214 - categorical_accuracy: 0.9649"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# training the model\u001B[39;00m\n\u001B[0;32m      7\u001B[0m early_stopping_callback \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 8\u001B[0m \u001B[43mmodel_ce\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# evaluating the model\u001B[39;00m\n\u001B[0;32m     10\u001B[0m test_scores \u001B[38;5;241m=\u001B[39m model_ce\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1740\u001B[0m ):\n\u001B[0;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    146\u001B[0m   (concrete_function,\n\u001B[0;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs)\u001B[0m\n\u001B[0;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1351\u001B[0m     args,\n\u001B[0;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1353\u001B[0m     executing_eagerly)\n\u001B[0;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1472\u001B[0m   )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\keras-api\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD()\n",
    "ce_loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = [keras.metrics.CategoricalAccuracy()]\n",
    "# compiling the model\n",
    "model_ce.compile(optimizer=optimizer, loss=ce_loss, metrics=metrics)\n",
    "# training the model\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_ce.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_ce.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "\n",
    "# saving the model\n",
    "path = './weights/mnist_ce_model.keras'\n",
    "model_ce.save(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:40:38.030253700Z",
     "start_time": "2023-08-15T22:39:26.873754200Z"
    }
   },
   "id": "74658d8b5c82aac1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "focal_loss = keras.losses.CategoricalFocalCrossentropy()\n",
    "# compiling the model\n",
    "optimizer = keras.optimizers.SGD()\n",
    "model_fl.compile(optimizer=optimizer, loss=focal_loss, metrics=metrics)\n",
    "# training the model\n",
    "model_fl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_fl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_focal_model.keras'\n",
    "model_fl.save(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.030253700Z"
    }
   },
   "id": "ff849813ffddfd76"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# defining rational loss function\n",
    "# RL(p_t) = 1/p_t * -p * log(p_t)\n",
    "    # TODO: plot the function\n",
    "def rational_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Rational Loss for multi-class classification, Keras style.\n",
    "    RL(p_t) = - 1/p_t * log(p_t), where p_t is the probability associated with the true class.\n",
    "\n",
    "    :param y_true: Ground truth labels, shape of [batch_size, num_classes].\n",
    "    :param y_pred: Predicted class probabilities, shape of [batch_size, num_classes].\n",
    "    :return: A scalar representing the mean rational loss over the batch.\n",
    "    NOTE: written assuming GPU support to make use of fast Tensor operations.\n",
    "    \"\"\"\n",
    "    # Create a Categorical Cross-Entropy loss instance\n",
    "    cce = keras.losses.CategoricalCrossentropy(\n",
    "        reduction=keras.losses.Reduction.NONE # Keep unreduced loss tensor\n",
    "    )\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    _y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    cross_entropy = cce(y_true, _y_pred) # batch_sizex1\n",
    "    # get y_pred for the true class\n",
    "    _y_pred = K.sum(y_true * _y_pred, axis=1) # batch_sizex1\n",
    "    _y_pred = K.clip(_y_pred, K.epsilon(), None) # Avoid division by zero\n",
    "    _rational_loss = cross_entropy / _y_pred # Rational loss  \n",
    "    \n",
    "    return _rational_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:45:53.690747900Z",
     "start_time": "2023-08-15T22:45:53.666249200Z"
    }
   },
   "id": "eb292d1ae3a65bc1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.036255300Z"
    }
   },
   "id": "3c4b133c43013fc9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0.05399305 23.02585093], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test rational loss\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]])\n",
    "y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "print(rational_loss(y_true, y_pred))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:45:56.281011700Z",
     "start_time": "2023-08-15T22:45:56.225014100Z"
    }
   },
   "id": "d2bb936ed83a8b25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def generate_data() -> Tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Generates synthetic y_true and y_pred data.\n",
    "#     :return: y_true and y_pred arrays.\n",
    "#     \"\"\"\n",
    "#     num_samples = 100\n",
    "#     num_classes = 3\n",
    "#     y_true = np.eye(num_classes)[np.random.choice(num_classes, num_samples)]\n",
    "#     y_pred = np.random.rand(num_samples, num_classes)\n",
    "#     y_pred /= y_pred.sum(axis=1, keepdims=True)\n",
    "#     return y_true, y_pred\n",
    "# \n",
    "# def plot_rational_loss() -> None:\n",
    "#     \"\"\"\n",
    "#     Plots the rational loss for the generated data.\n",
    "#     \"\"\"\n",
    "#     y_true, y_pred = generate_data()\n",
    "#     rational_loss_fixed = rational_loss()\n",
    "#     losses: List[float] = [rational_loss_fixed(y_t.reshape(1, -1), y_p.reshape(1, -1)).numpy() for y_t, y_p in zip(y_true, y_pred)]\n",
    "#     plt.plot(losses)\n",
    "#     plt.title(\"Rational Loss for Multi-Class Classification\")\n",
    "#     plt.xlabel(\"Sample\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.show()\n",
    "# \n",
    "# plot_rational_loss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.040754300Z"
    }
   },
   "id": "331edee2580725fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_rl.compile(optimizer= keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)\n",
    "# training the model\n",
    "history = model_rl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2)\n",
    "# evaluating the model\n",
    "test_scores = model_rl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_rational_model.keras'\n",
    "model_rl.save(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:47:55.585313300Z"
    }
   },
   "id": "25ab1b90eb796366"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# rebuilding the models\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.044751300Z"
    }
   },
   "id": "3b0b6284c01bdf98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# imbalance \n",
    "def create_imbalanced_data(x, y, imbalance_rate=0.5):\n",
    "    \"\"\"\n",
    "    Create an imbalanced dataset based on a given probability distribution.\n",
    "    The probability for class d is given by: P(d) = 0.5^d / 2*(1 - 0.5^10)\n",
    "\n",
    "    :param x: Features, shape of [total_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [total_samples, num_classes].\n",
    "    :param imbalance_rate: Base rate for the exponential decay of class frequency (default 0.5).\n",
    "    :return: Tuple of imbalanced features and labels, shapes of [selected_samples, feature_dim] and [selected_samples, num_classes].\n",
    "    \"\"\"\n",
    "    total_samples = len(y)\n",
    "    a = imbalance_rate\n",
    "    normalization_factor = 2 * (1 - a**10)\n",
    "\n",
    "    indices_by_class = [np.where(y[:, d] == 1)[0] for d in range(10)]\n",
    "    selected_indices = []\n",
    "\n",
    "    for d in range(10):\n",
    "        probability_d = (a**d) / normalization_factor\n",
    "        frequency = int(total_samples * probability_d)\n",
    "        np.random.shuffle(indices_by_class[d]) # Shuffle to ensure random selection\n",
    "        selected_indices.extend(indices_by_class[d][:frequency])\n",
    "\n",
    "    return x[selected_indices], y[selected_indices]\n",
    "\n",
    "\n",
    "x_train_imbalanced, y_train_imbalanced = create_imbalanced_data(x_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T22:40:38.086251Z",
     "start_time": "2023-08-15T22:40:38.046750600Z"
    }
   },
   "id": "674c73a18c8f5973"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_ce.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "model_fl.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.CategoricalFocalCrossentropy(), metrics=metrics)\n",
    "model_rl.compile(optimizer=keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.048751600Z"
    }
   },
   "id": "16d76b12905e4aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training on imbalanced data:\")\n",
    "print(\"Cross Entropy:\")\n",
    "model_ce.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Focal Loss:\")\n",
    "model_fl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Rational Loss:\")\n",
    "model_rl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.051250400Z"
    }
   },
   "id": "bdefdf376d35ec93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Balanced data\n",
    "print(model_ce.evaluate(x_test, y_test))\n",
    "print(model_fl.evaluate(x_test, y_test))\n",
    "print(model_rl.evaluate(x_test, y_test))\n",
    "\n",
    "# Imbalanced data\n",
    "x_test_imbalanced, y_test_imbalanced = create_imbalanced_data(x_test, y_test)\n",
    "print(model_ce.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_fl.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_rl.evaluate(x_test_imbalanced, y_test_imbalanced))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.052752500Z"
    }
   },
   "id": "c7d9401ce9ef65d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy_by_bins(model, x, y):\n",
    "    \"\"\"\n",
    "    Calculate and print the accuracy of the given model for specific bins of classes.\n",
    "    The bins are defined as: 0-1, 2-7, 8-9.\n",
    "\n",
    "    :param model: Trained Keras model to evaluate.\n",
    "    :param x: Input features, shape of [num_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [num_samples, num_classes].\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x).argmax(axis=-1)\n",
    "    true_labels = y.argmax(axis=-1)\n",
    "    bins = [(0, 1), (2, 7), (8, 9)]\n",
    "    for bin_start, bin_end in bins:\n",
    "        mask = (true_labels >= bin_start) & (true_labels <= bin_end) \n",
    "        bin_accuracy = np.mean(predictions[mask] == true_labels[mask])\n",
    "        print(f\"Accuracy for bin {bin_start}-{bin_end}: {bin_accuracy}\")\n",
    "\n",
    "print(\"Accuracy by bins for balanced data:\")\n",
    "print(\"Cross Entropy:\")\n",
    "accuracy_by_bins(model_ce, x_test, y_test)\n",
    "print(\"Focal Loss:\")\n",
    "accuracy_by_bins(model_fl, x_test, y_test)\n",
    "print(\"Rational Loss:\")\n",
    "accuracy_by_bins(model_rl, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.055252300Z"
    }
   },
   "id": "143062bb0fb2c0d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
