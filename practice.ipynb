{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db106a0ce89886c6",
   "metadata": {},
   "source": [
    "# Practice on Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2390991af87b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:42:28.287786900Z",
     "start_time": "2023-08-16T04:42:26.318800300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:42:26.683365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 00:42:27.395433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# for types hints\n",
    "from typing import Tuple, Callable, List\n",
    "from tensorflow import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0566659f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:42:31.506281200Z",
     "start_time": "2023-08-16T04:42:31.256289100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:42:31.476160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:42:31.492992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:31.493224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# check for gpus\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# list their names\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235572d8aa183bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:42:41.316163200Z",
     "start_time": "2023-08-16T04:42:41.308670900Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist dataset\n",
    "def load_and_preprocess_mnist() -> Tuple[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor]]:\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset, preprocess images, and perform one-hot encoding of labels.\n",
    "\n",
    "    :return: Tuple of training data (x_train, y_train) and testing data (x_test, y_test).\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) =  tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Reshape and normalize images\n",
    "    x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "    x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "    # One-hot encoding of labels\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ff4c5d4d8c22ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:42:44.409663500Z",
     "start_time": "2023-08-16T04:42:44.142164300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a49bafd834711d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:42:48.358164800Z",
     "start_time": "2023-08-16T04:42:46.119670200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:42:46.131291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:46.131573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:46.131822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:47.814361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:47.816339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:47.816379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-16 00:42:47.816703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 00:42:47.816753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "def build_model() -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Build a simple MLP model for MNIST classification.\n",
    "    :return: A tf.keras Model with inputs and outputs defined.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(784,), name='input')  # input layer\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='hidden1')(inputs)  # hidden layer\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='hidden2')(x)  # hidden layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', name='output')(x)  # output layer\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74658d8b5c82aac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:47:56.130797Z",
     "start_time": "2023-08-16T04:42:53.568806800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:42:56.228247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-16 00:42:56.232728: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f178f761dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-16 00:42:56.232785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-16 00:42:56.447425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-16 00:42:56.455350: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:543] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-08-16 00:42:56.530051: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 8s 7ms/step - loss: 1.1254 - categorical_accuracy: 0.6955 - val_loss: 0.4941 - val_categorical_accuracy: 0.8720\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.4401 - categorical_accuracy: 0.8780 - val_loss: 0.3533 - val_categorical_accuracy: 0.8997\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.3522 - categorical_accuracy: 0.9000 - val_loss: 0.3081 - val_categorical_accuracy: 0.9103\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.3128 - categorical_accuracy: 0.9096 - val_loss: 0.2816 - val_categorical_accuracy: 0.9174\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2870 - categorical_accuracy: 0.9173 - val_loss: 0.2614 - val_categorical_accuracy: 0.9250\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2675 - categorical_accuracy: 0.9219 - val_loss: 0.2490 - val_categorical_accuracy: 0.9269\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2513 - categorical_accuracy: 0.9271 - val_loss: 0.2342 - val_categorical_accuracy: 0.9326\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.2373 - categorical_accuracy: 0.9315 - val_loss: 0.2232 - val_categorical_accuracy: 0.9355\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.2245 - categorical_accuracy: 0.9353 - val_loss: 0.2160 - val_categorical_accuracy: 0.9377\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2136 - categorical_accuracy: 0.9383 - val_loss: 0.2047 - val_categorical_accuracy: 0.9412\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.2033 - categorical_accuracy: 0.9413 - val_loss: 0.1982 - val_categorical_accuracy: 0.9438\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1941 - categorical_accuracy: 0.9446 - val_loss: 0.1902 - val_categorical_accuracy: 0.9479\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1855 - categorical_accuracy: 0.9465 - val_loss: 0.1826 - val_categorical_accuracy: 0.9488\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1779 - categorical_accuracy: 0.9489 - val_loss: 0.1781 - val_categorical_accuracy: 0.9498\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1709 - categorical_accuracy: 0.9509 - val_loss: 0.1726 - val_categorical_accuracy: 0.9523\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1641 - categorical_accuracy: 0.9528 - val_loss: 0.1716 - val_categorical_accuracy: 0.9492\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1582 - categorical_accuracy: 0.9545 - val_loss: 0.1635 - val_categorical_accuracy: 0.9541\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1525 - categorical_accuracy: 0.9557 - val_loss: 0.1624 - val_categorical_accuracy: 0.9536\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1470 - categorical_accuracy: 0.9580 - val_loss: 0.1588 - val_categorical_accuracy: 0.9562\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1419 - categorical_accuracy: 0.9592 - val_loss: 0.1545 - val_categorical_accuracy: 0.9565\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.1374 - categorical_accuracy: 0.9604 - val_loss: 0.1493 - val_categorical_accuracy: 0.9590\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1326 - categorical_accuracy: 0.9626 - val_loss: 0.1483 - val_categorical_accuracy: 0.9578\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1283 - categorical_accuracy: 0.9634 - val_loss: 0.1429 - val_categorical_accuracy: 0.9601\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1246 - categorical_accuracy: 0.9643 - val_loss: 0.1398 - val_categorical_accuracy: 0.9613\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1206 - categorical_accuracy: 0.9661 - val_loss: 0.1379 - val_categorical_accuracy: 0.9607\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.1171 - categorical_accuracy: 0.9665 - val_loss: 0.1365 - val_categorical_accuracy: 0.9613\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1132 - categorical_accuracy: 0.9676 - val_loss: 0.1328 - val_categorical_accuracy: 0.9627\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.1103 - categorical_accuracy: 0.9685 - val_loss: 0.1317 - val_categorical_accuracy: 0.9628\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1071 - categorical_accuracy: 0.9697 - val_loss: 0.1297 - val_categorical_accuracy: 0.9629\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1041 - categorical_accuracy: 0.9704 - val_loss: 0.1327 - val_categorical_accuracy: 0.9636\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1013 - categorical_accuracy: 0.9708 - val_loss: 0.1268 - val_categorical_accuracy: 0.9632\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0985 - categorical_accuracy: 0.9721 - val_loss: 0.1252 - val_categorical_accuracy: 0.9653\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0955 - categorical_accuracy: 0.9736 - val_loss: 0.1240 - val_categorical_accuracy: 0.9643\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0937 - categorical_accuracy: 0.9728 - val_loss: 0.1213 - val_categorical_accuracy: 0.9644\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0906 - categorical_accuracy: 0.9745 - val_loss: 0.1199 - val_categorical_accuracy: 0.9653\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0887 - categorical_accuracy: 0.9745 - val_loss: 0.1180 - val_categorical_accuracy: 0.9660\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0864 - categorical_accuracy: 0.9754 - val_loss: 0.1185 - val_categorical_accuracy: 0.9658\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0841 - categorical_accuracy: 0.9758 - val_loss: 0.1173 - val_categorical_accuracy: 0.9657\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0821 - categorical_accuracy: 0.9767 - val_loss: 0.1157 - val_categorical_accuracy: 0.9666\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0801 - categorical_accuracy: 0.9776 - val_loss: 0.1142 - val_categorical_accuracy: 0.9662\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0782 - categorical_accuracy: 0.9782 - val_loss: 0.1138 - val_categorical_accuracy: 0.9659\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0763 - categorical_accuracy: 0.9785 - val_loss: 0.1112 - val_categorical_accuracy: 0.9668\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0749 - categorical_accuracy: 0.9793 - val_loss: 0.1140 - val_categorical_accuracy: 0.9662\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0733 - categorical_accuracy: 0.9794 - val_loss: 0.1132 - val_categorical_accuracy: 0.9663\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0716 - categorical_accuracy: 0.9796 - val_loss: 0.1093 - val_categorical_accuracy: 0.9676\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0698 - categorical_accuracy: 0.9803 - val_loss: 0.1098 - val_categorical_accuracy: 0.9672\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0684 - categorical_accuracy: 0.9804 - val_loss: 0.1111 - val_categorical_accuracy: 0.9670\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0669 - categorical_accuracy: 0.9814 - val_loss: 0.1086 - val_categorical_accuracy: 0.9671\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0655 - categorical_accuracy: 0.9815 - val_loss: 0.1077 - val_categorical_accuracy: 0.9680\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0641 - categorical_accuracy: 0.9824 - val_loss: 0.1075 - val_categorical_accuracy: 0.9693\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0628 - categorical_accuracy: 0.9829 - val_loss: 0.1072 - val_categorical_accuracy: 0.9672\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0615 - categorical_accuracy: 0.9827 - val_loss: 0.1062 - val_categorical_accuracy: 0.9687\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0601 - categorical_accuracy: 0.9834 - val_loss: 0.1052 - val_categorical_accuracy: 0.9681\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0590 - categorical_accuracy: 0.9836 - val_loss: 0.1058 - val_categorical_accuracy: 0.9686\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0577 - categorical_accuracy: 0.9843 - val_loss: 0.1058 - val_categorical_accuracy: 0.9688\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0566 - categorical_accuracy: 0.9846 - val_loss: 0.1051 - val_categorical_accuracy: 0.9688\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0556 - categorical_accuracy: 0.9850 - val_loss: 0.1043 - val_categorical_accuracy: 0.9688\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0545 - categorical_accuracy: 0.9850 - val_loss: 0.1067 - val_categorical_accuracy: 0.9684\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0534 - categorical_accuracy: 0.9852 - val_loss: 0.1036 - val_categorical_accuracy: 0.9685\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0523 - categorical_accuracy: 0.9857 - val_loss: 0.1033 - val_categorical_accuracy: 0.9682\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0513 - categorical_accuracy: 0.9863 - val_loss: 0.1032 - val_categorical_accuracy: 0.9697\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0504 - categorical_accuracy: 0.9860 - val_loss: 0.1028 - val_categorical_accuracy: 0.9685\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0493 - categorical_accuracy: 0.9863 - val_loss: 0.1026 - val_categorical_accuracy: 0.9699\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0483 - categorical_accuracy: 0.9869 - val_loss: 0.1026 - val_categorical_accuracy: 0.9687\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0477 - categorical_accuracy: 0.9874 - val_loss: 0.1032 - val_categorical_accuracy: 0.9691\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0465 - categorical_accuracy: 0.9876 - val_loss: 0.1040 - val_categorical_accuracy: 0.9684\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0459 - categorical_accuracy: 0.9879 - val_loss: 0.1027 - val_categorical_accuracy: 0.9682\n",
      "313/313 - 1s - loss: 0.0945 - categorical_accuracy: 0.9722 - 1s/epoch - 5ms/step\n",
      "Test loss: 0.09449376910924911\n",
      "Test accuracy: 0.9721999764442444\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD()\n",
    "ce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "# compiling the model\n",
    "model_ce.compile(optimizer=optimizer, loss=ce_loss, metrics=metrics)\n",
    "# training the model\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_ce.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_ce.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "\n",
    "# saving the model\n",
    "path = './weights/mnist_ce_model.keras'\n",
    "model_ce.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff849813ffddfd76",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-16T04:48:28.719992500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0699 - categorical_accuracy: 0.8563 - val_loss: 0.0605 - val_categorical_accuracy: 0.8785\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0622 - categorical_accuracy: 0.8717 - val_loss: 0.0549 - val_categorical_accuracy: 0.8895\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0570 - categorical_accuracy: 0.8809 - val_loss: 0.0511 - val_categorical_accuracy: 0.8944\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0532 - categorical_accuracy: 0.8868 - val_loss: 0.0483 - val_categorical_accuracy: 0.8983\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0503 - categorical_accuracy: 0.8915 - val_loss: 0.0461 - val_categorical_accuracy: 0.9022\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0480 - categorical_accuracy: 0.8959 - val_loss: 0.0443 - val_categorical_accuracy: 0.9045\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0461 - categorical_accuracy: 0.8999 - val_loss: 0.0427 - val_categorical_accuracy: 0.9070\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0444 - categorical_accuracy: 0.9025 - val_loss: 0.0415 - val_categorical_accuracy: 0.9094\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0430 - categorical_accuracy: 0.9046 - val_loss: 0.0403 - val_categorical_accuracy: 0.9115\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0418 - categorical_accuracy: 0.9073 - val_loss: 0.0393 - val_categorical_accuracy: 0.9147\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0407 - categorical_accuracy: 0.9089 - val_loss: 0.0386 - val_categorical_accuracy: 0.9155\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0397 - categorical_accuracy: 0.9111 - val_loss: 0.0377 - val_categorical_accuracy: 0.9180\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0388 - categorical_accuracy: 0.9131 - val_loss: 0.0369 - val_categorical_accuracy: 0.9176\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0379 - categorical_accuracy: 0.9144 - val_loss: 0.0364 - val_categorical_accuracy: 0.9188\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0372 - categorical_accuracy: 0.9162 - val_loss: 0.0356 - val_categorical_accuracy: 0.9210\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0364 - categorical_accuracy: 0.9184 - val_loss: 0.0350 - val_categorical_accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0358 - categorical_accuracy: 0.9191 - val_loss: 0.0344 - val_categorical_accuracy: 0.9219\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0351 - categorical_accuracy: 0.9206 - val_loss: 0.0340 - val_categorical_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0345 - categorical_accuracy: 0.9213 - val_loss: 0.0335 - val_categorical_accuracy: 0.9236\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0340 - categorical_accuracy: 0.9229 - val_loss: 0.0331 - val_categorical_accuracy: 0.9252\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0334 - categorical_accuracy: 0.9241 - val_loss: 0.0326 - val_categorical_accuracy: 0.9252\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0329 - categorical_accuracy: 0.9250 - val_loss: 0.0321 - val_categorical_accuracy: 0.9278\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0323 - categorical_accuracy: 0.9265 - val_loss: 0.0317 - val_categorical_accuracy: 0.9287\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0319 - categorical_accuracy: 0.9271 - val_loss: 0.0312 - val_categorical_accuracy: 0.9293\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0314 - categorical_accuracy: 0.9283 - val_loss: 0.0309 - val_categorical_accuracy: 0.9309\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0309 - categorical_accuracy: 0.9290 - val_loss: 0.0306 - val_categorical_accuracy: 0.9312\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0305 - categorical_accuracy: 0.9295 - val_loss: 0.0301 - val_categorical_accuracy: 0.9328\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0301 - categorical_accuracy: 0.9306 - val_loss: 0.0298 - val_categorical_accuracy: 0.9330\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0296 - categorical_accuracy: 0.9310 - val_loss: 0.0295 - val_categorical_accuracy: 0.9348\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0292 - categorical_accuracy: 0.9324 - val_loss: 0.0293 - val_categorical_accuracy: 0.9356\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0288 - categorical_accuracy: 0.9329 - val_loss: 0.0288 - val_categorical_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0285 - categorical_accuracy: 0.9337 - val_loss: 0.0286 - val_categorical_accuracy: 0.9361\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0281 - categorical_accuracy: 0.9338 - val_loss: 0.0283 - val_categorical_accuracy: 0.9366\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0277 - categorical_accuracy: 0.9350 - val_loss: 0.0280 - val_categorical_accuracy: 0.9388\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0274 - categorical_accuracy: 0.9360 - val_loss: 0.0277 - val_categorical_accuracy: 0.9387\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0270 - categorical_accuracy: 0.9364 - val_loss: 0.0275 - val_categorical_accuracy: 0.9390\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0267 - categorical_accuracy: 0.9368 - val_loss: 0.0272 - val_categorical_accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0264 - categorical_accuracy: 0.9378 - val_loss: 0.0269 - val_categorical_accuracy: 0.9414\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0261 - categorical_accuracy: 0.9384 - val_loss: 0.0266 - val_categorical_accuracy: 0.9414\n",
      "Epoch 40/100\n",
      "676/750 [==========================>...] - ETA: 0s - loss: 0.0259 - categorical_accuracy: 0.9392"
     ]
    }
   ],
   "source": [
    "focal_loss = tf.keras.losses.CategoricalFocalCrossentropy()\n",
    "# compiling the model\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model_fl.compile(optimizer=optimizer, loss=focal_loss, metrics=metrics)\n",
    "# training the model\n",
    "model_fl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_fl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_focal_model.keras'\n",
    "model_fl.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb292d1ae3a65bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T22:45:53.690747900Z",
     "start_time": "2023-08-15T22:45:53.666249200Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining rational loss function\n",
    "# RL(p_t) = 1/p_t * -p * log(p_t)\n",
    "    # TODO: plot the function\n",
    "def rational_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Rational Loss for multi-class classification, tf.keras style.\n",
    "    RL(p_t) = - 1/p_t * log(p_t), where p_t is the probability associated with the true class.\n",
    "\n",
    "    :param y_true: Ground truth labels, shape of [batch_size, num_classes].\n",
    "    :param y_pred: Predicted class probabilities, shape of [batch_size, num_classes].\n",
    "    :return: A scalar representing the mean rational loss over the batch.\n",
    "    NOTE: written assuming GPU support to make use of fast Tensor operations.\n",
    "    \"\"\"\n",
    "    # Create a Categorical Cross-Entropy loss instance\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE # Keep unreduced loss tensor\n",
    "    )\n",
    "    # Clip the prediction value to prevent NaN's and Inf's\n",
    "    _y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "    cross_entropy = cce(y_true, _y_pred) # batch_sizex1\n",
    "    # get y_pred for the true class\n",
    "    _y_pred = K.sum(y_true * _y_pred, axis=1) # batch_sizex1\n",
    "    _y_pred = K.clip(_y_pred, K.epsilon(), None) # Avoid division by zero\n",
    "    _rational_loss = cross_entropy / _y_pred # Rational loss  \n",
    "    \n",
    "    return _rational_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bb936ed83a8b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T22:45:56.281011700Z",
     "start_time": "2023-08-15T22:45:56.225014100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0.05399305 23.02585093], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test rational loss\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]])\n",
    "y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "print(rational_loss(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331edee2580725fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.040754300Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generate_data() -> Tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Generates synthetic y_true and y_pred data.\n",
    "#     :return: y_true and y_pred arrays.\n",
    "#     \"\"\"\n",
    "#     num_samples = 100\n",
    "#     num_classes = 3\n",
    "#     y_true = np.eye(num_classes)[np.random.choice(num_classes, num_samples)]\n",
    "#     y_pred = np.random.rand(num_samples, num_classes)\n",
    "#     y_pred /= y_pred.sum(axis=1, keepdims=True)\n",
    "#     return y_true, y_pred\n",
    "# \n",
    "# def plot_rational_loss() -> None:\n",
    "#     \"\"\"\n",
    "#     Plots the rational loss for the generated data.\n",
    "#     \"\"\"\n",
    "#     y_true, y_pred = generate_data()\n",
    "#     rational_loss_fixed = rational_loss()\n",
    "#     losses: List[float] = [rational_loss_fixed(y_t.reshape(1, -1), y_p.reshape(1, -1)).numpy() for y_t, y_p in zip(y_true, y_pred)]\n",
    "#     plt.plot(losses)\n",
    "#     plt.title(\"Rational Loss for Multi-Class Classification\")\n",
    "#     plt.xlabel(\"Sample\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.show()\n",
    "# \n",
    "# plot_rational_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ab1b90eb796366",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:47:55.585313300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 4s 4ms/step - loss: 141224880.0000 - categorical_accuracy: 0.2577 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190496.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190624.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190496.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190528.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190560.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 145190656.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190528.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190624.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190480.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190752.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190672.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190496.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190608.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190560.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190496.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190480.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190592.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190576.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 145190496.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 145190544.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 145190560.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 145190528.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 145190512.0000 - categorical_accuracy: 0.0992 - val_loss: 145116208.0000 - val_categorical_accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "723/750 [===========================>..] - ETA: 0s - loss: 145115904.0000 - categorical_accuracy: 0.0997"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\Fall 2023\\keras-functional-api\\practice.ipynb Cell 12\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/Fall%202023/keras-functional-api/practice.ipynb#Y230sZmlsZQ%3D%3D?line=1'>2</a>\u001B[0m model_rl\u001B[39m.\u001B[39mcompile(optimizer\u001B[39m=\u001B[39m tf\u001B[39m.\u001B[39mkeras\u001B[39m.\u001B[39moptimizers\u001B[39m.\u001B[39mSGD(), loss\u001B[39m=\u001B[39mrational_loss, metrics\u001B[39m=\u001B[39mmetrics)\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/Fall%202023/keras-functional-api/practice.ipynb#Y230sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m \u001B[39m# training the model\u001B[39;00m\n\u001B[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/Fall%202023/keras-functional-api/practice.ipynb#Y230sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m history \u001B[39m=\u001B[39m model_rl\u001B[39m.\u001B[39;49mfit(x_train, y_train, batch_size\u001B[39m=\u001B[39;49m\u001B[39m64\u001B[39;49m, epochs\u001B[39m=\u001B[39;49m\u001B[39m100\u001B[39;49m, validation_split\u001B[39m=\u001B[39;49m\u001B[39m0.2\u001B[39;49m)\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/Fall%202023/keras-functional-api/practice.ipynb#Y230sZmlsZQ%3D%3D?line=4'>5</a>\u001B[0m \u001B[39m# evaluating the model\u001B[39;00m\n\u001B[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/Fall%202023/keras-functional-api/practice.ipynb#Y230sZmlsZQ%3D%3D?line=5'>6</a>\u001B[0m test_scores \u001B[39m=\u001B[39m model_rl\u001B[39m.\u001B[39mevaluate(x_test, y_test, verbose\u001B[39m=\u001B[39m\u001B[39m2\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[39m=\u001B[39m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[39mreturn\u001B[39;00m fn(\u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mException\u001B[39;00m \u001B[39mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[39m=\u001B[39m _process_traceback_frames(e\u001B[39m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1555\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1551\u001B[0m \u001B[39mwith\u001B[39;00m data_handler\u001B[39m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m   1552\u001B[0m     data_handler\u001B[39m.\u001B[39m_initial_step \u001B[39m=\u001B[39m data_handler\u001B[39m.\u001B[39m_initial_step \u001B[39mor\u001B[39;00m (\n\u001B[0;32m   1553\u001B[0m         \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_maybe_load_initial_step_from_ckpt()\n\u001B[0;32m   1554\u001B[0m     )\n\u001B[1;32m-> 1555\u001B[0m     \u001B[39mfor\u001B[39;00m step \u001B[39min\u001B[39;00m data_handler\u001B[39m.\u001B[39msteps():\n\u001B[0;32m   1556\u001B[0m         \u001B[39mwith\u001B[39;00m tf\u001B[39m.\u001B[39mprofiler\u001B[39m.\u001B[39mexperimental\u001B[39m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m             \u001B[39m\"\u001B[39m\u001B[39mtrain\u001B[39m\u001B[39m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m             epoch_num\u001B[39m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m             _r\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m         ):\n\u001B[0;32m   1563\u001B[0m             callbacks\u001B[39m.\u001B[39mon_train_batch_begin(step)\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1372\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_insufficient_data:  \u001B[39m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[0;32m   1373\u001B[0m     \u001B[39mbreak\u001B[39;00m\n\u001B[1;32m-> 1374\u001B[0m original_spe \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_steps_per_execution\u001B[39m.\u001B[39;49mnumpy()\u001B[39m.\u001B[39mitem()\n\u001B[0;32m   1375\u001B[0m can_run_full_execution \u001B[39m=\u001B[39m (\n\u001B[0;32m   1376\u001B[0m     original_spe \u001B[39m==\u001B[39m \u001B[39m1\u001B[39m\n\u001B[0;32m   1377\u001B[0m     \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_inferred_steps \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m\n\u001B[0;32m   1378\u001B[0m     \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_inferred_steps \u001B[39m-\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_current_step \u001B[39m>\u001B[39m\u001B[39m=\u001B[39m original_spe\n\u001B[0;32m   1379\u001B[0m )\n\u001B[0;32m   1381\u001B[0m \u001B[39mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    635\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mnumpy\u001B[39m(\u001B[39mself\u001B[39m):\n\u001B[0;32m    636\u001B[0m   \u001B[39mif\u001B[39;00m context\u001B[39m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 637\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mread_value()\u001B[39m.\u001B[39mnumpy()\n\u001B[0;32m    638\u001B[0m   \u001B[39mraise\u001B[39;00m \u001B[39mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    639\u001B[0m       \u001B[39m\"\u001B[39m\u001B[39mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:725\u001B[0m, in \u001B[0;36mBaseResourceVariable.read_value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    716\u001B[0m \u001B[39m\"\"\"Constructs an op which reads the value of this variable.\u001B[39;00m\n\u001B[0;32m    717\u001B[0m \n\u001B[0;32m    718\u001B[0m \u001B[39mShould be used when there are multiple reads, or when it is desirable to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    722\u001B[0m \u001B[39m  The value of the variable.\u001B[39;00m\n\u001B[0;32m    723\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[0;32m    724\u001B[0m \u001B[39mwith\u001B[39;00m ops\u001B[39m.\u001B[39mname_scope(\u001B[39m\"\u001B[39m\u001B[39mRead\u001B[39m\u001B[39m\"\u001B[39m):\n\u001B[1;32m--> 725\u001B[0m   value \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_read_variable_op()\n\u001B[0;32m    726\u001B[0m \u001B[39m# Return an identity so it can get placed on whatever device the context\u001B[39;00m\n\u001B[0;32m    727\u001B[0m \u001B[39m# specifies instead of the device where the variable is.\u001B[39;00m\n\u001B[0;32m    728\u001B[0m \u001B[39mreturn\u001B[39;00m array_ops\u001B[39m.\u001B[39midentity(value)\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[1;34m(self, no_copy)\u001B[0m\n\u001B[0;32m    702\u001B[0m       result \u001B[39m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[0;32m    703\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m   result \u001B[39m=\u001B[39m read_and_set_handle(no_copy)\n\u001B[0;32m    706\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m context\u001B[39m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    707\u001B[0m   \u001B[39m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[0;32m    708\u001B[0m   \u001B[39m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[0;32m    709\u001B[0m   tape\u001B[39m.\u001B[39mrecord_operation(\n\u001B[0;32m    710\u001B[0m       \u001B[39m\"\u001B[39m\u001B[39mReadVariableOp\u001B[39m\u001B[39m\"\u001B[39m, [result], [\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandle],\n\u001B[0;32m    711\u001B[0m       backward_function\u001B[39m=\u001B[39m\u001B[39mlambda\u001B[39;00m x: [x],\n\u001B[0;32m    712\u001B[0m       forward_function\u001B[39m=\u001B[39m\u001B[39mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[1;34m(no_copy)\u001B[0m\n\u001B[0;32m    692\u001B[0m \u001B[39mif\u001B[39;00m no_copy \u001B[39mand\u001B[39;00m forward_compat\u001B[39m.\u001B[39mforward_compatible(\u001B[39m2022\u001B[39m, \u001B[39m5\u001B[39m, \u001B[39m3\u001B[39m):\n\u001B[0;32m    693\u001B[0m   gen_resource_variable_ops\u001B[39m.\u001B[39mdisable_copy_on_read(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandle)\n\u001B[1;32m--> 694\u001B[0m result \u001B[39m=\u001B[39m gen_resource_variable_ops\u001B[39m.\u001B[39;49mread_variable_op(\n\u001B[0;32m    695\u001B[0m     \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mhandle, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_dtype)\n\u001B[0;32m    696\u001B[0m _maybe_set_handle_data(\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_dtype, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandle, result)\n\u001B[0;32m    697\u001B[0m \u001B[39mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mc:\\Users\\the_3\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:524\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    522\u001B[0m \u001B[39mif\u001B[39;00m tld\u001B[39m.\u001B[39mis_eager:\n\u001B[0;32m    523\u001B[0m   \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m--> 524\u001B[0m     _result \u001B[39m=\u001B[39m pywrap_tfe\u001B[39m.\u001B[39;49mTFE_Py_FastPathExecute(\n\u001B[0;32m    525\u001B[0m       _ctx, \u001B[39m\"\u001B[39;49m\u001B[39mReadVariableOp\u001B[39;49m\u001B[39m\"\u001B[39;49m, name, resource, \u001B[39m\"\u001B[39;49m\u001B[39mdtype\u001B[39;49m\u001B[39m\"\u001B[39;49m, dtype)\n\u001B[0;32m    526\u001B[0m     \u001B[39mreturn\u001B[39;00m _result\n\u001B[0;32m    527\u001B[0m   \u001B[39mexcept\u001B[39;00m _core\u001B[39m.\u001B[39m_NotOkStatusException \u001B[39mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# compiling the model\n",
    "model_rl.compile(optimizer= tf.keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)\n",
    "# training the model\n",
    "history = model_rl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2)\n",
    "# evaluating the model\n",
    "test_scores = model_rl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_rational_model.keras'\n",
    "model_rl.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b6284c01bdf98",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.044751300Z"
    }
   },
   "outputs": [],
   "source": [
    "# rebuilding the models\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c73a18c8f5973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T22:40:38.086251Z",
     "start_time": "2023-08-15T22:40:38.046750600Z"
    }
   },
   "outputs": [],
   "source": [
    "# imbalance \n",
    "def create_imbalanced_data(x, y, imbalance_rate=0.5):\n",
    "    \"\"\"\n",
    "    Create an imbalanced dataset based on a given probability distribution.\n",
    "    The probability for class d is given by: P(d) = 0.5^d / 2*(1 - 0.5^10)\n",
    "\n",
    "    :param x: Features, shape of [total_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [total_samples, num_classes].\n",
    "    :param imbalance_rate: Base rate for the exponential decay of class frequency (default 0.5).\n",
    "    :return: Tuple of imbalanced features and labels, shapes of [selected_samples, feature_dim] and [selected_samples, num_classes].\n",
    "    \"\"\"\n",
    "    total_samples = len(y)\n",
    "    a = imbalance_rate\n",
    "    normalization_factor = 2 * (1 - a**10)\n",
    "\n",
    "    indices_by_class = [np.where(y[:, d] == 1)[0] for d in range(10)]\n",
    "    selected_indices = []\n",
    "\n",
    "    for d in range(10):\n",
    "        probability_d = (a**d) / normalization_factor\n",
    "        frequency = int(total_samples * probability_d)\n",
    "        np.random.shuffle(indices_by_class[d]) # Shuffle to ensure random selection\n",
    "        selected_indices.extend(indices_by_class[d][:frequency])\n",
    "\n",
    "    return x[selected_indices], y[selected_indices]\n",
    "\n",
    "\n",
    "x_train_imbalanced, y_train_imbalanced = create_imbalanced_data(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d76b12905e4aa4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.048751600Z"
    }
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_ce.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "model_fl.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.CategoricalFocalCrossentropy(), metrics=metrics)\n",
    "model_rl.compile(optimizer=keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefdf376d35ec93",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.051250400Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training on imbalanced data:\")\n",
    "print(\"Cross Entropy:\")\n",
    "model_ce.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Focal Loss:\")\n",
    "model_fl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Rational Loss:\")\n",
    "model_rl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9401ce9ef65d9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.052752500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Balanced data\n",
    "print(model_ce.evaluate(x_test, y_test))\n",
    "print(model_fl.evaluate(x_test, y_test))\n",
    "print(model_rl.evaluate(x_test, y_test))\n",
    "\n",
    "# Imbalanced data\n",
    "x_test_imbalanced, y_test_imbalanced = create_imbalanced_data(x_test, y_test)\n",
    "print(model_ce.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_fl.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_rl.evaluate(x_test_imbalanced, y_test_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143062bb0fb2c0d0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.055252300Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_by_bins(model, x, y):\n",
    "    \"\"\"\n",
    "    Calculate and print the accuracy of the given model for specific bins of classes.\n",
    "    The bins are defined as: 0-1, 2-7, 8-9.\n",
    "\n",
    "    :param model: Trained tf.keras model to evaluate.\n",
    "    :param x: Input features, shape of [num_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [num_samples, num_classes].\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x).argmax(axis=-1)\n",
    "    true_labels = y.argmax(axis=-1)\n",
    "    bins = [(0, 1), (2, 7), (8, 9)]\n",
    "    for bin_start, bin_end in bins:\n",
    "        mask = (true_labels >= bin_start) & (true_labels <= bin_end) \n",
    "        bin_accuracy = np.mean(predictions[mask] == true_labels[mask])\n",
    "        print(f\"Accuracy for bin {bin_start}-{bin_end}: {bin_accuracy}\")\n",
    "\n",
    "print(\"Accuracy by bins for balanced data:\")\n",
    "print(\"Cross Entropy:\")\n",
    "accuracy_by_bins(model_ce, x_test, y_test)\n",
    "print(\"Focal Loss:\")\n",
    "accuracy_by_bins(model_fl, x_test, y_test)\n",
    "print(\"Rational Loss:\")\n",
    "accuracy_by_bins(model_rl, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
