{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db106a0ce89886c6",
   "metadata": {},
   "source": [
    "# Practice on Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2390991af87b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:34:20.671436900Z",
     "start_time": "2023-08-16T05:34:18.050935200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:34:18.309046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 01:34:19.465465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# for types hints\n",
    "from typing import Tuple, Callable, List\n",
    "from tensorflow import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0566659f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:34:24.210934800Z",
     "start_time": "2023-08-16T05:34:24.193436200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:34:24.167306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:24.190791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:24.191032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for gpus\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# list their names\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235572d8aa183bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:34:27.409956Z",
     "start_time": "2023-08-16T05:34:27.355465500Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist dataset\n",
    "def load_and_preprocess_mnist() -> Tuple[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor]]:\n",
    "    \"\"\"\n",
    "    Load the MNIST dataset, preprocess images, and perform one-hot encoding of labels.\n",
    "\n",
    "    :return: Tuple of training data (x_train, y_train) and testing data (x_test, y_test).\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) =  tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Reshape and normalize images\n",
    "    x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "    x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "    # One-hot encoding of labels\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ff4c5d4d8c22ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:34:29.920230400Z",
     "start_time": "2023-08-16T05:34:29.626231300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a49bafd834711d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:34:33.870754700Z",
     "start_time": "2023-08-16T05:34:32.166757600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:34:32.179234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:32.179521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:32.179724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:33.454333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:33.454829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:33.454846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-16 01:34:33.455115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-16 01:34:33.455161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "def build_model() -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Build a simple MLP model for MNIST classification.\n",
    "    :return: A tf.keras Model with inputs and outputs defined.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(784,), name='input')  # input layer\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='hidden1')(inputs)  # hidden layer\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='hidden2')(x)  # hidden layer\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', name='output')(x)  # output layer\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74658d8b5c82aac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:35:03.487429100Z",
     "start_time": "2023-08-16T05:34:43.806487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:34:46.185768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-16 01:34:46.189082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4ea086020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-16 01:34:46.189115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-08-16 01:34:46.387316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-16 01:34:46.396035: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:543] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-08-16 01:34:46.459814: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 7s 6ms/step - loss: 1.0914 - categorical_accuracy: 0.7086 - val_loss: 0.4965 - val_categorical_accuracy: 0.8682\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.4433 - categorical_accuracy: 0.8766 - val_loss: 0.3599 - val_categorical_accuracy: 0.8967\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.3571 - categorical_accuracy: 0.8972 - val_loss: 0.3100 - val_categorical_accuracy: 0.9086\n",
      "Epoch 4/100\n",
      "347/750 [============>.................] - ETA: 2s - loss: 0.3235 - categorical_accuracy: 0.9072"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# training the model\u001B[39;00m\n\u001B[1;32m      7\u001B[0m early_stopping_callback \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 8\u001B[0m \u001B[43mmodel_ce\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# evaluating the model\u001B[39;00m\n\u001B[1;32m     10\u001B[0m test_scores \u001B[38;5;241m=\u001B[39m model_ce\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1740\u001B[0m ):\n\u001B[1;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    146\u001B[0m   (concrete_function,\n\u001B[1;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs)\u001B[0m\n\u001B[1;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1351\u001B[0m     args,\n\u001B[1;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1353\u001B[0m     executing_eagerly)\n\u001B[1;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1472\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD()\n",
    "ce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "# compiling the model\n",
    "model_ce.compile(optimizer=optimizer, loss=ce_loss, metrics=metrics)\n",
    "# training the model\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "model_ce.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_ce.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "\n",
    "# saving the model\n",
    "path = './weights/mnist_ce_model.keras'\n",
    "model_ce.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff849813ffddfd76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T04:55:33.741491900Z",
     "start_time": "2023-08-16T04:48:28.719992500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0699 - categorical_accuracy: 0.8563 - val_loss: 0.0605 - val_categorical_accuracy: 0.8785\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0622 - categorical_accuracy: 0.8717 - val_loss: 0.0549 - val_categorical_accuracy: 0.8895\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0570 - categorical_accuracy: 0.8809 - val_loss: 0.0511 - val_categorical_accuracy: 0.8944\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0532 - categorical_accuracy: 0.8868 - val_loss: 0.0483 - val_categorical_accuracy: 0.8983\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0503 - categorical_accuracy: 0.8915 - val_loss: 0.0461 - val_categorical_accuracy: 0.9022\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0480 - categorical_accuracy: 0.8959 - val_loss: 0.0443 - val_categorical_accuracy: 0.9045\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0461 - categorical_accuracy: 0.8999 - val_loss: 0.0427 - val_categorical_accuracy: 0.9070\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0444 - categorical_accuracy: 0.9025 - val_loss: 0.0415 - val_categorical_accuracy: 0.9094\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0430 - categorical_accuracy: 0.9046 - val_loss: 0.0403 - val_categorical_accuracy: 0.9115\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0418 - categorical_accuracy: 0.9073 - val_loss: 0.0393 - val_categorical_accuracy: 0.9147\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0407 - categorical_accuracy: 0.9089 - val_loss: 0.0386 - val_categorical_accuracy: 0.9155\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0397 - categorical_accuracy: 0.9111 - val_loss: 0.0377 - val_categorical_accuracy: 0.9180\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0388 - categorical_accuracy: 0.9131 - val_loss: 0.0369 - val_categorical_accuracy: 0.9176\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0379 - categorical_accuracy: 0.9144 - val_loss: 0.0364 - val_categorical_accuracy: 0.9188\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0372 - categorical_accuracy: 0.9162 - val_loss: 0.0356 - val_categorical_accuracy: 0.9210\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0364 - categorical_accuracy: 0.9184 - val_loss: 0.0350 - val_categorical_accuracy: 0.9213\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0358 - categorical_accuracy: 0.9191 - val_loss: 0.0344 - val_categorical_accuracy: 0.9219\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0351 - categorical_accuracy: 0.9206 - val_loss: 0.0340 - val_categorical_accuracy: 0.9231\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0345 - categorical_accuracy: 0.9213 - val_loss: 0.0335 - val_categorical_accuracy: 0.9236\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0340 - categorical_accuracy: 0.9229 - val_loss: 0.0331 - val_categorical_accuracy: 0.9252\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0334 - categorical_accuracy: 0.9241 - val_loss: 0.0326 - val_categorical_accuracy: 0.9252\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0329 - categorical_accuracy: 0.9250 - val_loss: 0.0321 - val_categorical_accuracy: 0.9278\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0323 - categorical_accuracy: 0.9265 - val_loss: 0.0317 - val_categorical_accuracy: 0.9287\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0319 - categorical_accuracy: 0.9271 - val_loss: 0.0312 - val_categorical_accuracy: 0.9293\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0314 - categorical_accuracy: 0.9283 - val_loss: 0.0309 - val_categorical_accuracy: 0.9309\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0309 - categorical_accuracy: 0.9290 - val_loss: 0.0306 - val_categorical_accuracy: 0.9312\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0305 - categorical_accuracy: 0.9295 - val_loss: 0.0301 - val_categorical_accuracy: 0.9328\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0301 - categorical_accuracy: 0.9306 - val_loss: 0.0298 - val_categorical_accuracy: 0.9330\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0296 - categorical_accuracy: 0.9310 - val_loss: 0.0295 - val_categorical_accuracy: 0.9348\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0292 - categorical_accuracy: 0.9324 - val_loss: 0.0293 - val_categorical_accuracy: 0.9356\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0288 - categorical_accuracy: 0.9329 - val_loss: 0.0288 - val_categorical_accuracy: 0.9355\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0285 - categorical_accuracy: 0.9337 - val_loss: 0.0286 - val_categorical_accuracy: 0.9361\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0281 - categorical_accuracy: 0.9338 - val_loss: 0.0283 - val_categorical_accuracy: 0.9366\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0277 - categorical_accuracy: 0.9350 - val_loss: 0.0280 - val_categorical_accuracy: 0.9388\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0274 - categorical_accuracy: 0.9360 - val_loss: 0.0277 - val_categorical_accuracy: 0.9387\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0270 - categorical_accuracy: 0.9364 - val_loss: 0.0275 - val_categorical_accuracy: 0.9390\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0267 - categorical_accuracy: 0.9368 - val_loss: 0.0272 - val_categorical_accuracy: 0.9400\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0264 - categorical_accuracy: 0.9378 - val_loss: 0.0269 - val_categorical_accuracy: 0.9414\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0261 - categorical_accuracy: 0.9384 - val_loss: 0.0266 - val_categorical_accuracy: 0.9414\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0258 - categorical_accuracy: 0.9392 - val_loss: 0.0264 - val_categorical_accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 6s 8ms/step - loss: 0.0254 - categorical_accuracy: 0.9397 - val_loss: 0.0262 - val_categorical_accuracy: 0.9424\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0252 - categorical_accuracy: 0.9404 - val_loss: 0.0259 - val_categorical_accuracy: 0.9438\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0249 - categorical_accuracy: 0.9405 - val_loss: 0.0258 - val_categorical_accuracy: 0.9437\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0246 - categorical_accuracy: 0.9416 - val_loss: 0.0255 - val_categorical_accuracy: 0.9445\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0243 - categorical_accuracy: 0.9422 - val_loss: 0.0253 - val_categorical_accuracy: 0.9439\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0241 - categorical_accuracy: 0.9433 - val_loss: 0.0251 - val_categorical_accuracy: 0.9453\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0238 - categorical_accuracy: 0.9431 - val_loss: 0.0249 - val_categorical_accuracy: 0.9457\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0235 - categorical_accuracy: 0.9438 - val_loss: 0.0247 - val_categorical_accuracy: 0.9454\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0233 - categorical_accuracy: 0.9442 - val_loss: 0.0245 - val_categorical_accuracy: 0.9467\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0231 - categorical_accuracy: 0.9445 - val_loss: 0.0243 - val_categorical_accuracy: 0.9461\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0228 - categorical_accuracy: 0.9456 - val_loss: 0.0241 - val_categorical_accuracy: 0.9470\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0226 - categorical_accuracy: 0.9461 - val_loss: 0.0240 - val_categorical_accuracy: 0.9470\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0224 - categorical_accuracy: 0.9463 - val_loss: 0.0239 - val_categorical_accuracy: 0.9477\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0221 - categorical_accuracy: 0.9468 - val_loss: 0.0236 - val_categorical_accuracy: 0.9480\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0219 - categorical_accuracy: 0.9472 - val_loss: 0.0234 - val_categorical_accuracy: 0.9482\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0217 - categorical_accuracy: 0.9482 - val_loss: 0.0233 - val_categorical_accuracy: 0.9488\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0215 - categorical_accuracy: 0.9478 - val_loss: 0.0232 - val_categorical_accuracy: 0.9480\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0213 - categorical_accuracy: 0.9484 - val_loss: 0.0229 - val_categorical_accuracy: 0.9497\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0211 - categorical_accuracy: 0.9488 - val_loss: 0.0229 - val_categorical_accuracy: 0.9495\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0209 - categorical_accuracy: 0.9494 - val_loss: 0.0227 - val_categorical_accuracy: 0.9497\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0207 - categorical_accuracy: 0.9499 - val_loss: 0.0226 - val_categorical_accuracy: 0.9497\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0205 - categorical_accuracy: 0.9502 - val_loss: 0.0226 - val_categorical_accuracy: 0.9498\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0203 - categorical_accuracy: 0.9507 - val_loss: 0.0223 - val_categorical_accuracy: 0.9509\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0202 - categorical_accuracy: 0.9511 - val_loss: 0.0222 - val_categorical_accuracy: 0.9510\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0200 - categorical_accuracy: 0.9516 - val_loss: 0.0221 - val_categorical_accuracy: 0.9513\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0198 - categorical_accuracy: 0.9516 - val_loss: 0.0219 - val_categorical_accuracy: 0.9518\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0196 - categorical_accuracy: 0.9520 - val_loss: 0.0218 - val_categorical_accuracy: 0.9517\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0195 - categorical_accuracy: 0.9528 - val_loss: 0.0217 - val_categorical_accuracy: 0.9524\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0193 - categorical_accuracy: 0.9529 - val_loss: 0.0215 - val_categorical_accuracy: 0.9527\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0191 - categorical_accuracy: 0.9533 - val_loss: 0.0214 - val_categorical_accuracy: 0.9526\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0190 - categorical_accuracy: 0.9537 - val_loss: 0.0214 - val_categorical_accuracy: 0.9528\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0188 - categorical_accuracy: 0.9539 - val_loss: 0.0211 - val_categorical_accuracy: 0.9537\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0187 - categorical_accuracy: 0.9546 - val_loss: 0.0210 - val_categorical_accuracy: 0.9539\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0185 - categorical_accuracy: 0.9545 - val_loss: 0.0210 - val_categorical_accuracy: 0.9537\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0184 - categorical_accuracy: 0.9550 - val_loss: 0.0208 - val_categorical_accuracy: 0.9539\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0182 - categorical_accuracy: 0.9552 - val_loss: 0.0207 - val_categorical_accuracy: 0.9549\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0181 - categorical_accuracy: 0.9556 - val_loss: 0.0206 - val_categorical_accuracy: 0.9548\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0179 - categorical_accuracy: 0.9560 - val_loss: 0.0205 - val_categorical_accuracy: 0.9552\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0178 - categorical_accuracy: 0.9562 - val_loss: 0.0204 - val_categorical_accuracy: 0.9553\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0176 - categorical_accuracy: 0.9568 - val_loss: 0.0203 - val_categorical_accuracy: 0.9551\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0175 - categorical_accuracy: 0.9569 - val_loss: 0.0203 - val_categorical_accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0174 - categorical_accuracy: 0.9571 - val_loss: 0.0202 - val_categorical_accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0172 - categorical_accuracy: 0.9577 - val_loss: 0.0201 - val_categorical_accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0171 - categorical_accuracy: 0.9580 - val_loss: 0.0199 - val_categorical_accuracy: 0.9559\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0170 - categorical_accuracy: 0.9579 - val_loss: 0.0198 - val_categorical_accuracy: 0.9558\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0169 - categorical_accuracy: 0.9584 - val_loss: 0.0198 - val_categorical_accuracy: 0.9562\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0167 - categorical_accuracy: 0.9588 - val_loss: 0.0197 - val_categorical_accuracy: 0.9561\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0166 - categorical_accuracy: 0.9588 - val_loss: 0.0196 - val_categorical_accuracy: 0.9567\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0165 - categorical_accuracy: 0.9591 - val_loss: 0.0195 - val_categorical_accuracy: 0.9567\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0164 - categorical_accuracy: 0.9593 - val_loss: 0.0194 - val_categorical_accuracy: 0.9567\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0163 - categorical_accuracy: 0.9592 - val_loss: 0.0194 - val_categorical_accuracy: 0.9567\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0161 - categorical_accuracy: 0.9596 - val_loss: 0.0192 - val_categorical_accuracy: 0.9576\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0160 - categorical_accuracy: 0.9599 - val_loss: 0.0192 - val_categorical_accuracy: 0.9570\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0159 - categorical_accuracy: 0.9604 - val_loss: 0.0192 - val_categorical_accuracy: 0.9572\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0158 - categorical_accuracy: 0.9604 - val_loss: 0.0191 - val_categorical_accuracy: 0.9579\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0157 - categorical_accuracy: 0.9605 - val_loss: 0.0190 - val_categorical_accuracy: 0.9571\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0156 - categorical_accuracy: 0.9610 - val_loss: 0.0189 - val_categorical_accuracy: 0.9578\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0155 - categorical_accuracy: 0.9613 - val_loss: 0.0188 - val_categorical_accuracy: 0.9580\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0153 - categorical_accuracy: 0.9615 - val_loss: 0.0188 - val_categorical_accuracy: 0.9581\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0153 - categorical_accuracy: 0.9614 - val_loss: 0.0187 - val_categorical_accuracy: 0.9586\n",
      "313/313 - 1s - loss: 0.0185 - categorical_accuracy: 0.9562 - 781ms/epoch - 2ms/step\n",
      "Test loss: 0.018461357802152634\n",
      "Test accuracy: 0.9562000036239624\n"
     ]
    }
   ],
   "source": [
    "focal_loss = tf.keras.losses.CategoricalFocalCrossentropy()\n",
    "# compiling the model\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model_fl.compile(optimizer=optimizer, loss=focal_loss, metrics=metrics)\n",
    "# training the model\n",
    "model_fl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_fl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_focal_model.keras'\n",
    "model_fl.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb292d1ae3a65bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:35:11.057174700Z",
     "start_time": "2023-08-16T05:35:10.962670300Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining rational loss function\n",
    "# RL(p_t) = 1/p_t * -p * log(p_t)\n",
    "    # TODO: plot the function\n",
    "def rational_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Rational Loss for multi-class classification, tf.keras style.\n",
    "    RL(p_t) = - 1/p_t * log(p_t), where p_t is the probability associated with the true class.\n",
    "\n",
    "    :param y_true: Ground truth labels, shape of [batch_size, num_classes].\n",
    "    :param y_pred: Predicted class probabilities, shape of [batch_size, num_classes].\n",
    "    :return: A scalar representing the mean rational loss over the batch.\n",
    "    NOTE: written assuming GPU support to make use of fast Tensor operations.\n",
    "    \"\"\"\n",
    "    # Create a Categorical Cross-Entropy loss instance\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE # Keep unreduced loss tensor\n",
    "    )\n",
    "    # clip the predicted probabilities to avoid log(0)\n",
    "    _y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
    "    cross_entropy = cce(y_true, _y_pred) # batch_sizex1\n",
    "    # find the probability associated with the true class\n",
    "    _y_true = tf.argmax(y_true, axis=1)\n",
    "    # get the predicted probability of the true class\n",
    "    _y_pred = tf.gather(_y_pred, _y_true, axis=1)\n",
    "    # rational loss by dividing the cross entropy by the predicted probability of the true class\n",
    "    _rational_loss = cross_entropy / _y_pred # Rational loss\n",
    "    \n",
    "    return K.mean(_rational_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2bb936ed83a8b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:35:18.326328500Z",
     "start_time": "2023-08-16T05:35:18.312333500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5756468.518475293, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# test rational loss\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]])\n",
    "y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "print(rational_loss(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331edee2580725fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-15T22:40:38.040754300Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generate_data() -> Tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Generates synthetic y_true and y_pred data.\n",
    "#     :return: y_true and y_pred arrays.\n",
    "#     \"\"\"\n",
    "#     num_samples = 100\n",
    "#     num_classes = 3\n",
    "#     y_true = np.eye(num_classes)[np.random.choice(num_classes, num_samples)]\n",
    "#     y_pred = np.random.rand(num_samples, num_classes)\n",
    "#     y_pred /= y_pred.sum(axis=1, keepdims=True)\n",
    "#     return y_true, y_pred\n",
    "# \n",
    "# def plot_rational_loss() -> None:\n",
    "#     \"\"\"\n",
    "#     Plots the rational loss for the generated data.\n",
    "#     \"\"\"\n",
    "#     y_true, y_pred = generate_data()\n",
    "#     rational_loss_fixed = rational_loss()\n",
    "#     losses: List[float] = [rational_loss_fixed(y_t.reshape(1, -1), y_p.reshape(1, -1)).numpy() for y_t, y_p in zip(y_true, y_pred)]\n",
    "#     plt.plot(losses)\n",
    "#     plt.title(\"Rational Loss for Multi-Class Classification\")\n",
    "#     plt.xlabel(\"Sample\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.show()\n",
    "# \n",
    "# plot_rational_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ab1b90eb796366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:36:42.624732200Z",
     "start_time": "2023-08-16T05:35:27.217153400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 16.3998 - categorical_accuracy: 0.8751 - val_loss: 14.4876 - val_categorical_accuracy: 0.9304\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 14.2088 - categorical_accuracy: 0.9347 - val_loss: 13.4822 - val_categorical_accuracy: 0.9474\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 13.3935 - categorical_accuracy: 0.9494 - val_loss: 13.3884 - val_categorical_accuracy: 0.9548\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 12.8958 - categorical_accuracy: 0.9586 - val_loss: 12.6673 - val_categorical_accuracy: 0.9612\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 12.5716 - categorical_accuracy: 0.9640 - val_loss: 12.5632 - val_categorical_accuracy: 0.9610\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 12.2997 - categorical_accuracy: 0.9681 - val_loss: 12.3048 - val_categorical_accuracy: 0.9637\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 12.0924 - categorical_accuracy: 0.9719 - val_loss: 12.3455 - val_categorical_accuracy: 0.9649\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 11.9193 - categorical_accuracy: 0.9743 - val_loss: 12.0508 - val_categorical_accuracy: 0.9685\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 11.7562 - categorical_accuracy: 0.9776 - val_loss: 12.1838 - val_categorical_accuracy: 0.9679\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 11.6274 - categorical_accuracy: 0.9791 - val_loss: 12.1598 - val_categorical_accuracy: 0.9693\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 11.5090 - categorical_accuracy: 0.9802 - val_loss: 11.9481 - val_categorical_accuracy: 0.9697\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 11.4106 - categorical_accuracy: 0.9818 - val_loss: 12.0021 - val_categorical_accuracy: 0.9702\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 11.3010 - categorical_accuracy: 0.9831 - val_loss: 11.8915 - val_categorical_accuracy: 0.9711\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 11.2386 - categorical_accuracy: 0.9840 - val_loss: 11.8602 - val_categorical_accuracy: 0.9717\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 11.1485 - categorical_accuracy: 0.9856 - val_loss: 11.9685 - val_categorical_accuracy: 0.9699\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 11.0572 - categorical_accuracy: 0.9869 - val_loss: 11.8759 - val_categorical_accuracy: 0.9721\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 10.9985 - categorical_accuracy: 0.9870 - val_loss: 11.8644 - val_categorical_accuracy: 0.9732\n",
      "313/313 - 1s - loss: 11.6380 - categorical_accuracy: 0.9718 - 724ms/epoch - 2ms/step\n",
      "Test loss: 11.638002395629883\n",
      "Test accuracy: 0.9718000292778015\n"
     ]
    }
   ],
   "source": [
    "# compiling the model\n",
    "model_rl.compile(optimizer= tf.keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)\n",
    "# training the model\n",
    "history = model_rl.fit(x_train, y_train, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "# evaluating the model\n",
    "test_scores = model_rl.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])\n",
    "# saving the model\n",
    "path = './weights/mnist_rational_model.keras'\n",
    "model_rl.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0b6284c01bdf98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:37:27.022510400Z",
     "start_time": "2023-08-16T05:37:26.823891600Z"
    }
   },
   "outputs": [],
   "source": [
    "# rebuilding the models\n",
    "model_ce = build_model()\n",
    "model_fl = build_model()\n",
    "model_rl = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674c73a18c8f5973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:37:29.440075100Z",
     "start_time": "2023-08-16T05:37:29.394082700Z"
    }
   },
   "outputs": [],
   "source": [
    "# imbalance \n",
    "def create_imbalanced_data(x, y, imbalance_rate=0.5):\n",
    "    \"\"\"\n",
    "    Create an imbalanced dataset based on a given probability distribution.\n",
    "    The probability for class d is given by: P(d) = 0.5^d / 2*(1 - 0.5^10)\n",
    "\n",
    "    :param x: Features, shape of [total_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [total_samples, num_classes].\n",
    "    :param imbalance_rate: Base rate for the exponential decay of class frequency (default 0.5).\n",
    "    :return: Tuple of imbalanced features and labels, shapes of [selected_samples, feature_dim] and [selected_samples, num_classes].\n",
    "    \"\"\"\n",
    "    total_samples = len(y)\n",
    "    a = imbalance_rate\n",
    "    normalization_factor = 2 * (1 - a**10)\n",
    "\n",
    "    indices_by_class = [np.where(y[:, d] == 1)[0] for d in range(10)]\n",
    "    selected_indices = []\n",
    "\n",
    "    for d in range(10):\n",
    "        probability_d = (a**d) / normalization_factor\n",
    "        frequency = int(total_samples * probability_d)\n",
    "        np.random.shuffle(indices_by_class[d]) # Shuffle to ensure random selection\n",
    "        selected_indices.extend(indices_by_class[d][:frequency])\n",
    "\n",
    "    return x[selected_indices], y[selected_indices]\n",
    "\n",
    "\n",
    "x_train_imbalanced, y_train_imbalanced = create_imbalanced_data(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d76b12905e4aa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:37:31.686841600Z",
     "start_time": "2023-08-16T05:37:31.639842900Z"
    }
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model_ce.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "model_fl.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.CategoricalFocalCrossentropy(), metrics=metrics)\n",
    "model_rl.compile(optimizer=tf.keras.optimizers.SGD(), loss=rational_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdefdf376d35ec93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:41:21.816543200Z",
     "start_time": "2023-08-16T05:39:36.335592300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on imbalanced data:\n",
      "Cross Entropy:\n",
      "Epoch 1/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.1120 - categorical_accuracy: 0.9675 - val_loss: 5.9664 - val_categorical_accuracy: 0.2683\n",
      "Epoch 2/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0939 - categorical_accuracy: 0.9715 - val_loss: 6.3878 - val_categorical_accuracy: 0.2645\n",
      "Epoch 3/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0846 - categorical_accuracy: 0.9743 - val_loss: 6.6570 - val_categorical_accuracy: 0.2683\n",
      "Epoch 4/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0783 - categorical_accuracy: 0.9762 - val_loss: 6.8922 - val_categorical_accuracy: 0.2729\n",
      "Epoch 5/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0732 - categorical_accuracy: 0.9776 - val_loss: 7.0381 - val_categorical_accuracy: 0.2725\n",
      "Epoch 6/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0696 - categorical_accuracy: 0.9797 - val_loss: 7.2306 - val_categorical_accuracy: 0.2689\n",
      "Epoch 7/100\n",
      "652/652 [==============================] - 6s 9ms/step - loss: 0.0664 - categorical_accuracy: 0.9801 - val_loss: 7.2133 - val_categorical_accuracy: 0.2716\n",
      "Focal Loss:\n",
      "Epoch 1/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 0.0223 - categorical_accuracy: 0.9427 - val_loss: 0.9575 - val_categorical_accuracy: 0.2472\n",
      "Epoch 2/100\n",
      "652/652 [==============================] - 4s 7ms/step - loss: 0.0167 - categorical_accuracy: 0.9545 - val_loss: 1.0256 - val_categorical_accuracy: 0.2589\n",
      "Epoch 3/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0142 - categorical_accuracy: 0.9610 - val_loss: 1.0744 - val_categorical_accuracy: 0.2620\n",
      "Epoch 4/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 0.0127 - categorical_accuracy: 0.9634 - val_loss: 1.1089 - val_categorical_accuracy: 0.2633\n",
      "Epoch 5/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 0.0116 - categorical_accuracy: 0.9661 - val_loss: 1.1412 - val_categorical_accuracy: 0.2639\n",
      "Epoch 6/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 0.0109 - categorical_accuracy: 0.9683 - val_loss: 1.1670 - val_categorical_accuracy: 0.2606\n",
      "Epoch 7/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 0.0102 - categorical_accuracy: 0.9696 - val_loss: 1.1886 - val_categorical_accuracy: 0.2645\n",
      "Rational Loss:\n",
      "Epoch 1/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 3.1385 - categorical_accuracy: 0.9770 - val_loss: 13819.8066 - val_categorical_accuracy: 0.2794\n",
      "Epoch 2/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 2.9742 - categorical_accuracy: 0.9811 - val_loss: 17304.4863 - val_categorical_accuracy: 0.2748\n",
      "Epoch 3/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 2.8748 - categorical_accuracy: 0.9856 - val_loss: 25629.0469 - val_categorical_accuracy: 0.2779\n",
      "Epoch 4/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 2.8288 - categorical_accuracy: 0.9867 - val_loss: 28019.8672 - val_categorical_accuracy: 0.2798\n",
      "Epoch 5/100\n",
      "652/652 [==============================] - 5s 8ms/step - loss: 2.7441 - categorical_accuracy: 0.9895 - val_loss: 29960.5488 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 2.6802 - categorical_accuracy: 0.9919 - val_loss: 34929.6445 - val_categorical_accuracy: 0.2833\n",
      "Epoch 7/100\n",
      "652/652 [==============================] - 5s 7ms/step - loss: 2.6434 - categorical_accuracy: 0.9930 - val_loss: 44388.6367 - val_categorical_accuracy: 0.2773\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7fa5681637c0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training on imbalanced data:\")\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "print(\"Cross Entropy:\")\n",
    "model_ce.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Focal Loss:\")\n",
    "model_fl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])\n",
    "print(\"Rational Loss:\")\n",
    "model_rl.fit(x_train_imbalanced, y_train_imbalanced, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d9401ce9ef65d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:42:14.565230100Z",
     "start_time": "2023-08-16T05:42:08.136390100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test on balanced data:\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 5.3273 - categorical_accuracy: 0.4049\n",
      "[5.327250957489014, 0.4049000144004822]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8436 - categorical_accuracy: 0.3959\n",
      "[0.8436211943626404, 0.39590001106262207]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 32818.2148 - categorical_accuracy: 0.4075\n",
      "[32818.21484375, 0.4074999988079071]\n",
      "test on imbalanced data:\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 1.2605 - categorical_accuracy: 0.8399\n",
      "[1.2605335712432861, 0.83990877866745]\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 0.2039 - categorical_accuracy: 0.8244\n",
      "[0.20391705632209778, 0.8244013786315918]\n",
      "138/138 [==============================] - 1s 4ms/step - loss: 3080.6453 - categorical_accuracy: 0.8436\n",
      "[3080.645263671875, 0.843557596206665]\n"
     ]
    }
   ],
   "source": [
    "# Balanced data\n",
    "print(\"test on balanced data:\")\n",
    "print(model_ce.evaluate(x_test, y_test))\n",
    "print(model_fl.evaluate(x_test, y_test))\n",
    "print(model_rl.evaluate(x_test, y_test))\n",
    "\n",
    "# Imbalanced data\n",
    "print(\"test on imbalanced data:\")\n",
    "x_test_imbalanced, y_test_imbalanced = create_imbalanced_data(x_test, y_test)\n",
    "print(model_ce.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_fl.evaluate(x_test_imbalanced, y_test_imbalanced))\n",
    "print(model_rl.evaluate(x_test_imbalanced, y_test_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "143062bb0fb2c0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T05:42:32.557232300Z",
     "start_time": "2023-08-16T05:42:29.312952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by bins for balanced data:\n",
      "Cross Entropy:\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Accuracy for bin 0-1: 0.9919621749408983\n",
      "Accuracy for bin 2-7: 0.33056590986106404\n",
      "Accuracy for bin 8-9: 0.0\n",
      "Focal Loss:\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Accuracy for bin 0-1: 0.9843971631205674\n",
      "Accuracy for bin 2-7: 0.3180277871907828\n",
      "Accuracy for bin 8-9: 0.0\n",
      "Rational Loss:\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Accuracy for bin 0-1: 0.9914893617021276\n",
      "Accuracy for bin 2-7: 0.33514063029481533\n",
      "Accuracy for bin 8-9: 0.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy_by_bins(model, x, y):\n",
    "    \"\"\"\n",
    "    Calculate and print the accuracy of the given model for specific bins of classes.\n",
    "    The bins are defined as: 0-1, 2-7, 8-9.\n",
    "\n",
    "    :param model: Trained tf.keras model to evaluate.\n",
    "    :param x: Input features, shape of [num_samples, feature_dim].\n",
    "    :param y: One-hot encoded labels, shape of [num_samples, num_classes].\n",
    "    \"\"\"\n",
    "    predictions = model.predict(x).argmax(axis=-1)\n",
    "    true_labels = y.argmax(axis=-1)\n",
    "    bins = [(0, 1), (2, 7), (8, 9)]\n",
    "    for bin_start, bin_end in bins:\n",
    "        mask = (true_labels >= bin_start) & (true_labels <= bin_end) \n",
    "        bin_accuracy = np.mean(predictions[mask] == true_labels[mask])\n",
    "        print(f\"Accuracy for bin {bin_start}-{bin_end}: {bin_accuracy}\")\n",
    "\n",
    "print(\"Accuracy by bins for balanced data:\")\n",
    "print(\"Cross Entropy:\")\n",
    "accuracy_by_bins(model_ce, x_test, y_test)\n",
    "print(\"Focal Loss:\")\n",
    "accuracy_by_bins(model_fl, x_test, y_test)\n",
    "print(\"Rational Loss:\")\n",
    "accuracy_by_bins(model_rl, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
