{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T21:59:43.404602100Z",
     "start_time": "2023-10-09T21:59:43.205104900Z"
    }
   },
   "outputs": [],
   "source": [
    "# matching cmes to seps \n",
    "# use SEP onset time as reference and find cme donki time which should precede SEP onset time within time widow\n",
    "# when match is found, calculate time difference, CME time - SEP onset time. SEP onset time -> CME time (those are real solar events that happened that i am trying to find)\n",
    "# If SEP doesn't have a CME match, look further back in time to 6 hours earlier, and potentially keep looking back\n",
    "# within the time widow, we are finding other CMEs that happened within the time widow. Meaning SEPs may have multiple CME candidate sources. Find all the matching CMEs if there are more than one.\n",
    "# calculate time difference for all matched CMEs, time_diff = CME_time - SEP_onset_time\n",
    "# since CME precede SEPs, the difference is negative. In case of multiple CME matches, take the largest (smallest negative value) time difference as\n",
    "# the precursor CME for that SEP. \n",
    "# make it dynamic so the SEP time to match can be changed to peak time or else and the time to look back for matching is variable\n",
    "# in DONKI cme dataset, take the DONKI date (as donki time), and in pf10th10 dataset, take the onset time. first row (index 0) in group of 4 rows.\n",
    "# record the intensities of the SEPs.\n",
    "\n",
    "# results table has rows as CMEs\n",
    "# for matching, it can be match for one matching CME, or matching multiple SEPs then dup or matching none then blank.\n",
    "# duplicates because of multiple SEPs that match a single CME\n",
    "# additional inputs consist of the years to pay attention to: 2010 to 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# we are going to read these two files and build a dataset by matching events in these datasets. let's call  DONKI_CDAW_CMEs_original.csv as dataset A and curr_pf10th10_original.csv as dataset B. from data set A, we are interested in donki_date, latitude, longitude, donki_speed  columns for every row. For dataset B, we are interested in  datetime, intensity columns for each group of 4 rows (index with the Index column 1 to 4). We will be using datetime index 1 (first row) of a group of 4 rows to match with donki_date "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T21:59:43.406102600Z",
     "start_time": "2023-10-09T21:59:43.221103900Z"
    }
   },
   "id": "542d9db12dfcdb21"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Union, Optional\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:12:54.117785900Z",
     "start_time": "2023-10-17T18:12:53.166786900Z"
    }
   },
   "id": "ba28ba0eba4d3599"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(            donki_date            cdaw_date  ESP  2nd_order_speed_20R  \\\n 0  2010-04-03 09:54:00  2010-04-03 10:33:00    0                  661   \n 1  2010-06-13 07:32:00  2010-06-13 06:30:00    0                  435   \n 2  2010-06-20 03:18:00  2010-06-20 02:06:00    0                  548   \n 3  2010-07-03 01:30:00  2010-07-03 01:30:00    0                  447   \n 4  2010-08-01 02:42:00  2010-08-01 00:30:00    0                    0   \n \n    latitude  longitude  donki_ha  donki_speed  solar_wind_speed  Type_2_Area  \\\n 0         7        8.0        26          620             487.3            0   \n 1        17      117.0        30          500             427.5            0   \n 2       -13      -80.0        20          570             387.2            0   \n 3        -4       35.0        23          625             602.6            0   \n 4         7      -22.0        48          760             509.8            0   \n \n    ...  Max_speed_past_day  CMEs_over_1000_past_9_hrs  sunspots  \\\n 0  ...                   0                          0        24   \n 1  ...                   0                          0        25   \n 2  ...                   0                          0        18   \n 3  ...                   0                          0        13   \n 4  ...                   0                          0        24   \n \n    flare_intensity  is_ESP  ESP_formula  only_longitude_ESP  is_ESP_hw  \\\n 0     7.400000e-06       1     0.247477                   0      620.0   \n 1     1.000000e-07       0     0.000000                   0      500.0   \n 2     1.000000e-07       0     0.000000                   0      570.0   \n 3     1.000000e-07       0     0.000000                   0      625.0   \n 4     1.000000e-07       0     0.000000                   0      760.0   \n \n    speed_times_HW  target  \n 0           16120       0  \n 1           15000       0  \n 2           11400       0  \n 3           14375       0  \n 4           36480       0  \n \n [5 rows x 75 columns],\n    Unnamed: 0    Julian Day  Year  DayOfYear  Intensity  %Rate/day  Index  \\\n 0           0  2.450011e+06  1995  293.26389    0.11119     0.0000      1   \n 1           1  2.450011e+06  1995  293.34375   10.93500    70.0420      2   \n 2           2  2.450011e+06  1995  293.51042   65.14900    11.1010      3   \n 3           3  2.450012e+06  1995  294.10417    6.93270    -4.1139      4   \n 4           4  2.450757e+06  1997  308.25347    0.16920     0.0000      1   \n \n               datetime  \n 0  1995-10-20 06:20:00  \n 1  1995-10-20 08:15:00  \n 2  1995-10-20 12:15:00  \n 3  1995-10-21 02:30:00  \n 4  1997-11-04 06:04:00  )"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset A\n",
    "dataset_a_path = '../cme_and_electron/DONKI_CDAW_CMEs_original.csv'\n",
    "dataset_a = pd.read_csv(dataset_a_path)\n",
    "\n",
    "# Read dataset B\n",
    "dataset_b_path = '../cme_and_electron/curr_pf10th10_original.csv'\n",
    "dataset_b = pd.read_csv(dataset_b_path)\n",
    "\n",
    "# Show the first few rows of each dataset to understand their structure\n",
    "dataset_a.head(), dataset_b.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:04.994862300Z",
     "start_time": "2023-10-10T03:34:04.925362400Z"
    }
   },
   "id": "a637c43b9a7b180b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Convert 'donki_date' and 'datetime' columns to datetime objects for better manipulation\n",
    "dataset_a['donki_date'] = pd.to_datetime(dataset_a['donki_date'])\n",
    "dataset_b['datetime'] = pd.to_datetime(dataset_b['datetime'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.009860700Z",
     "start_time": "2023-10-10T03:34:04.987361600Z"
    }
   },
   "id": "170371bab47d5c90"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_time_window = 180  # 3 hours in minutes\n",
    "window_limit = 1000 * 60  # 24 hours in minutes\n",
    "lower_year = 2010  # inclusive\n",
    "upper_year = 2017  # inclusive\n",
    "index_to_match = 1  # index of SEP onset row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.049861700Z",
     "start_time": "2023-10-10T03:34:05.002362200Z"
    }
   },
   "id": "30490d9f5dc75db"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def filter_columns_from_dataset_a(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters out the required columns from dataset A.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataset A DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing only the required columns.\n",
    "    \"\"\"\n",
    "    return df[['donki_date', 'latitude', 'longitude', 'donki_speed']]\n",
    "\n",
    "\n",
    "def filter_and_aggregate_dataset_b(df: pd.DataFrame, index_param: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters out the required columns from dataset B and aggregates rows based on the index parameter.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataset B DataFrame.\n",
    "        index_param (int): The index parameter to group rows.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing aggregated rows and the required columns.\n",
    "    \"\"\"\n",
    "    # Filter columns\n",
    "    filtered_df = df[df['Index'] == index_param][['datetime', 'Intensity']]\n",
    "\n",
    "    return filtered_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.050363500Z",
     "start_time": "2023-10-10T03:34:05.020861400Z"
    }
   },
   "id": "93046cb546e516d7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Filter columns from dataset A\n",
    "filtered_dataset_a = filter_columns_from_dataset_a(dataset_a)\n",
    "\n",
    "# Filter and aggregate dataset B with the default index parameter of 1\n",
    "filtered_dataset_b = filter_and_aggregate_dataset_b(dataset_b, index_to_match)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.051361100Z",
     "start_time": "2023-10-10T03:34:05.037361800Z"
    }
   },
   "id": "6f695f469a0c5f2e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "            donki_date  latitude  longitude  donki_speed\n0  2010-04-03 09:54:00         7        8.0          620\n1  2010-06-13 07:32:00        17      117.0          500\n2  2010-06-20 03:18:00       -13      -80.0          570\n3  2010-07-03 01:30:00        -4       35.0          625\n4  2010-08-01 02:42:00         7      -22.0          760\n..                 ...       ...        ...          ...\n95 2011-06-23 12:39:00         2      -40.0          350\n96 2011-06-29 01:25:00       -20       60.0          490\n97 2011-07-09 00:54:00       -25      -30.0          850\n98 2011-07-09 17:42:00        20      112.0          838\n99 2011-07-21 23:18:00       -20     -131.0          608\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>donki_date</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>donki_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-04-03 09:54:00</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-06-13 07:32:00</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-06-20 03:18:00</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>570</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-07-03 01:30:00</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>625</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-08-01 02:42:00</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>760</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2011-06-23 12:39:00</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>350</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2011-06-29 01:25:00</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>2011-07-09 00:54:00</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2011-07-09 17:42:00</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>838</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2011-07-21 23:18:00</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>608</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the filtered DataFrames\n",
    "filtered_dataset_a.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.101860500Z",
     "start_time": "2023-10-10T03:34:05.049362500Z"
    }
   },
   "id": "7677dac3c190ff6d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               datetime  Intensity\n0   1995-10-20 06:20:00   0.111190\n4   1997-11-04 06:04:00   0.169200\n8   1997-11-06 12:24:00   1.751300\n12  1998-04-20 11:10:00   0.195370\n16  1998-05-02 13:50:00   0.177920\n..                  ...        ...\n380 2004-09-13 19:54:00   0.428170\n384 2004-09-19 17:35:00   0.094505\n388 2004-11-01 05:55:00   0.188800\n392 2004-11-07 17:44:00   0.758930\n396 2005-01-16 00:40:00   1.845600\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>Intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1995-10-20 06:20:00</td>\n      <td>0.111190</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1997-11-04 06:04:00</td>\n      <td>0.169200</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1997-11-06 12:24:00</td>\n      <td>1.751300</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1998-04-20 11:10:00</td>\n      <td>0.195370</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1998-05-02 13:50:00</td>\n      <td>0.177920</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>2004-09-13 19:54:00</td>\n      <td>0.428170</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>2004-09-19 17:35:00</td>\n      <td>0.094505</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>2004-11-01 05:55:00</td>\n      <td>0.188800</td>\n    </tr>\n    <tr>\n      <th>392</th>\n      <td>2004-11-07 17:44:00</td>\n      <td>0.758930</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>2005-01-16 00:40:00</td>\n      <td>1.845600</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset_b.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.203862800Z",
     "start_time": "2023-10-10T03:34:05.088361300Z"
    }
   },
   "id": "508c15857c441c70"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def populate_intensity_values(sep_datetime: str, unfiltered_seps: pd.DataFrame, index_to_match: int = 1) -> Tuple[\n",
    "    float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Populate the intensity values of \"onset\", \"threshold\", \"peak\", and \"ending\" for a given SEP event.\n",
    "    \n",
    "    Parameters:\n",
    "        sep_datetime (str): The datetime of the SEP onset.\n",
    "        unfiltered_seps (pd.DataFrame): The dataset containing SEP events.\n",
    "        index_to_match (int): The index of the SEP onset row for which to find the other intensity values.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[float, float, float, float]: The intensities of \"onset\", \"threshold\", \"peak\", and \"ending\".\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Sep datetime {sep_datetime} index_to_match: {index_to_match}')\n",
    "    # print(unfiltered_seps)\n",
    "    print(unfiltered_seps['datetime'])\n",
    "\n",
    "    # Find the SEP event that matches the given datetime and index\n",
    "    matching_sep = unfiltered_seps[\n",
    "        (unfiltered_seps['datetime'] == sep_datetime) & (unfiltered_seps['Index'] == index_to_match)]\n",
    "\n",
    "    if matching_sep.empty:\n",
    "        print(f'No matching SEP event found for {sep_datetime}')\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    else:\n",
    "        print(f'Matching SEP event found for {sep_datetime}')\n",
    "    # Find the index of the onset row for the matched SEP event\n",
    "    onset_idx = matching_sep.index[0]\n",
    "\n",
    "    # Fetch the intensities for \"onset\", \"threshold\", \"peak\", and \"ending\" stages\n",
    "    try:\n",
    "        onset = unfiltered_seps.loc[onset_idx, 'Intensity']\n",
    "        threshold = unfiltered_seps.loc[onset_idx + 1, 'Intensity']\n",
    "        peak = unfiltered_seps.loc[onset_idx + 2, 'Intensity']\n",
    "        ending = unfiltered_seps.loc[onset_idx + 3, 'Intensity']\n",
    "    except KeyError:\n",
    "        # Return NaNs if any of the required rows are missing\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    return onset, threshold, peak, ending\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.291362300Z",
     "start_time": "2023-10-10T03:34:05.204861100Z"
    }
   },
   "id": "33fadb15369d573"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "def find_matching_seps(cme_row: pd.Series, seps: pd.DataFrame,\n",
    "                       initial_time_window: int = 180, window_limit: int = 1440) -> Tuple[\n",
    "    List[pd.Series], List[int]]:\n",
    "    \"\"\"\n",
    "    Finds matching SEPs for a given CME row within a specified initial time window and expands it if no matches are found.\n",
    "    \n",
    "    Parameters:\n",
    "        cme_row (pd.Series): A row from dataset A representing a CME event.\n",
    "        seps (pd.DataFrame): Filtered dataset B containing SEP events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching CMEs to SEPs.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[pd.Series], List[int]]: The list of matching SEP rows and their time differences in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    matching_seps = []\n",
    "    matching_time_diffs = []\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (cme_row['donki_date'] - seps['datetime']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(-time_window, 0)  # Only consider negative time differences (CME before SEP)\n",
    "        matching_seps = seps[within_window]\n",
    "\n",
    "        if not matching_seps.empty:\n",
    "            matching_time_diffs = time_diffs[within_window].tolist()\n",
    "            break\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return matching_seps, matching_time_diffs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:05.629360600Z",
     "start_time": "2023-10-10T03:34:05.550860900Z"
    }
   },
   "id": "c79b35bbb7b25a9c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def find_closest_matching_seps(cme_row: pd.Series, seps: pd.DataFrame,\n",
    "                               initial_time_window: int = 180,\n",
    "                               window_limit: int = 1440) -> Tuple[pd.Series, int]:\n",
    "    \"\"\"\n",
    "    Finds the closest matching SEP for a given CME row within a specified initial time window and expands it if no matches are found.\n",
    "    Tracks already matched SEPs to avoid multiple CMEs matching to a single SEP.\n",
    "    \n",
    "    Parameters:\n",
    "        cme_row (pd.Series): A row from dataset A representing a CME event.\n",
    "        seps (pd.DataFrame): Filtered dataset B containing SEP events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching CMEs to SEPs.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.Series, int]: The closest matching SEP row and its time difference in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    closest_match = None\n",
    "    closest_time_diff = float('inf')\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (cme_row['donki_date'] - seps['datetime']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(-time_window, 0)  # Only consider negative time differences (CME before SEP)\n",
    "        matching_seps = seps[within_window]\n",
    "        matching_time_diffs = time_diffs[within_window]\n",
    "\n",
    "        if not matching_seps.empty:\n",
    "            min_time_diff_idx = matching_time_diffs.idxmin()\n",
    "            if matching_time_diffs[min_time_diff_idx] < closest_time_diff:\n",
    "                closest_time_diff = matching_time_diffs[min_time_diff_idx]\n",
    "                closest_match = matching_seps.loc[min_time_diff_idx]\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return closest_match, closest_time_diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:06.515868500Z",
     "start_time": "2023-10-10T03:34:06.495868500Z"
    }
   },
   "id": "d4346c92e983e686"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'donki_date' in dataset A: datetime64[ns]\n",
      "Data type of 'datetime' in dataset B: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "columns_for_matches = ['CME_speed', 'CME_latitude', 'CME_longitude', 'CME_time', 'SEP_onset_time', 'time_difference',\n",
    "                       'matching', 'SEP_onset_intensity', 'SEP_threshold_intensity', 'SEP_peak_intensity',\n",
    "                       'SEP_ending_intensity']\n",
    "\n",
    "# Create explicit copies after filtering based on years\n",
    "filtered_dataset_a = filtered_dataset_a.copy()\n",
    "filtered_dataset_b = filtered_dataset_b.copy()\n",
    "\n",
    "# Explicitly convert 'donki_date' and 'datetime' to datetime objects again after filtering\n",
    "filtered_dataset_a['donki_date'] = pd.to_datetime(filtered_dataset_a['donki_date'])\n",
    "filtered_dataset_b['datetime'] = pd.to_datetime(filtered_dataset_b['datetime'])\n",
    "\n",
    "# Show data types of 'donki_date' in dataset A and 'datetime' in dataset B\n",
    "print(\"Data type of 'donki_date' in dataset A:\", filtered_dataset_a['donki_date'].dtype)\n",
    "print(\"Data type of 'datetime' in dataset B:\", filtered_dataset_b['datetime'].dtype)\n",
    "\n",
    "# Add the 'year' column again\n",
    "filtered_dataset_a['year'] = filtered_dataset_a['donki_date'].dt.year\n",
    "filtered_dataset_b['year'] = filtered_dataset_b['datetime'].dt.year\n",
    "\n",
    "# Filter datasets based on year constraints\n",
    "filtered_dataset_a = filtered_dataset_a[\n",
    "    (filtered_dataset_a['year'] >= lower_year) & (filtered_dataset_a['year'] <= upper_year)]\n",
    "filtered_dataset_b = filtered_dataset_b[\n",
    "    (filtered_dataset_b['year'] >= lower_year) & (filtered_dataset_b['year'] <= upper_year)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:07.148047100Z",
     "start_time": "2023-10-10T03:34:07.100047100Z"
    }
   },
   "id": "5eb05f32aaa8bab1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "            donki_date  latitude  longitude  donki_speed  year\n0  2010-04-03 09:54:00         7        8.0          620  2010\n1  2010-06-13 07:32:00        17      117.0          500  2010\n2  2010-06-20 03:18:00       -13      -80.0          570  2010\n3  2010-07-03 01:30:00        -4       35.0          625  2010\n4  2010-08-01 02:42:00         7      -22.0          760  2010\n..                 ...       ...        ...          ...   ...\n95 2011-06-23 12:39:00         2      -40.0          350  2011\n96 2011-06-29 01:25:00       -20       60.0          490  2011\n97 2011-07-09 00:54:00       -25      -30.0          850  2011\n98 2011-07-09 17:42:00        20      112.0          838  2011\n99 2011-07-21 23:18:00       -20     -131.0          608  2011\n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>donki_date</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>donki_speed</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-04-03 09:54:00</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>620</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-06-13 07:32:00</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>500</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-06-20 03:18:00</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>570</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-07-03 01:30:00</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>625</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-08-01 02:42:00</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>760</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>2011-06-23 12:39:00</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>350</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>2011-06-29 01:25:00</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>490</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>2011-07-09 00:54:00</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>850</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2011-07-09 17:42:00</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>838</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>2011-07-21 23:18:00</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>608</td>\n      <td>2011</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print filtered_dataset_a\n",
    "filtered_dataset_a.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:07.994545900Z",
     "start_time": "2023-10-10T03:34:07.965046600Z"
    }
   },
   "id": "3c524ddd2d11f2b3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "               datetime    Intensity  year\n448 2010-08-14 10:25:00     0.123710  2010\n452 2011-03-07 21:40:00     0.154310  2011\n456 2011-03-21 06:24:00     2.721500  2011\n460 2011-06-07 06:54:00     2.196500  2011\n464 2011-08-04 03:45:00     0.198140  2011\n468 2011-08-09 08:10:00     0.351730  2011\n472 2011-09-23 15:00:00     4.978700  2011\n476 2011-10-22 12:49:00     0.135930  2011\n480 2011-11-26 08:05:00     0.139810  2011\n484 2012-01-23 04:39:00     1.471200  2012\n488 2012-01-27 18:29:00     7.033900  2012\n492 2012-03-07 02:50:00     2.270100  2012\n496 2012-03-07 22:30:00  1682.500000  2012\n500 2012-03-13 17:44:00     6.042400  2012\n504 2012-05-17 01:25:00     0.107000  2012\n508 2012-05-26 22:59:00     0.134840  2012\n512 2012-06-16 09:45:00     0.268050  2012\n516 2012-07-07 02:39:00     1.353300  2012\n520 2012-07-08 20:05:00     3.292200  2012\n524 2012-07-12 16:30:00     0.118600  2012\n528 2012-07-17 15:24:00     0.145700  2012\n532 2012-07-19 01:45:00     5.238900  2012\n536 2012-09-01 01:39:00     0.301350  2012\n540 2012-09-28 01:14:00     0.194640  2012\n544 2013-03-16 09:00:00     4.528500  2013\n548 2013-04-11 07:59:00     0.105930  2013\n552 2013-05-15 05:55:00     0.987320  2013\n556 2013-05-22 13:25:00     0.104340  2013\n560 2013-09-30 00:04:00     0.119930  2013\n564 2013-12-28 18:24:00     0.098784  2013\n568 2014-01-06 08:05:00     0.164860  2014\n572 2014-01-06 12:20:00    40.008000  2014\n576 2014-02-20 07:39:00     0.294570  2014\n580 2014-02-20 07:39:00     0.294570  2014\n584 2014-02-25 03:45:00     0.113390  2014\n588 2014-04-18 13:34:00     0.094115  2014\n592 2014-09-10 19:00:00     0.775960  2014\n596 2014-11-02 18:54:00     3.480900  2014\n600 2015-06-18 04:30:00     0.156570  2015\n604 2015-06-21 19:54:00     3.810600  2015\n608 2015-06-25 16:39:00     3.641600  2015\n612 2015-10-29 03:00:00     0.132600  2015\n616 2016-01-02 00:04:00     0.136260  2016\n620 2017-07-14 04:39:00     0.591790  2017\n624 2017-09-04 22:25:00     0.242930  2017\n628 2017-09-10 15:35:00     0.527200  2017",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>Intensity</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>448</th>\n      <td>2010-08-14 10:25:00</td>\n      <td>0.123710</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>452</th>\n      <td>2011-03-07 21:40:00</td>\n      <td>0.154310</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>456</th>\n      <td>2011-03-21 06:24:00</td>\n      <td>2.721500</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>2011-06-07 06:54:00</td>\n      <td>2.196500</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>464</th>\n      <td>2011-08-04 03:45:00</td>\n      <td>0.198140</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>2011-08-09 08:10:00</td>\n      <td>0.351730</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>472</th>\n      <td>2011-09-23 15:00:00</td>\n      <td>4.978700</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>2011-10-22 12:49:00</td>\n      <td>0.135930</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>2011-11-26 08:05:00</td>\n      <td>0.139810</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2012-01-23 04:39:00</td>\n      <td>1.471200</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>2012-01-27 18:29:00</td>\n      <td>7.033900</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>2012-03-07 02:50:00</td>\n      <td>2.270100</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>2012-03-07 22:30:00</td>\n      <td>1682.500000</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>2012-03-13 17:44:00</td>\n      <td>6.042400</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>2012-05-17 01:25:00</td>\n      <td>0.107000</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>2012-05-26 22:59:00</td>\n      <td>0.134840</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>2012-06-16 09:45:00</td>\n      <td>0.268050</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>516</th>\n      <td>2012-07-07 02:39:00</td>\n      <td>1.353300</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>520</th>\n      <td>2012-07-08 20:05:00</td>\n      <td>3.292200</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>524</th>\n      <td>2012-07-12 16:30:00</td>\n      <td>0.118600</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>2012-07-17 15:24:00</td>\n      <td>0.145700</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>532</th>\n      <td>2012-07-19 01:45:00</td>\n      <td>5.238900</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>536</th>\n      <td>2012-09-01 01:39:00</td>\n      <td>0.301350</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>2012-09-28 01:14:00</td>\n      <td>0.194640</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>2013-03-16 09:00:00</td>\n      <td>4.528500</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>2013-04-11 07:59:00</td>\n      <td>0.105930</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>2013-05-15 05:55:00</td>\n      <td>0.987320</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>2013-05-22 13:25:00</td>\n      <td>0.104340</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>560</th>\n      <td>2013-09-30 00:04:00</td>\n      <td>0.119930</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>2013-12-28 18:24:00</td>\n      <td>0.098784</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>2014-01-06 08:05:00</td>\n      <td>0.164860</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>572</th>\n      <td>2014-01-06 12:20:00</td>\n      <td>40.008000</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>2014-02-20 07:39:00</td>\n      <td>0.294570</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>580</th>\n      <td>2014-02-20 07:39:00</td>\n      <td>0.294570</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>2014-02-25 03:45:00</td>\n      <td>0.113390</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>2014-04-18 13:34:00</td>\n      <td>0.094115</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>2014-09-10 19:00:00</td>\n      <td>0.775960</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>2014-11-02 18:54:00</td>\n      <td>3.480900</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>2015-06-18 04:30:00</td>\n      <td>0.156570</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>604</th>\n      <td>2015-06-21 19:54:00</td>\n      <td>3.810600</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>2015-06-25 16:39:00</td>\n      <td>3.641600</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>2015-10-29 03:00:00</td>\n      <td>0.132600</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>616</th>\n      <td>2016-01-02 00:04:00</td>\n      <td>0.136260</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>2017-07-14 04:39:00</td>\n      <td>0.591790</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>2017-09-04 22:25:00</td>\n      <td>0.242930</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>2017-09-10 15:35:00</td>\n      <td>0.527200</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print filtered_dataset_b\n",
    "filtered_dataset_b.head(n=100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:08.373046900Z",
     "start_time": "2023-10-10T03:34:08.349056800Z"
    }
   },
   "id": "5605f2ed7d5fe240"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Reinitialize an empty DataFrame for storing matches\n",
    "matches_CME_SEPs = pd.DataFrame(columns=columns_for_matches)\n",
    "# empty list of new rows\n",
    "new_rows = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:09.452557500Z",
     "start_time": "2023-10-10T03:34:09.441057400Z"
    }
   },
   "id": "a21b3a2ce2c704e9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2010-08-14 10:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2010-08-14 10:25:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-03-07 21:40:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-03-07 21:40:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-03-07 21:40:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-03-07 21:40:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-03-21 06:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-03-21 06:24:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-06-07 06:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-06-07 06:54:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-06-07 06:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-06-07 06:54:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-08-04 03:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-04 03:45:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-08-04 03:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-04 03:45:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-08-09 08:10:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-09 08:10:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-09-23 15:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-09-23 15:00:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-09-23 15:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-09-23 15:00:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-10-22 12:49:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-10-22 12:49:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-10-22 12:49:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-10-22 12:49:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-10-22 12:49:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-10-22 12:49:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-10-22 12:49:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-10-22 12:49:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-11-26 08:05:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-11-26 08:05:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2011-11-26 08:05:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-11-26 08:05:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-01-23 04:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-23 04:39:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-01-23 04:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-23 04:39:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-01-23 04:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-23 04:39:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-01-27 18:29:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-27 18:29:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-17 01:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-17 01:25:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-17 01:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-17 01:25:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-17 01:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-17 01:25:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-26 22:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-26 22:59:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-26 22:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-26 22:59:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-26 22:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-26 22:59:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-05-26 22:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-26 22:59:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-06-16 09:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-06-16 09:45:00\n",
      "Data type of dataset_b in new_row: datetime64[ns]\n",
      "Sep datetime 2012-06-16 09:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-06-16 09:45:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Loop through each row in dataset A to find matching SEPs from dataset B\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, cme_row \u001B[38;5;129;01min\u001B[39;00m filtered_dataset_a\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m----> 3\u001B[0m     matching_seps, matching_time_diffs \u001B[38;5;241m=\u001B[39m \u001B[43mfind_matching_seps\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcme_row\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiltered_dataset_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_time_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow_limit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# Prepare data for new row in matches_CME_SEPs\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     new_row \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCME_speed\u001B[39m\u001B[38;5;124m'\u001B[39m: cme_row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdonki_speed\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCME_latitude\u001B[39m\u001B[38;5;124m'\u001B[39m: cme_row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSEP_ending_intensity\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mnan\n\u001B[0;32m     19\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[10], line 23\u001B[0m, in \u001B[0;36mfind_matching_seps\u001B[1;34m(cme_row, seps, initial_time_window, window_limit)\u001B[0m\n\u001B[0;32m     21\u001B[0m time_diffs \u001B[38;5;241m=\u001B[39m (cme_row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdonki_date\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m seps[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatetime\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mtotal_seconds() \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m60\u001B[39m  \u001B[38;5;66;03m# Time difference in minutes\u001B[39;00m\n\u001B[0;32m     22\u001B[0m within_window \u001B[38;5;241m=\u001B[39m time_diffs\u001B[38;5;241m.\u001B[39mbetween(\u001B[38;5;241m-\u001B[39mtime_window, \u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# Only consider negative time differences (CME before SEP)\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m matching_seps \u001B[38;5;241m=\u001B[39m \u001B[43mseps\u001B[49m\u001B[43m[\u001B[49m\u001B[43mwithin_window\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m matching_seps\u001B[38;5;241m.\u001B[39mempty:\n\u001B[0;32m     26\u001B[0m     matching_time_diffs \u001B[38;5;241m=\u001B[39m time_diffs[within_window]\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\frame.py:3752\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3750\u001B[0m \u001B[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001B[39;00m\n\u001B[0;32m   3751\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m com\u001B[38;5;241m.\u001B[39mis_bool_indexer(key):\n\u001B[1;32m-> 3752\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_bool_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3754\u001B[0m \u001B[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001B[39;00m\n\u001B[0;32m   3755\u001B[0m \u001B[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001B[39;00m\n\u001B[0;32m   3756\u001B[0m is_single_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_list_like(key)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\frame.py:3811\u001B[0m, in \u001B[0;36mDataFrame._getitem_bool_array\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   3810\u001B[0m indexer \u001B[38;5;241m=\u001B[39m key\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m-> 3811\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_take_with_is_copy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\generic.py:3948\u001B[0m, in \u001B[0;36mNDFrame._take_with_is_copy\u001B[1;34m(self, indices, axis)\u001B[0m\n\u001B[0;32m   3940\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_take_with_is_copy\u001B[39m(\u001B[38;5;28mself\u001B[39m: NDFrameT, indices, axis: Axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NDFrameT:\n\u001B[0;32m   3941\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3942\u001B[0m \u001B[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001B[39;00m\n\u001B[0;32m   3943\u001B[0m \u001B[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3946\u001B[0m \u001B[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001B[39;00m\n\u001B[0;32m   3947\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3948\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_take\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3949\u001B[0m     \u001B[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001B[39;00m\n\u001B[0;32m   3950\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result\u001B[38;5;241m.\u001B[39m_get_axis(axis)\u001B[38;5;241m.\u001B[39mequals(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_axis(axis)):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\generic.py:3932\u001B[0m, in \u001B[0;36mNDFrame._take\u001B[1;34m(self, indices, axis, convert_indices)\u001B[0m\n\u001B[0;32m   3924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3925\u001B[0m         axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   3926\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m indices\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   3927\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write()\n\u001B[0;32m   3928\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m is_range_indexer(indices, \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m))\n\u001B[0;32m   3929\u001B[0m     ):\n\u001B[0;32m   3930\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 3932\u001B[0m new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3933\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3934\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_block_manager_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3935\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   3936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3937\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3938\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtake\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001B[0m, in \u001B[0;36mBaseBlockManager.take\u001B[1;34m(self, indexer, axis, verify, convert_indices)\u001B[0m\n\u001B[0;32m    960\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m maybe_convert_indices(indexer, n, verify\u001B[38;5;241m=\u001B[39mverify)\n\u001B[0;32m    962\u001B[0m new_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes[axis]\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m--> 963\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreindex_indexer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnew_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindexer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    967\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_dups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aip\\lib\\site-packages\\pandas\\core\\internals\\managers.py:765\u001B[0m, in \u001B[0;36mBaseBlockManager.reindex_indexer\u001B[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    763\u001B[0m     \u001B[38;5;66;03m# We can avoid the need to rebuild these\u001B[39;00m\n\u001B[0;32m    764\u001B[0m     new_mgr\u001B[38;5;241m.\u001B[39m_blknos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblknos\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m--> 765\u001B[0m     new_mgr\u001B[38;5;241m.\u001B[39m_blklocs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblklocs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    766\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_mgr\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through each row in dataset A to find matching SEPs from dataset B\n",
    "for idx, cme_row in filtered_dataset_a.iterrows():\n",
    "    matching_seps, matching_time_diffs = find_matching_seps(\n",
    "        cme_row, filtered_dataset_b, initial_time_window, window_limit)\n",
    "\n",
    "    # Prepare data for new row in matches_CME_SEPs\n",
    "    new_row = {\n",
    "        'CME_speed': cme_row['donki_speed'],\n",
    "        'CME_latitude': cme_row['latitude'],\n",
    "        'CME_longitude': cme_row['longitude'],\n",
    "        'CME_time': cme_row['donki_date'],\n",
    "        'SEP_onset_time': np.nan,\n",
    "        'time_difference': np.nan,\n",
    "        'matching': '',\n",
    "        'SEP_onset_intensity': np.nan,\n",
    "        'SEP_threshold_intensity': np.nan,\n",
    "        'SEP_peak_intensity': np.nan,\n",
    "        'SEP_ending_intensity': np.nan\n",
    "    }\n",
    "\n",
    "    if len(matching_seps) > 0:\n",
    "        # Populate fields if matches are found\n",
    "        if len(matching_seps) > 1:\n",
    "            new_row['matching'] = 'dup'\n",
    "        else:\n",
    "            new_row['matching'] = 'match'\n",
    "\n",
    "        # Use the closest match for other fields\n",
    "        closest_match = matching_seps.iloc[0]\n",
    "        closest_match_time_diff = matching_time_diffs[0]\n",
    "\n",
    "        # print(\"Data type of 'datetime' in closest_match:\", type(closest_match['datetime']))\n",
    "\n",
    "        new_row.update({\n",
    "            'SEP_onset_time': closest_match['datetime'],\n",
    "            'time_difference': closest_match_time_diff\n",
    "        })\n",
    "\n",
    "        print('Data type of dataset_b in new_row:', dataset_b['datetime'].dtype)\n",
    "\n",
    "        # Find the intensities at indices 1-4 for the matched SEP\n",
    "        onset, threshold, peak, ending = populate_intensity_values(closest_match['datetime'], dataset_b, index_to_match)\n",
    "        new_row.update({\n",
    "            'SEP_onset_intensity': onset,\n",
    "            'SEP_threshold_intensity': threshold,\n",
    "            'SEP_peak_intensity': peak,\n",
    "            'SEP_ending_intensity': ending\n",
    "        })\n",
    "\n",
    "    # Add the new row to the list\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Use pd.concat to add all new rows to matches_CME_SEPs\n",
    "matches_CME_SEPs = pd.DataFrame(new_rows, columns=columns_for_matches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:16:46.971608500Z",
     "start_time": "2023-10-10T03:16:36.236106600Z"
    }
   },
   "id": "c61acf480c876a2c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    CME_speed  CME_latitude  CME_longitude            CME_time SEP_onset_time  \\\n0         620             7            8.0 2010-04-03 09:54:00            NaT   \n1         500            17          117.0 2010-06-13 07:32:00            NaT   \n2         570           -13          -80.0 2010-06-20 03:18:00            NaT   \n3         625            -4           35.0 2010-07-03 01:30:00            NaT   \n4         760             7          -22.0 2010-08-01 02:42:00            NaT   \n..        ...           ...            ...                 ...            ...   \n95        350             2          -40.0 2011-06-23 12:39:00            NaT   \n96        490           -20           60.0 2011-06-29 01:25:00            NaT   \n97        850           -25          -30.0 2011-07-09 00:54:00            NaT   \n98        838            20          112.0 2011-07-09 17:42:00            NaT   \n99        608           -20         -131.0 2011-07-21 23:18:00            NaT   \n\n    time_difference matching  SEP_onset_intensity  SEP_threshold_intensity  \\\n0               NaN                           NaN                      NaN   \n1               NaN                           NaN                      NaN   \n2               NaN                           NaN                      NaN   \n3               NaN                           NaN                      NaN   \n4               NaN                           NaN                      NaN   \n..              ...      ...                  ...                      ...   \n95              NaN                           NaN                      NaN   \n96              NaN                           NaN                      NaN   \n97              NaN                           NaN                      NaN   \n98              NaN                           NaN                      NaN   \n99              NaN                           NaN                      NaN   \n\n    SEP_peak_intensity  SEP_ending_intensity  \n0                  NaN                   NaN  \n1                  NaN                   NaN  \n2                  NaN                   NaN  \n3                  NaN                   NaN  \n4                  NaN                   NaN  \n..                 ...                   ...  \n95                 NaN                   NaN  \n96                 NaN                   NaN  \n97                 NaN                   NaN  \n98                 NaN                   NaN  \n99                 NaN                   NaN  \n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CME_speed</th>\n      <th>CME_latitude</th>\n      <th>CME_longitude</th>\n      <th>CME_time</th>\n      <th>SEP_onset_time</th>\n      <th>time_difference</th>\n      <th>matching</th>\n      <th>SEP_onset_intensity</th>\n      <th>SEP_threshold_intensity</th>\n      <th>SEP_peak_intensity</th>\n      <th>SEP_ending_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>620</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>2010-04-03 09:54:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>2010-06-13 07:32:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>2010-06-20 03:18:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>2010-07-03 01:30:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>760</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>2010-08-01 02:42:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>350</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>2011-06-23 12:39:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>490</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>2011-06-29 01:25:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>850</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>2011-07-09 00:54:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>838</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>2011-07-09 17:42:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>608</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>2011-07-21 23:18:00</td>\n      <td>NaT</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the matches_CME_SEPs DataFrame\n",
    "matches_CME_SEPs.head(100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T21:59:56.277604100Z",
     "start_time": "2023-10-09T21:59:56.224106100Z"
    }
   },
   "id": "5e4fb4fc86cafb45"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35b433b8b435716e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Save the matches_CME_SEPs DataFrame to a CSV file\n",
    "csv_file_path = '../cme_and_electron/matches_CME_SEPs.csv'\n",
    "matches_CME_SEPs.to_csv(csv_file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:52.571451300Z",
     "start_time": "2023-10-10T03:34:52.531951400Z"
    }
   },
   "id": "1d7e5a0a41e73045"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# to get the exact amount of SEPs , i will have to go by SEPs to CMEs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb2a5a99e83387b4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def find_closest_cme(sep_row: pd.Series, cmes: pd.DataFrame,\n",
    "                     initial_time_window: int = 180, window_limit: int = 1440) -> Tuple[\n",
    "    Union[pd.Series, None], Union[float, None]]:\n",
    "    \"\"\"\n",
    "    Finds the closest matching CME for a given SEP row within a specified initial time window and expands it if no matches are found.\n",
    "    \n",
    "    Parameters:\n",
    "        sep_row (pd.Series): A row from dataset B representing an SEP event.\n",
    "        cmes (pd.DataFrame): Filtered dataset A containing CME events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching SEP to CME.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Union[pd.Series, None], Union[float, None]]: The closest matching CME row and the time difference in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    closest_cme = None\n",
    "    closest_time_diff = None\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (sep_row['datetime'] - cmes['donki_date']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(0, time_window)  # Only consider positive time differences (SEP after CME)\n",
    "\n",
    "        if within_window.sum() > 0:\n",
    "            # Find the closest match within the time window\n",
    "            closest_cme_idx = time_diffs[within_window].idxmin()\n",
    "            closest_cme = cmes.loc[closest_cme_idx]\n",
    "            closest_time_diff = time_diffs[closest_cme_idx]\n",
    "            break\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return closest_cme, closest_time_diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:15.170208600Z",
     "start_time": "2023-10-10T03:34:15.148710200Z"
    }
   },
   "id": "6f14d5fd5cc2cb95"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest time difference for SEP 2010-08-14 10:25:00 is 13.0\n",
      "Closest time difference for SEP 2011-03-07 21:40:00 is 88.0\n",
      "Closest time difference for SEP 2011-03-21 06:24:00 is 210.0\n",
      "Closest time difference for SEP 2011-06-07 06:54:00 is 4.0\n",
      "Closest time difference for SEP 2011-08-04 03:45:00 is 830.0\n",
      "Closest time difference for SEP 2011-08-09 08:10:00 is 850.0\n",
      "Closest time difference for SEP 2011-09-23 15:00:00 is 1656.0\n",
      "Closest time difference for SEP 2011-10-22 12:49:00 is 89.0\n",
      "Closest time difference for SEP 2011-11-26 08:05:00 is 53.0\n",
      "Closest time difference for SEP 2012-01-23 04:39:00 is 39.0\n",
      "Closest time difference for SEP 2012-01-27 18:29:00 is 110.0\n",
      "Closest time difference for SEP 2012-03-07 02:50:00 is 134.0\n",
      "Closest time difference for SEP 2012-03-07 22:30:00 is 1314.0\n",
      "Closest time difference for SEP 2012-03-13 17:44:00 is 9668.0\n",
      "Closest time difference for SEP 2012-05-17 01:25:00 is 1366.0\n",
      "Closest time difference for SEP 2012-05-26 22:59:00 is 5.0\n",
      "Closest time difference for SEP 2012-06-16 09:45:00 is 1149.0\n",
      "Closest time difference for SEP 2012-07-07 02:39:00 is 207.0\n",
      "Closest time difference for SEP 2012-07-08 20:05:00 is 53.0\n",
      "Closest time difference for SEP 2012-07-12 16:30:00 is 1281.0\n",
      "Closest time difference for SEP 2012-07-17 15:24:00 is 60.0\n",
      "Closest time difference for SEP 2012-07-19 01:45:00 is 2121.0\n",
      "Closest time difference for SEP 2012-09-01 01:39:00 is 303.0\n",
      "Closest time difference for SEP 2012-09-28 01:14:00 is 890.0\n",
      "Closest time difference for SEP 2013-03-16 09:00:00 is 1566.0\n",
      "Closest time difference for SEP 2013-04-11 07:59:00 is 23.0\n",
      "Closest time difference for SEP 2013-05-15 05:55:00 is 217.0\n",
      "Closest time difference for SEP 2013-05-22 13:25:00 is 1.0\n",
      "Closest time difference for SEP 2013-09-30 00:04:00 is 84.0\n",
      "Closest time difference for SEP 2013-12-28 18:24:00 is 24.0\n",
      "Closest time difference for SEP 2014-01-06 08:05:00 is 1361.0\n",
      "Closest time difference for SEP 2014-01-06 12:20:00 is 251.0\n",
      "Closest time difference for SEP 2014-02-20 07:39:00 is 267.0\n",
      "Closest time difference for SEP 2014-02-20 07:39:00 is 267.0\n",
      "Closest time difference for SEP 2014-02-25 03:45:00 is 140.0\n",
      "Closest time difference for SEP 2014-04-18 13:34:00 is 25.0\n",
      "Closest time difference for SEP 2014-09-10 19:00:00 is 42.0\n",
      "Closest time difference for SEP 2014-11-02 18:54:00 is 510.0\n",
      "Closest time difference for SEP 2015-06-18 04:30:00 is 185.0\n",
      "Closest time difference for SEP 2015-06-21 19:54:00 is 1026.0\n",
      "Closest time difference for SEP 2015-06-25 16:39:00 is 483.0\n",
      "Closest time difference for SEP 2015-10-29 03:00:00 is 12.0\n",
      "Closest time difference for SEP 2016-01-02 00:04:00 is 52.0\n",
      "Closest time difference for SEP 2017-07-14 04:39:00 is 183.0\n",
      "Closest time difference for SEP 2017-09-04 22:25:00 is 166.0\n",
      "Closest time difference for SEP 2017-09-10 15:35:00 is 8396.0\n",
      "Sep datetime 2010-08-14 10:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2010-08-14 10:25:00\n",
      "Sep datetime 2011-03-07 21:40:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-03-07 21:40:00\n",
      "Sep datetime 2011-03-21 06:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-03-21 06:24:00\n",
      "Sep datetime 2011-06-07 06:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-06-07 06:54:00\n",
      "Sep datetime 2011-08-04 03:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-04 03:45:00\n",
      "Sep datetime 2011-08-09 08:10:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-09 08:10:00\n",
      "Sep datetime 2011-09-23 15:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-09-23 15:00:00\n",
      "Sep datetime 2011-10-22 12:49:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-10-22 12:49:00\n",
      "Sep datetime 2011-11-26 08:05:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-11-26 08:05:00\n",
      "Sep datetime 2012-01-23 04:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-23 04:39:00\n",
      "Sep datetime 2012-01-27 18:29:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-27 18:29:00\n",
      "Sep datetime 2012-03-07 02:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 02:50:00\n",
      "Sep datetime 2012-03-07 22:30:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-07 22:30:00\n",
      "Sep datetime 2012-03-13 17:44:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-13 17:44:00\n",
      "Sep datetime 2012-05-17 01:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-17 01:25:00\n",
      "Sep datetime 2012-05-26 22:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-05-26 22:59:00\n",
      "Sep datetime 2012-06-16 09:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-06-16 09:45:00\n",
      "Sep datetime 2012-07-07 02:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-07-07 02:39:00\n",
      "Sep datetime 2012-07-08 20:05:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-07-08 20:05:00\n",
      "Sep datetime 2012-07-12 16:30:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-07-12 16:30:00\n",
      "Sep datetime 2012-07-17 15:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-07-17 15:24:00\n",
      "Sep datetime 2012-07-19 01:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-07-19 01:45:00\n",
      "Sep datetime 2012-09-01 01:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-09-01 01:39:00\n",
      "Sep datetime 2012-09-28 01:14:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-09-28 01:14:00\n",
      "Sep datetime 2013-03-16 09:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-03-16 09:00:00\n",
      "Sep datetime 2013-04-11 07:59:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-04-11 07:59:00\n",
      "Sep datetime 2013-05-15 05:55:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-05-15 05:55:00\n",
      "Sep datetime 2013-05-22 13:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-05-22 13:25:00\n",
      "Sep datetime 2013-09-30 00:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-09-30 00:04:00\n",
      "Sep datetime 2013-12-28 18:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-12-28 18:24:00\n",
      "Sep datetime 2014-01-06 08:05:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-01-06 08:05:00\n",
      "Sep datetime 2014-01-06 12:20:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-01-06 12:20:00\n",
      "Sep datetime 2014-02-20 07:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-02-20 07:39:00\n",
      "Sep datetime 2014-02-20 07:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-02-20 07:39:00\n",
      "Sep datetime 2014-02-25 03:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-02-25 03:45:00\n",
      "Sep datetime 2014-04-18 13:34:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-04-18 13:34:00\n",
      "Sep datetime 2014-09-10 19:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-09-10 19:00:00\n",
      "Sep datetime 2014-11-02 18:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-11-02 18:54:00\n",
      "Sep datetime 2015-06-18 04:30:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-06-18 04:30:00\n",
      "Sep datetime 2015-06-21 19:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-06-21 19:54:00\n",
      "Sep datetime 2015-06-25 16:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-06-25 16:39:00\n",
      "Sep datetime 2015-10-29 03:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-10-29 03:00:00\n",
      "Sep datetime 2016-01-02 00:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2016-01-02 00:04:00\n",
      "Sep datetime 2017-07-14 04:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2017-07-14 04:39:00\n",
      "Sep datetime 2017-09-04 22:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2017-09-04 22:25:00\n",
      "Sep datetime 2017-09-10 15:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 08:15:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 02:30:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "627   2017-09-09 02:44:00\n",
      "628   2017-09-10 15:35:00\n",
      "629   2017-09-10 16:50:00\n",
      "630   2017-09-11 11:50:00\n",
      "631   2017-09-14 20:05:00\n",
      "Name: datetime, Length: 632, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2017-09-10 15:35:00\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Pre-populate target table with all CMEs\n",
    "new_rows = []\n",
    "for idx, cme_row in filtered_dataset_a.iterrows():\n",
    "    new_row = {\n",
    "        'CME_speed': cme_row['donki_speed'],\n",
    "        'CME_latitude': cme_row['latitude'],\n",
    "        'CME_longitude': cme_row['longitude'],\n",
    "        'CME_time': cme_row['donki_date'],\n",
    "        'SEP_onset_time': np.nan,\n",
    "        'time_difference': np.nan,\n",
    "        'matching': '',\n",
    "        'SEP_onset_intensity': np.nan,\n",
    "        'SEP_threshold_intensity': np.nan,\n",
    "        'SEP_peak_intensity': np.nan,\n",
    "        'SEP_ending_intensity': np.nan\n",
    "    }\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "matches_CME_SEPs = pd.DataFrame(new_rows, columns=columns_for_matches)\n",
    "\n",
    "# Step 2 & 3: Find closest matching CME for each SEP and update the target table\n",
    "closest_cmes_for_seps = {}  # To keep track of closest CMEs for each SEP\n",
    "\n",
    "for idx, sep_row in filtered_dataset_b.iterrows():\n",
    "    closest_cme, closest_time_diff = find_closest_cme(sep_row, filtered_dataset_a, initial_time_window, window_limit)\n",
    "    sep_id = sep_row['datetime']\n",
    "\n",
    "    print(f'Closest time difference for SEP {sep_id} is {closest_time_diff}')\n",
    "\n",
    "    if closest_cme is not None:\n",
    "        cme_id = closest_cme['donki_date']\n",
    "        # Check if this CME is already the closest match for another SEP\n",
    "        if cme_id in closest_cmes_for_seps:\n",
    "            closest_cmes_for_seps[cme_id]['matching'] = 'dup'\n",
    "            closest_cmes_for_seps[cme_id]['SEPs'].append({'sep': sep_row, 'time_diff': closest_time_diff})\n",
    "        else:\n",
    "            closest_cmes_for_seps[cme_id] = {'matching': 'match',\n",
    "                                             'SEPs': [{'sep': sep_row, 'time_diff': closest_time_diff}]}\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for cme_id, cme_info in closest_cmes_for_seps.items():\n",
    "    # Get CME details from the original DataFrame\n",
    "    cme_details = matches_CME_SEPs.loc[matches_CME_SEPs['CME_time'] == cme_id].iloc[0]\n",
    "\n",
    "    # Loop through all SEPs that have this CME as the closest match\n",
    "    for sep_info in cme_info['SEPs']:\n",
    "        closest_sep = sep_info['sep']\n",
    "        closest_time_diff = sep_info['time_diff']\n",
    "\n",
    "        onset, threshold, peak, ending = populate_intensity_values(closest_sep['datetime'], dataset_b, index_to_match)\n",
    "\n",
    "        updated_values = {\n",
    "            'SEP_onset_time': closest_sep['datetime'],\n",
    "            'time_difference': -closest_time_diff,\n",
    "            'matching': cme_info['matching'],\n",
    "            'SEP_onset_intensity': onset,\n",
    "            'SEP_threshold_intensity': threshold,\n",
    "            'SEP_peak_intensity': peak,\n",
    "            'SEP_ending_intensity': ending\n",
    "        }\n",
    "\n",
    "        if cme_info['matching'] == 'dup':\n",
    "            # Create a new row with CME details and new SEP details\n",
    "            new_row = cme_details.copy()\n",
    "            new_row.update(updated_values)\n",
    "            new_rows.append(new_row)\n",
    "        else:\n",
    "            # Update the existing row in the DataFrame\n",
    "            matches_CME_SEPs.loc[matches_CME_SEPs['CME_time'] == cme_id, updated_values.keys()] = list(\n",
    "                updated_values.values())\n",
    "\n",
    "# Convert the list of new rows to a DataFrame and concatenate it with the original DataFrame\n",
    "if new_rows:\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    matches_CME_SEPs = pd.concat([matches_CME_SEPs, new_rows_df], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:22.631836900Z",
     "start_time": "2023-10-10T03:34:21.932337Z"
    }
   },
   "id": "dcf5f05173315764"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    CME_speed  CME_latitude  CME_longitude            CME_time SEP_onset_time  \\\n0         620             7            8.0 2010-04-03 09:54:00            NaN   \n1         500            17          117.0 2010-06-13 07:32:00            NaN   \n2         570           -13          -80.0 2010-06-20 03:18:00            NaN   \n3         625            -4           35.0 2010-07-03 01:30:00            NaN   \n4         760             7          -22.0 2010-08-01 02:42:00            NaN   \n..        ...           ...            ...                 ...            ...   \n95        350             2          -40.0 2011-06-23 12:39:00            NaN   \n96        490           -20           60.0 2011-06-29 01:25:00            NaN   \n97        850           -25          -30.0 2011-07-09 00:54:00            NaN   \n98        838            20          112.0 2011-07-09 17:42:00            NaN   \n99        608           -20         -131.0 2011-07-21 23:18:00            NaN   \n\n    time_difference matching  SEP_onset_intensity  SEP_threshold_intensity  \\\n0               NaN                           NaN                      NaN   \n1               NaN                           NaN                      NaN   \n2               NaN                           NaN                      NaN   \n3               NaN                           NaN                      NaN   \n4               NaN                           NaN                      NaN   \n..              ...      ...                  ...                      ...   \n95              NaN                           NaN                      NaN   \n96              NaN                           NaN                      NaN   \n97              NaN                           NaN                      NaN   \n98              NaN                           NaN                      NaN   \n99              NaN                           NaN                      NaN   \n\n    SEP_peak_intensity  SEP_ending_intensity  \n0                  NaN                   NaN  \n1                  NaN                   NaN  \n2                  NaN                   NaN  \n3                  NaN                   NaN  \n4                  NaN                   NaN  \n..                 ...                   ...  \n95                 NaN                   NaN  \n96                 NaN                   NaN  \n97                 NaN                   NaN  \n98                 NaN                   NaN  \n99                 NaN                   NaN  \n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CME_speed</th>\n      <th>CME_latitude</th>\n      <th>CME_longitude</th>\n      <th>CME_time</th>\n      <th>SEP_onset_time</th>\n      <th>time_difference</th>\n      <th>matching</th>\n      <th>SEP_onset_intensity</th>\n      <th>SEP_threshold_intensity</th>\n      <th>SEP_peak_intensity</th>\n      <th>SEP_ending_intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>620</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>2010-04-03 09:54:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>2010-06-13 07:32:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>2010-06-20 03:18:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>2010-07-03 01:30:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>760</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>2010-08-01 02:42:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>350</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>2011-06-23 12:39:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>490</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>2011-06-29 01:25:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>850</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>2011-07-09 00:54:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>838</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>2011-07-09 17:42:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>608</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>2011-07-21 23:18:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_CME_SEPs.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T03:34:26.232346300Z",
     "start_time": "2023-10-10T03:34:26.175846Z"
    }
   },
   "id": "60856113ce7ce24f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finding Elevated Events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d894b2a5449064"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(   CME_speed  CME_latitude  CME_longitude        CME_time SEP_onset_time  \\\n 0        620             7            8.0   4/3/2010 9:54            NaN   \n 1        500            17          117.0  6/13/2010 7:32            NaN   \n 2        570           -13          -80.0  6/20/2010 3:18            NaN   \n 3        625            -4           35.0   7/3/2010 1:30            NaN   \n 4        760             7          -22.0   8/1/2010 2:42            NaN   \n \n    time_difference matching  SEP_peak_intensity Unnamed: 8  \n 0              NaN      NaN                 NaN        NaN  \n 1              NaN      NaN                 NaN        NaN  \n 2              NaN      NaN                 NaN        NaN  \n 3              NaN      NaN                 NaN        NaN  \n 4              NaN      NaN                 NaN        NaN  ,\n    Unnamed: 0    Julian Day  Year  DayOfYear  Intensity  %Rate/day  Index  \\\n 0           0  2.450011e+06  1995  293.26389    0.11119      0.000      1   \n 1           1  2.450011e+06  1995  293.31944    1.53060     66.660      2   \n 2           2  2.450011e+06  1995  293.51042   65.14900     11.101      3   \n 3           3  2.450012e+06  1995  294.81944    0.93392    -13.740      4   \n 4           4  2.450757e+06  1997  308.25347    0.16920      0.000      1   \n \n               datetime  \n 0  1995-10-20 06:20:00  \n 1  1995-10-20 07:39:00  \n 2  1995-10-20 12:15:00  \n 3  1995-10-21 19:39:00  \n 4  1997-11-04 06:04:00  )"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset A\n",
    "dataset_a_path = '../cme_and_electron/matches_CME_SEPs - curated - updated.csv'\n",
    "dataset_a = pd.read_csv(dataset_a_path)\n",
    "\n",
    "# Read dataset B\n",
    "dataset_b_path = '../cme_and_electron/curr_pf10th10re2.csv'\n",
    "dataset_b = pd.read_csv(dataset_b_path)\n",
    "\n",
    "# Show the first few rows of each dataset to understand their structure\n",
    "dataset_a.head(), dataset_b.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:04.940769Z",
     "start_time": "2023-10-17T18:13:04.711271900Z"
    }
   },
   "id": "346f3da799707a0c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Convert 'donki_date' and 'datetime' columns to datetime objects for better manipulation\n",
    "dataset_a['CME_time'] = pd.to_datetime(dataset_a['CME_time'])\n",
    "dataset_b['datetime'] = pd.to_datetime(dataset_b['datetime'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:08.402203100Z",
     "start_time": "2023-10-17T18:13:08.288704600Z"
    }
   },
   "id": "805c61bfd52b3c19"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "initial_time_window = 180  # 3 hours in minutes\n",
    "window_limit = 1000 * 60  # 24 hours in minutes\n",
    "lower_year = 2010  # inclusive\n",
    "upper_year = 2017  # inclusive\n",
    "index_to_match = 1  # index of Elevated onset row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:09.518702300Z",
     "start_time": "2023-10-17T18:13:09.456204300Z"
    }
   },
   "id": "8180eb481f51423"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def filter_columns_from_dataset_a(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters out the required columns from dataset A.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataset A DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing only the required columns.\n",
    "    \"\"\"\n",
    "    return df[['CME_speed', 'CME_latitude', 'CME_longitude', 'CME_time']]\n",
    "\n",
    "\n",
    "def filter_and_aggregate_dataset_b(df: pd.DataFrame, index_param: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters out the required columns from dataset B and aggregates rows based on the index parameter.\n",
    "    Additionally, removes the group of SEPs where the 'Intensity' at 'Index' 3 is greater than or equal to 10.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The original dataset B DataFrame.\n",
    "        index_param (int): The index parameter to filter rows for onset time.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing aggregated rows and the required columns after filtering.\n",
    "    \"\"\"\n",
    "    # Step 1: Identify groups where 'Intensity' at 'Index' 3 is >= 10\n",
    "    # Since they come in groups of 4, we will check every 4th element starting from the 3rd index (0-based)\n",
    "    groups_to_remove = []\n",
    "    for i in range(2, len(df), 4):\n",
    "        if df.loc[i, 'Intensity'] >= 10:\n",
    "            groups_to_remove.extend(range(i - 2, i + 2))\n",
    "\n",
    "    # Remove identified groups\n",
    "    filtered_df = df.drop(groups_to_remove, errors='ignore')\n",
    "\n",
    "    # Step 2: Filter by 'Index' and taking only 'datetime' and 'Intensity' columns\n",
    "    filtered_df = filtered_df[filtered_df['Index'] == index_param][['datetime', 'Intensity']]\n",
    "\n",
    "    return filtered_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:10.299703900Z",
     "start_time": "2023-10-17T18:13:10.171704500Z"
    }
   },
   "id": "ca629bb8400758c6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Filter columns from dataset A\n",
    "filtered_dataset_a = filter_columns_from_dataset_a(dataset_a)\n",
    "\n",
    "# Filter and aggregate dataset B with the default index parameter of 1\n",
    "filtered_dataset_b = filter_and_aggregate_dataset_b(dataset_b, index_to_match)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:11.190703700Z",
     "start_time": "2023-10-17T18:13:11.060203900Z"
    }
   },
   "id": "e23f650bf53032df"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    CME_speed  CME_latitude  CME_longitude            CME_time\n0         620             7            8.0 2010-04-03 09:54:00\n1         500            17          117.0 2010-06-13 07:32:00\n2         570           -13          -80.0 2010-06-20 03:18:00\n3         625            -4           35.0 2010-07-03 01:30:00\n4         760             7          -22.0 2010-08-01 02:42:00\n..        ...           ...            ...                 ...\n95        350             2          -40.0 2011-06-23 12:39:00\n96        490           -20           60.0 2011-06-29 01:25:00\n97        850           -25          -30.0 2011-07-09 00:54:00\n98        838            20          112.0 2011-07-09 17:42:00\n99        608           -20         -131.0 2011-07-21 23:18:00\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CME_speed</th>\n      <th>CME_latitude</th>\n      <th>CME_longitude</th>\n      <th>CME_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>620</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>2010-04-03 09:54:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>2010-06-13 07:32:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>2010-06-20 03:18:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>2010-07-03 01:30:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>760</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>2010-08-01 02:42:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>350</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>2011-06-23 12:39:00</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>490</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>2011-06-29 01:25:00</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>850</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>2011-07-09 00:54:00</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>838</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>2011-07-09 17:42:00</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>608</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>2011-07-21 23:18:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the filtered DataFrames\n",
    "filtered_dataset_a.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:11.711204Z",
     "start_time": "2023-10-17T18:13:11.509706400Z"
    }
   },
   "id": "ff8a662431d3422a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               datetime  Intensity\n8   1997-11-13 23:30:00    0.28051\n16  1998-04-29 18:04:00    0.16804\n20  1998-05-01 03:49:00    0.67055\n36  1998-06-16 21:15:00    0.12050\n40  1998-08-22 16:09:00    0.35469\n..                  ...        ...\n824 2013-11-19 12:04:00    0.12475\n828 2013-12-14 14:44:00    0.40125\n832 2013-12-26 15:35:00    0.32855\n848 2014-02-19 04:00:00    0.14628\n860 2014-03-29 18:54:00    0.12358\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>Intensity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>1997-11-13 23:30:00</td>\n      <td>0.28051</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1998-04-29 18:04:00</td>\n      <td>0.16804</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1998-05-01 03:49:00</td>\n      <td>0.67055</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1998-06-16 21:15:00</td>\n      <td>0.12050</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1998-08-22 16:09:00</td>\n      <td>0.35469</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>2013-11-19 12:04:00</td>\n      <td>0.12475</td>\n    </tr>\n    <tr>\n      <th>828</th>\n      <td>2013-12-14 14:44:00</td>\n      <td>0.40125</td>\n    </tr>\n    <tr>\n      <th>832</th>\n      <td>2013-12-26 15:35:00</td>\n      <td>0.32855</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>2014-02-19 04:00:00</td>\n      <td>0.14628</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>2014-03-29 18:54:00</td>\n      <td>0.12358</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset_b.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:12.336206800Z",
     "start_time": "2023-10-17T18:13:12.055704500Z"
    }
   },
   "id": "1b5b0e6aaa2a6f6c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def populate_peak_intensity(sep_datetime: str, unfiltered_seps: pd.DataFrame, index_to_match: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Populate the intensity values of \"onset\", \"threshold\", \"peak\", and \"ending\" for a given SEP event.\n",
    "    \n",
    "    Parameters:\n",
    "        sep_datetime (str): The datetime of the SEP onset.\n",
    "        unfiltered_seps (pd.DataFrame): The dataset containing SEP events.\n",
    "        index_to_match (int): The index of the SEP onset row for which to find the other intensity values.\n",
    "        \n",
    "    Returns:\n",
    "       float: The intensity of \"peak\"\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Elevated datetime {sep_datetime} index_to_match: {index_to_match}')\n",
    "    # print(unfiltered_seps)\n",
    "    print(unfiltered_seps['datetime'])\n",
    "\n",
    "    # Find the SEP event that matches the given datetime and index\n",
    "    matching_sep = unfiltered_seps[\n",
    "        (unfiltered_seps['datetime'] == sep_datetime) & (unfiltered_seps['Index'] == index_to_match)]\n",
    "\n",
    "    if matching_sep.empty:\n",
    "        print(f'No matching SEP event found for {sep_datetime}')\n",
    "        return np.nan\n",
    "    else:\n",
    "        print(f'Matching SEP event found for {sep_datetime}')\n",
    "    # Find the index of the onset row for the matched SEP event\n",
    "    onset_idx = matching_sep.index[0]\n",
    "\n",
    "    # Fetch the intensities for \"onset\", \"threshold\", \"peak\", and \"ending\" stages\n",
    "    try:\n",
    "        # onset = unfiltered_seps.loc[onset_idx, 'Intensity']\n",
    "        # threshold = unfiltered_seps.loc[onset_idx + 1, 'Intensity']\n",
    "        peak = unfiltered_seps.loc[onset_idx + 2, 'Intensity']\n",
    "        # ending = unfiltered_seps.loc[onset_idx + 3, 'Intensity']\n",
    "    except KeyError:\n",
    "        # Return NaNs if any of the required rows are missing\n",
    "        return np.nan\n",
    "\n",
    "    return peak"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:12.906703700Z",
     "start_time": "2023-10-17T18:13:12.751204200Z"
    }
   },
   "id": "ac0788d6c7c901d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def find_matching_seps(cme_row: pd.Series, seps: pd.DataFrame,\n",
    "                       initial_time_window: int = 180, window_limit: int = 1440) -> Tuple[List[pd.Series], List[int]]:\n",
    "    \"\"\"\n",
    "    Finds matching SEPs for a given CME row within a specified initial time window and expands it if no matches are found.\n",
    "    \n",
    "    Parameters:\n",
    "        cme_row (pd.Series): A row from dataset A representing a CME event.\n",
    "        seps (pd.DataFrame): Filtered dataset B containing SEP events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching CMEs to SEPs.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[pd.Series], List[int]]: The list of matching SEP rows and their time differences in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    matching_seps = pd.DataFrame()\n",
    "    matching_time_diffs = []\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (cme_row['donki_date'] - seps['datetime']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(-time_window, 0)  # Only consider negative time differences (CME before SEP)\n",
    "\n",
    "        # Get the SEPs within the time window\n",
    "        potential_matches = seps[within_window]\n",
    "\n",
    "        # Filter out SEPs with peak intensity >= 10\n",
    "        matching_seps = potential_matches[potential_matches['Intensity'] < 10]\n",
    "\n",
    "        if not matching_seps.empty:\n",
    "            matching_time_diffs = time_diffs[within_window].tolist()\n",
    "            break\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return matching_seps, matching_time_diffs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:13.353703200Z",
     "start_time": "2023-10-17T18:13:13.201705800Z"
    }
   },
   "id": "f23f4c73222b7f63"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def find_closest_matching_seps(cme_row: pd.Series, seps: pd.DataFrame,\n",
    "                               initial_time_window: int = 180,\n",
    "                               window_limit: int = 1440) -> Tuple[pd.Series, int]:\n",
    "    \"\"\"\n",
    "    Finds the closest matching SEP for a given CME row within a specified initial time window and expands it if no matches are found.\n",
    "    Tracks already matched SEPs to avoid multiple CMEs matching to a single SEP.\n",
    "    \n",
    "    Parameters:\n",
    "        cme_row (pd.Series): A row from dataset A representing a CME event.\n",
    "        seps (pd.DataFrame): Filtered dataset B containing SEP events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching CMEs to SEPs.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.Series, int]: The closest matching SEP row and its time difference in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    closest_match = None\n",
    "    closest_time_diff = float('inf')\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (cme_row['donki_date'] - seps['datetime']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(-time_window, 0)  # Only consider negative time differences (CME before SEP)\n",
    "\n",
    "        # Get SEPs within the time window\n",
    "        potential_matches = seps[within_window]\n",
    "\n",
    "        # Filter out SEPs with peak intensity >= 10\n",
    "        matching_seps = potential_matches[potential_matches['Intensity'] < 10]\n",
    "        matching_time_diffs = time_diffs[within_window]\n",
    "\n",
    "        if not matching_seps.empty:\n",
    "            min_time_diff_idx = matching_time_diffs.idxmin()\n",
    "            if matching_time_diffs[min_time_diff_idx] < closest_time_diff:\n",
    "                closest_time_diff = matching_time_diffs[min_time_diff_idx]\n",
    "                closest_match = matching_seps.loc[min_time_diff_idx]\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return closest_match, closest_time_diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:16.055322200Z",
     "start_time": "2023-10-17T18:13:15.963824600Z"
    }
   },
   "id": "1e8e97d91c239a97"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'donki_date' in dataset A: datetime64[ns]\n",
      "Data type of 'datetime' in dataset B: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "columns_for_matches = ['CME_speed', 'CME_latitude', 'CME_longitude', 'CME_time', 'SEP_onset_time', 'time_difference',\n",
    "                       'matching', 'SEP_peak_intensity']\n",
    "\n",
    "# Create explicit copies after filtering based on years\n",
    "filtered_dataset_a = filtered_dataset_a.copy()\n",
    "filtered_dataset_b = filtered_dataset_b.copy()\n",
    "\n",
    "# Explicitly convert 'donki_date' and 'datetime' to datetime objects again after filtering\n",
    "filtered_dataset_a['CME_time'] = pd.to_datetime(filtered_dataset_a['CME_time'])\n",
    "filtered_dataset_b['datetime'] = pd.to_datetime(filtered_dataset_b['datetime'])\n",
    "\n",
    "# Show data types of 'donki_date' in dataset A and 'datetime' in dataset B\n",
    "print(\"Data type of 'donki_date' in dataset A:\", filtered_dataset_a['CME_time'].dtype)\n",
    "print(\"Data type of 'datetime' in dataset B:\", filtered_dataset_b['datetime'].dtype)\n",
    "\n",
    "# Add the 'year' column again\n",
    "filtered_dataset_a['year'] = filtered_dataset_a['CME_time'].dt.year\n",
    "filtered_dataset_b['year'] = filtered_dataset_b['datetime'].dt.year\n",
    "\n",
    "# Filter datasets based on year constraints\n",
    "filtered_dataset_a = filtered_dataset_a[\n",
    "    (filtered_dataset_a['year'] >= lower_year) & (filtered_dataset_a['year'] <= upper_year)]\n",
    "filtered_dataset_b = filtered_dataset_b[\n",
    "    (filtered_dataset_b['year'] >= lower_year) & (filtered_dataset_b['year'] <= upper_year)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:16.872822500Z",
     "start_time": "2023-10-17T18:13:16.707322700Z"
    }
   },
   "id": "31ca8c7a92945b7d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    CME_speed  CME_latitude  CME_longitude            CME_time  year\n0         620             7            8.0 2010-04-03 09:54:00  2010\n1         500            17          117.0 2010-06-13 07:32:00  2010\n2         570           -13          -80.0 2010-06-20 03:18:00  2010\n3         625            -4           35.0 2010-07-03 01:30:00  2010\n4         760             7          -22.0 2010-08-01 02:42:00  2010\n..        ...           ...            ...                 ...   ...\n95        350             2          -40.0 2011-06-23 12:39:00  2011\n96        490           -20           60.0 2011-06-29 01:25:00  2011\n97        850           -25          -30.0 2011-07-09 00:54:00  2011\n98        838            20          112.0 2011-07-09 17:42:00  2011\n99        608           -20         -131.0 2011-07-21 23:18:00  2011\n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CME_speed</th>\n      <th>CME_latitude</th>\n      <th>CME_longitude</th>\n      <th>CME_time</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>620</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>2010-04-03 09:54:00</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500</td>\n      <td>17</td>\n      <td>117.0</td>\n      <td>2010-06-13 07:32:00</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570</td>\n      <td>-13</td>\n      <td>-80.0</td>\n      <td>2010-06-20 03:18:00</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625</td>\n      <td>-4</td>\n      <td>35.0</td>\n      <td>2010-07-03 01:30:00</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>760</td>\n      <td>7</td>\n      <td>-22.0</td>\n      <td>2010-08-01 02:42:00</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>350</td>\n      <td>2</td>\n      <td>-40.0</td>\n      <td>2011-06-23 12:39:00</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>490</td>\n      <td>-20</td>\n      <td>60.0</td>\n      <td>2011-06-29 01:25:00</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>850</td>\n      <td>-25</td>\n      <td>-30.0</td>\n      <td>2011-07-09 00:54:00</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>838</td>\n      <td>20</td>\n      <td>112.0</td>\n      <td>2011-07-09 17:42:00</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>608</td>\n      <td>-20</td>\n      <td>-131.0</td>\n      <td>2011-07-21 23:18:00</td>\n      <td>2011</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print filtered_dataset_a\n",
    "filtered_dataset_a.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:17.523822Z",
     "start_time": "2023-10-17T18:13:17.370823Z"
    }
   },
   "id": "4e4f8e7deb4b7aee"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "               datetime  Intensity  year\n608 2010-08-03 14:15:00   0.190010  2010\n616 2010-08-18 07:34:00   0.126090  2010\n620 2011-01-28 01:39:00   0.145610  2011\n624 2011-02-15 06:35:00   0.209320  2011\n636 2011-06-04 23:44:00   0.184230  2011\n644 2011-06-17 06:20:00   0.645910  2011\n648 2011-08-02 07:09:00   0.126220  2011\n656 2011-08-08 18:35:00   0.125880  2011\n664 2011-09-06 03:04:00   0.178250  2011\n668 2011-09-06 22:09:00   0.900070  2011\n680 2011-11-04 00:04:00   0.111540  2011\n688 2011-12-25 19:39:00   0.134570  2011\n692 2012-01-20 11:24:00   0.205900  2012\n704 2012-02-25 03:24:00   0.261580  2012\n708 2012-03-05 00:29:00   0.284700  2012\n768 2012-11-08 19:54:00   0.299840  2012\n772 2012-12-14 22:30:00   0.575990  2012\n776 2013-01-17 01:50:00   0.208290  2013\n788 2013-04-21 09:35:00   0.100950  2013\n804 2013-08-21 03:35:00   0.368100  2013\n812 2013-10-28 02:55:00   0.305660  2013\n816 2013-11-02 07:50:00   0.141600  2013\n820 2013-11-06 15:45:00   0.213170  2013\n824 2013-11-19 12:04:00   0.124750  2013\n828 2013-12-14 14:44:00   0.401250  2013\n832 2013-12-26 15:35:00   0.328550  2013\n848 2014-02-19 04:00:00   0.146280  2014\n860 2014-03-29 18:54:00   0.123580  2014\n868 2014-09-02 04:25:00   0.263510  2014\n876 2014-09-22 07:54:00   0.124620  2014\n884 2014-12-13 22:00:00   0.120830  2014\n888 2014-12-21 11:55:00   0.391740  2014\n892 2015-03-15 04:20:00   0.177560  2015\n896 2015-05-12 03:04:00   0.094055  2015\n912 2015-07-01 16:09:00   0.145540  2015\n916 2015-09-20 19:09:00   0.115760  2015\n924 2015-11-09 21:04:00   0.182520  2015\n928 2015-12-28 15:24:00   0.168850  2015\n936 2016-05-15 20:24:00   0.452040  2016",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>Intensity</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>608</th>\n      <td>2010-08-03 14:15:00</td>\n      <td>0.190010</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>616</th>\n      <td>2010-08-18 07:34:00</td>\n      <td>0.126090</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>2011-01-28 01:39:00</td>\n      <td>0.145610</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>2011-02-15 06:35:00</td>\n      <td>0.209320</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>2011-06-04 23:44:00</td>\n      <td>0.184230</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>644</th>\n      <td>2011-06-17 06:20:00</td>\n      <td>0.645910</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>2011-08-02 07:09:00</td>\n      <td>0.126220</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>2011-08-08 18:35:00</td>\n      <td>0.125880</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>2011-09-06 03:04:00</td>\n      <td>0.178250</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>2011-09-06 22:09:00</td>\n      <td>0.900070</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>2011-11-04 00:04:00</td>\n      <td>0.111540</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>2011-12-25 19:39:00</td>\n      <td>0.134570</td>\n      <td>2011</td>\n    </tr>\n    <tr>\n      <th>692</th>\n      <td>2012-01-20 11:24:00</td>\n      <td>0.205900</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>704</th>\n      <td>2012-02-25 03:24:00</td>\n      <td>0.261580</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>708</th>\n      <td>2012-03-05 00:29:00</td>\n      <td>0.284700</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>2012-11-08 19:54:00</td>\n      <td>0.299840</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>2012-12-14 22:30:00</td>\n      <td>0.575990</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>776</th>\n      <td>2013-01-17 01:50:00</td>\n      <td>0.208290</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>788</th>\n      <td>2013-04-21 09:35:00</td>\n      <td>0.100950</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>804</th>\n      <td>2013-08-21 03:35:00</td>\n      <td>0.368100</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>812</th>\n      <td>2013-10-28 02:55:00</td>\n      <td>0.305660</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>816</th>\n      <td>2013-11-02 07:50:00</td>\n      <td>0.141600</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>2013-11-06 15:45:00</td>\n      <td>0.213170</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>2013-11-19 12:04:00</td>\n      <td>0.124750</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>828</th>\n      <td>2013-12-14 14:44:00</td>\n      <td>0.401250</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>832</th>\n      <td>2013-12-26 15:35:00</td>\n      <td>0.328550</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>2014-02-19 04:00:00</td>\n      <td>0.146280</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>2014-03-29 18:54:00</td>\n      <td>0.123580</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>868</th>\n      <td>2014-09-02 04:25:00</td>\n      <td>0.263510</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>2014-09-22 07:54:00</td>\n      <td>0.124620</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>2014-12-13 22:00:00</td>\n      <td>0.120830</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>2014-12-21 11:55:00</td>\n      <td>0.391740</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>892</th>\n      <td>2015-03-15 04:20:00</td>\n      <td>0.177560</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>2015-05-12 03:04:00</td>\n      <td>0.094055</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>912</th>\n      <td>2015-07-01 16:09:00</td>\n      <td>0.145540</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>2015-09-20 19:09:00</td>\n      <td>0.115760</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>924</th>\n      <td>2015-11-09 21:04:00</td>\n      <td>0.182520</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>2015-12-28 15:24:00</td>\n      <td>0.168850</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>2016-05-15 20:24:00</td>\n      <td>0.452040</td>\n      <td>2016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print filtered_dataset_b\n",
    "filtered_dataset_b.head(n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:18.596822400Z",
     "start_time": "2023-10-17T18:13:18.373822600Z"
    }
   },
   "id": "f956cda39422f8f2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Reinitialize an empty DataFrame for storing matches\n",
    "matches_CME_Elevated = pd.DataFrame(columns=columns_for_matches)\n",
    "# empty list of new rows\n",
    "new_rows = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:20.138833600Z",
     "start_time": "2023-10-17T18:13:19.992333700Z"
    }
   },
   "id": "ae4f72c0c345448c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def find_closest_cme(sep_row: pd.Series, cmes: pd.DataFrame,\n",
    "                     initial_time_window: int = 180, window_limit: int = 1440) -> Tuple[\n",
    "    Union[pd.Series, None], Union[float, None]]:\n",
    "    \"\"\"\n",
    "    Finds the closest matching CME for a given SEP row within a specified initial time window and expands it if no matches are found.\n",
    "    \n",
    "    Parameters:\n",
    "        sep_row (pd.Series): A row from dataset B representing an SEP event.\n",
    "        cmes (pd.DataFrame): Filtered dataset A containing CME events.\n",
    "        initial_time_window (int): Initial time window in minutes for matching SEP to CME.\n",
    "        window_limit (int): Maximum time window in minutes to expand for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Union[pd.Series, None], Union[float, None]]: The closest matching CME row and the time difference in minutes.\n",
    "    \"\"\"\n",
    "    time_window = initial_time_window\n",
    "    closest_cme = None\n",
    "    closest_time_diff = None\n",
    "\n",
    "    while time_window <= window_limit:\n",
    "        time_diffs = (sep_row['datetime'] - cmes['CME_time']).dt.total_seconds() / 60  # Time difference in minutes\n",
    "        within_window = time_diffs.between(0, time_window)  # Only consider positive time differences (SEP after CME)\n",
    "\n",
    "        if within_window.sum() > 0:\n",
    "            # Find the closest match within the time window\n",
    "            closest_cme_idx = time_diffs[within_window].idxmin()\n",
    "            closest_cme = cmes.loc[closest_cme_idx]\n",
    "            closest_time_diff = time_diffs[closest_cme_idx]\n",
    "            break\n",
    "\n",
    "        # Expand the time window by 3 hours (180 minutes)\n",
    "        time_window += initial_time_window\n",
    "\n",
    "    return closest_cme, closest_time_diff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:28.276467100Z",
     "start_time": "2023-10-17T18:13:28.136486300Z"
    }
   },
   "id": "caa5d0d2cfbae975"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest time difference for SEP 2010-08-03 14:15:00 is 2301.0\n",
      "Closest time difference for SEP 2010-08-18 07:34:00 is 94.0\n",
      "Closest time difference for SEP 2011-01-28 01:39:00 is 14.0\n",
      "Closest time difference for SEP 2011-02-15 06:35:00 is 250.0\n",
      "Closest time difference for SEP 2011-06-04 23:44:00 is 95.0\n",
      "Closest time difference for SEP 2011-06-17 06:20:00 is 4210.0\n",
      "Closest time difference for SEP 2011-08-02 07:09:00 is 29.0\n",
      "Closest time difference for SEP 2011-08-08 18:35:00 is 35.0\n",
      "Closest time difference for SEP 2011-09-06 03:04:00 is 55.0\n",
      "Closest time difference for SEP 2011-09-06 22:09:00 is 975.0\n",
      "Closest time difference for SEP 2011-11-04 00:04:00 is 85.0\n",
      "Closest time difference for SEP 2011-12-25 19:39:00 is 15.0\n",
      "Closest time difference for SEP 2012-01-20 11:24:00 is 1214.0\n",
      "Closest time difference for SEP 2012-02-25 03:24:00 is 435.0\n",
      "Closest time difference for SEP 2012-03-05 00:29:00 is 785.0\n",
      "Closest time difference for SEP 2012-11-08 19:54:00 is 186.0\n",
      "Closest time difference for SEP 2012-12-14 22:30:00 is 1206.0\n",
      "Closest time difference for SEP 2013-01-17 01:50:00 is 402.0\n",
      "Closest time difference for SEP 2013-04-21 09:35:00 is 101.0\n",
      "Closest time difference for SEP 2013-08-21 03:35:00 is 1151.0\n",
      "Closest time difference for SEP 2013-10-28 02:55:00 is 43.0\n",
      "Closest time difference for SEP 2013-11-02 07:50:00 is 182.0\n",
      "Closest time difference for SEP 2013-11-06 15:45:00 is 69.0\n",
      "Closest time difference for SEP 2013-11-19 12:04:00 is 85.0\n",
      "Closest time difference for SEP 2013-12-14 14:44:00 is 140.0\n",
      "Closest time difference for SEP 2013-12-26 15:35:00 is 491.0\n",
      "Closest time difference for SEP 2014-02-19 04:00:00 is 240.0\n",
      "Closest time difference for SEP 2014-03-29 18:54:00 is 15.0\n",
      "Closest time difference for SEP 2014-09-02 04:25:00 is 109.0\n",
      "Closest time difference for SEP 2014-09-22 07:54:00 is 90.0\n",
      "Closest time difference for SEP 2014-12-13 22:00:00 is 456.0\n",
      "Closest time difference for SEP 2014-12-21 11:55:00 is 619.0\n",
      "Closest time difference for SEP 2015-03-15 04:20:00 is 140.0\n",
      "Closest time difference for SEP 2015-05-12 03:04:00 is 16.0\n",
      "Closest time difference for SEP 2015-07-01 16:09:00 is 93.0\n",
      "Closest time difference for SEP 2015-09-20 19:09:00 is 57.0\n",
      "Closest time difference for SEP 2015-11-09 21:04:00 is 448.0\n",
      "Closest time difference for SEP 2015-12-28 15:24:00 is 165.0\n",
      "Closest time difference for SEP 2016-05-15 20:24:00 is 288.0\n",
      "Elevated datetime 2010-08-03 14:15:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2010-08-03 14:15:00\n",
      "Elevated datetime 2010-08-18 07:34:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2010-08-18 07:34:00\n",
      "Elevated datetime 2011-01-28 01:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-01-28 01:39:00\n",
      "Elevated datetime 2011-02-15 06:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-02-15 06:35:00\n",
      "Elevated datetime 2011-06-04 23:44:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-06-04 23:44:00\n",
      "Elevated datetime 2011-06-17 06:20:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-06-17 06:20:00\n",
      "Elevated datetime 2011-08-02 07:09:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-02 07:09:00\n",
      "Elevated datetime 2011-08-08 18:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-08-08 18:35:00\n",
      "Elevated datetime 2011-09-06 03:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-09-06 03:04:00\n",
      "Elevated datetime 2011-09-06 22:09:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-09-06 22:09:00\n",
      "Elevated datetime 2011-11-04 00:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-11-04 00:04:00\n",
      "Elevated datetime 2011-12-25 19:39:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2011-12-25 19:39:00\n",
      "Elevated datetime 2012-01-20 11:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-01-20 11:24:00\n",
      "Elevated datetime 2012-02-25 03:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-02-25 03:24:00\n",
      "Elevated datetime 2012-03-05 00:29:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-03-05 00:29:00\n",
      "Elevated datetime 2012-11-08 19:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-11-08 19:54:00\n",
      "Elevated datetime 2012-12-14 22:30:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2012-12-14 22:30:00\n",
      "Elevated datetime 2013-01-17 01:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-01-17 01:50:00\n",
      "Elevated datetime 2013-04-21 09:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-04-21 09:35:00\n",
      "Elevated datetime 2013-08-21 03:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-08-21 03:35:00\n",
      "Elevated datetime 2013-10-28 02:55:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-10-28 02:55:00\n",
      "Elevated datetime 2013-11-02 07:50:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-11-02 07:50:00\n",
      "Elevated datetime 2013-11-06 15:45:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-11-06 15:45:00\n",
      "Elevated datetime 2013-11-19 12:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-11-19 12:04:00\n",
      "Elevated datetime 2013-12-14 14:44:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-12-14 14:44:00\n",
      "Elevated datetime 2013-12-26 15:35:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2013-12-26 15:35:00\n",
      "Elevated datetime 2014-02-19 04:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-02-19 04:00:00\n",
      "Elevated datetime 2014-03-29 18:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-03-29 18:54:00\n",
      "Elevated datetime 2014-09-02 04:25:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-09-02 04:25:00\n",
      "Elevated datetime 2014-09-22 07:54:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-09-22 07:54:00\n",
      "Elevated datetime 2014-12-13 22:00:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-12-13 22:00:00\n",
      "Elevated datetime 2014-12-21 11:55:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2014-12-21 11:55:00\n",
      "Elevated datetime 2015-03-15 04:20:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-03-15 04:20:00\n",
      "Elevated datetime 2015-05-12 03:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-05-12 03:04:00\n",
      "Elevated datetime 2015-07-01 16:09:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-07-01 16:09:00\n",
      "Elevated datetime 2015-09-20 19:09:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-09-20 19:09:00\n",
      "Elevated datetime 2015-11-09 21:04:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-11-09 21:04:00\n",
      "Elevated datetime 2015-12-28 15:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2015-12-28 15:24:00\n",
      "Elevated datetime 2016-05-15 20:24:00 index_to_match: 1\n",
      "0     1995-10-20 06:20:00\n",
      "1     1995-10-20 07:39:00\n",
      "2     1995-10-20 12:15:00\n",
      "3     1995-10-21 19:39:00\n",
      "4     1997-11-04 06:04:00\n",
      "              ...        \n",
      "947   2017-09-09 18:15:00\n",
      "948   2017-09-10 15:35:00\n",
      "949   2017-09-10 16:30:00\n",
      "950   2017-09-11 11:50:00\n",
      "951   2017-09-15 22:14:00\n",
      "Name: datetime, Length: 952, dtype: datetime64[ns]\n",
      "Matching SEP event found for 2016-05-15 20:24:00\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Pre-populate target table with all CMEs\n",
    "new_rows = []\n",
    "for idx, cme_row in filtered_dataset_a.iterrows():\n",
    "    new_row = {\n",
    "        'CME_speed': cme_row['CME_speed'],\n",
    "        'CME_latitude': cme_row['CME_latitude'],\n",
    "        'CME_longitude': cme_row['CME_longitude'],\n",
    "        'CME_time': cme_row['CME_time'],\n",
    "        'SEP_onset_time': np.nan,\n",
    "        'time_difference': np.nan,\n",
    "        'matching': '',\n",
    "        'SEP_peak_intensity': np.nan\n",
    "    }\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "matches_CME_Elevated = pd.DataFrame(new_rows, columns=columns_for_matches)\n",
    "\n",
    "# Step 2 & 3: Find closest matching CME for each SEP and update the target table\n",
    "closest_cmes_for_seps = {}  # To keep track of closest CMEs for each SEP\n",
    "\n",
    "for idx, sep_row in filtered_dataset_b.iterrows():\n",
    "    # Skip SEPs with peak intensity >= 10\n",
    "    if sep_row['Intensity'] >= 10:\n",
    "        continue\n",
    "    closest_cme, closest_time_diff = find_closest_cme(sep_row, filtered_dataset_a, initial_time_window, window_limit)\n",
    "    sep_id = sep_row['datetime']\n",
    "\n",
    "    print(f'Closest time difference for SEP {sep_id} is {closest_time_diff}')\n",
    "\n",
    "    if closest_cme is not None:\n",
    "        cme_id = closest_cme['CME_time']\n",
    "        # Check if this CME is already the closest match for another SEP\n",
    "        if cme_id in closest_cmes_for_seps:\n",
    "            closest_cmes_for_seps[cme_id]['matching'] = 'dup'\n",
    "            closest_cmes_for_seps[cme_id]['SEPs'].append({'sep': sep_row, 'time_diff': closest_time_diff})\n",
    "        else:\n",
    "            closest_cmes_for_seps[cme_id] = {'matching': 'match',\n",
    "                                             'SEPs': [{'sep': sep_row, 'time_diff': closest_time_diff}]}\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "for cme_id, cme_info in closest_cmes_for_seps.items():\n",
    "    # Get CME details from the original DataFrame\n",
    "    cme_details = matches_CME_Elevated.loc[matches_CME_Elevated['CME_time'] == cme_id].iloc[0]\n",
    "\n",
    "    # Loop through all SEPs that have this CME as the closest match\n",
    "    for sep_info in cme_info['SEPs']:\n",
    "        closest_sep = sep_info['sep']\n",
    "        closest_time_diff = sep_info['time_diff']\n",
    "\n",
    "        peak = populate_peak_intensity(closest_sep['datetime'], dataset_b, index_to_match)\n",
    "\n",
    "        updated_values = {\n",
    "            'SEP_onset_time': closest_sep['datetime'],\n",
    "            'time_difference': -closest_time_diff,\n",
    "            'matching': cme_info['matching'],\n",
    "            'SEP_peak_intensity': peak\n",
    "        }\n",
    "\n",
    "        if cme_info['matching'] == 'dup':\n",
    "            # Create a new row with CME details and new SEP details\n",
    "            new_row = cme_details.copy()\n",
    "            new_row.update(updated_values)\n",
    "            new_rows.append(new_row)\n",
    "        else:\n",
    "            # Update the existing row in the DataFrame\n",
    "            matches_CME_Elevated.loc[matches_CME_Elevated['CME_time'] == cme_id, updated_values.keys()] = list(\n",
    "                updated_values.values())\n",
    "\n",
    "# Convert the list of new rows to a DataFrame and concatenate it with the original DataFrame\n",
    "if new_rows:\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    matches_CME_Elevated = pd.concat([matches_CME_Elevated, new_rows_df], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:29.931134300Z",
     "start_time": "2023-10-17T18:13:29.391135700Z"
    }
   },
   "id": "bc6c51ab43946f98"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Save the matches_CME_Elevated DataFrame to a CSV file\n",
    "csv_file_path = '../cme_and_electron/matches_CME_Elevated.csv'\n",
    "matches_CME_Elevated.to_csv(csv_file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T18:13:39.496812200Z",
     "start_time": "2023-10-17T18:13:39.295812200Z"
    }
   },
   "id": "ab4021ed3f34c02d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Loop through each row in dataset A to find matching SEPs from dataset B\n",
    "# for idx, cme_row in filtered_dataset_a.iterrows():\n",
    "#     matching_seps, matching_time_diffs = find_matching_seps(\n",
    "#         cme_row, filtered_dataset_b, initial_time_window, window_limit)\n",
    "# \n",
    "#     # Prepare data for new row in matches_CME_SEPs\n",
    "#     new_row = {\n",
    "#         'CME_speed': cme_row['CME_speed'],\n",
    "#         'CME_latitude': cme_row['CME_latitude'],\n",
    "#         'CME_longitude': cme_row['CME_longitude'],\n",
    "#         'CME_time': cme_row['CME_time'],\n",
    "#         'SEP_onset_time': np.nan,\n",
    "#         'time_difference': np.nan,\n",
    "#         'matching': '',\n",
    "#         'SEP_peak_intensity': np.nan\n",
    "#     }\n",
    "# \n",
    "#     if len(matching_seps) > 0:\n",
    "#         # Populate fields if matches are found\n",
    "#         if len(matching_seps) > 1:\n",
    "#             new_row['matching'] = 'dup'\n",
    "#         else:\n",
    "#             new_row['matching'] = 'match'\n",
    "# \n",
    "#         # Use the closest match for other fields\n",
    "#         closest_match = matching_seps.iloc[0]\n",
    "#         closest_match_time_diff = matching_time_diffs[0]\n",
    "# \n",
    "#         # print(\"Data type of 'datetime' in closest_match:\", type(closest_match['datetime']))\n",
    "# \n",
    "#         new_row.update({\n",
    "#             'SEP_onset_time': closest_match['datetime'],\n",
    "#             'time_difference': closest_match_time_diff\n",
    "#         })\n",
    "# \n",
    "#         print('Data type of dataset_b in new_row:', dataset_b['datetime'].dtype)\n",
    "# \n",
    "#         # Find the intensities at indices 1-4 for the matched SEP\n",
    "#         onset, threshold, peak, ending = populate_peak_intensity(closest_match['datetime'], dataset_b, index_to_match)\n",
    "#         new_row.update({\n",
    "#             'SEP_peak_intensity': peak\n",
    "#         })\n",
    "# \n",
    "#     # Add the new row to the list\n",
    "#     new_rows.append(new_row)\n",
    "# \n",
    "# # Use pd.concat to add all new rows to matches_CME_SEPs\n",
    "# matches_CME_Elevated = pd.DataFrame(new_rows, columns=columns_for_matches)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b89a1bb495ce19fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# Load the matches_CME_SEPs dataset\n",
    "matches_CME_SEPs_path = '../cme_and_electron/matches_CME_SEPs - curated - updated.csv'\n",
    "matches_CME_SEPs = pd.read_csv(matches_CME_SEPs_path, parse_dates=['CME_time'])\n",
    "\n",
    "# Load the DONKI_CDAW_CMEs dataset\n",
    "DONKI_CDAW_CMEs_path = '../cme_and_electron/DONKI_CDAW_CMEs_original.csv'\n",
    "DONKI_CDAW_CMEs = pd.read_csv(DONKI_CDAW_CMEs_path, parse_dates=['cdaw_date'])\n",
    "\n",
    "# Preview the datasets\n",
    "matches_CME_SEPs.head(), DONKI_CDAW_CMEs.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3f796646dc4bc3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter out the CME_time rows that are already present in the DONKI_CDAW_CMEs dataset\n",
    "existing_cme_times_in_cdaw = DONKI_CDAW_CMEs['donki_date']\n",
    "remaining_cme_times = matches_CME_SEPs.loc[~matches_CME_SEPs['CME_time'].isin(existing_cme_times_in_cdaw)]\n",
    "\n",
    "# Preview the remaining CME_time rows\n",
    "remaining_cme_times.head(), len(remaining_cme_times)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d434296db1bd8936"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def find_closest_cdaw_match(cme_time: pd.Timestamp, cdaw_df: pd.DataFrame,\n",
    "                            time_window: timedelta = timedelta(hours=2)) -> Optional[pd.Series]:\n",
    "    \"\"\"\n",
    "    Finds the closest matching cdaw_date for a given CME_time within a specified time window.\n",
    "    \n",
    "    Parameters:\n",
    "        cme_time (pd.Timestamp): A timestamp from matches_CME_SEPs representing a CME event.\n",
    "        cdaw_df (pd.DataFrame): The DONKI_CDAW_CMEs DataFrame.\n",
    "        time_window (timedelta): The time window for matching.\n",
    "        \n",
    "    Returns:\n",
    "        Optional[pd.Series]: The closest matching cdaw_date row, None if no match found.\n",
    "    \"\"\"\n",
    "    time_diffs = (cdaw_df['cdaw_date'] - cme_time).abs()\n",
    "    within_window = time_diffs <= time_window\n",
    "    matching_cdaw = cdaw_df[within_window]\n",
    "\n",
    "    if matching_cdaw.empty:\n",
    "        return None\n",
    "\n",
    "    closest_time_diff_idx = time_diffs[within_window].idxmin()\n",
    "    return cdaw_df.loc[closest_time_diff_idx]\n",
    "\n",
    "\n",
    "# Initialize an empty list to hold the new rows with additional columns\n",
    "new_rows_with_cdaw = []\n",
    "\n",
    "# Loop through each remaining CME_time to find the closest cdaw_date\n",
    "for idx, row in remaining_cme_times.iterrows():\n",
    "    closest_cdaw_match = find_closest_cdaw_match(row['CME_time'], DONKI_CDAW_CMEs)\n",
    "\n",
    "    # Create a new row with additional columns if a match is found\n",
    "    new_row = row.copy()\n",
    "    if closest_cdaw_match is not None:\n",
    "        new_row['CDAW time'] = closest_cdaw_match['cdaw_date']\n",
    "        new_row['CDAW MPA'] = closest_cdaw_match['MPA']\n",
    "        new_row['Time Difference CDAW-DONKI'] = (closest_cdaw_match['cdaw_date'] - row['CME_time']).total_seconds() / 60\n",
    "    else:\n",
    "        new_row['CDAW time'] = pd.NaT\n",
    "        new_row['CDAW MPA'] = pd.NA\n",
    "        new_row['Time Difference CDAW-DONKI'] = pd.NA\n",
    "\n",
    "    new_rows_with_cdaw.append(new_row)\n",
    "\n",
    "# Create the final DataFrame\n",
    "final_df = pd.DataFrame(new_rows_with_cdaw)\n",
    "\n",
    "# Preview the final DataFrame\n",
    "final_df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c888af2e6bc2535b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a new CSV file\n",
    "final_csv_path = '../cme_and_electron/final_matched_CME_SEPs_with_CDAW.csv'\n",
    "final_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "final_csv_path\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a03edff568fd4e"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'../cme_and_electron/DONKI_CDAW_CMEs_updated.csv'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "donki_cdaw_cmes_path = '../cme_and_electron/DONKI_CDAW_CMEs_original.csv'\n",
    "merged_cme_seps_elevated_path = '../cme_and_electron/merged_CME_SEPs_Elevated.csv'\n",
    "\n",
    "donki_cdaw_cmes = pd.read_csv(donki_cdaw_cmes_path)\n",
    "merged_cme_seps_elevated = pd.read_csv(merged_cme_seps_elevated_path)\n",
    "\n",
    "# Convert 'CME_time' and 'donki_date' to datetime objects for proper comparison\n",
    "donki_cdaw_cmes['donki_date'] = pd.to_datetime(donki_cdaw_cmes['donki_date'])\n",
    "merged_cme_seps_elevated['CME_time'] = pd.to_datetime(merged_cme_seps_elevated['CME_time'])\n",
    "\n",
    "# Add new columns for SEP time and intensity in DONKI_CDAW_CMEs\n",
    "donki_cdaw_cmes['SEP_time'] = pd.NaT\n",
    "donki_cdaw_cmes['SEP_intensity'] = pd.NaT\n",
    "\n",
    "# Initialize a list to collect rows that didn't match with any row in DONKI_CDAW_CMEs\n",
    "unmatched_rows = []\n",
    "\n",
    "# Iterate over each row in merge_CME_SEPs_Elevated\n",
    "for idx, row in merged_cme_seps_elevated.iterrows():\n",
    "    # Try to find a matching row in DONKI_CDAW_CMEs\n",
    "    mask = (\n",
    "            (donki_cdaw_cmes['donki_date'] == row['CME_time']) &\n",
    "            (donki_cdaw_cmes['latitude'] == row['CME_latitude']) &\n",
    "            (donki_cdaw_cmes['longitude'] == row['CME_longitude']) &\n",
    "            (donki_cdaw_cmes['donki_speed'] == row['CME_speed'])\n",
    "    )\n",
    "    matching_rows = donki_cdaw_cmes[mask]\n",
    "\n",
    "    # If a match is found, update the SEP time and intensity\n",
    "    if not matching_rows.empty:\n",
    "        donki_cdaw_cmes.loc[mask, 'SEP_time'] = row['SEP_onset_time']\n",
    "        donki_cdaw_cmes.loc[mask, 'SEP_intensity'] = row['SEP_peak_intensity']\n",
    "    else:\n",
    "        # Try to find a row with at least a matching date\n",
    "        date_matching_rows = donki_cdaw_cmes[donki_cdaw_cmes['donki_date'] == row['CME_time']]\n",
    "\n",
    "        if not date_matching_rows.empty:\n",
    "            # Update the latitude, longitude, and speed along with SEP information\n",
    "            donki_cdaw_cmes.loc[date_matching_rows.index, ['latitude', 'longitude', 'donki_speed']] = row[\n",
    "                ['CME_latitude', 'CME_longitude', 'CME_speed']]\n",
    "            donki_cdaw_cmes.loc[date_matching_rows.index, 'SEP_time'] = row['SEP_onset_time']\n",
    "            donki_cdaw_cmes.loc[date_matching_rows.index, 'SEP_intensity'] = row['SEP_peak_intensity']\n",
    "        else:\n",
    "            # If no match is found, add to the list of unmatched rows\n",
    "            unmatched_rows.append(row)\n",
    "\n",
    "# Add unmatched rows to the end of DONKI_CDAW_CMEs\n",
    "if unmatched_rows:\n",
    "    unmatched_df = pd.DataFrame(unmatched_rows)\n",
    "    # Rename the columns to match with DONKI_CDAW_CMEs\n",
    "    unmatched_df.rename(columns={\n",
    "        'CME_time': 'donki_date',\n",
    "        'CME_latitude': 'latitude',\n",
    "        'CME_longitude': 'longitude',\n",
    "        'CME_speed': 'donki_speed',\n",
    "        'SEP_onset_time': 'SEP_time',\n",
    "        'SEP_peak_intensity': 'SEP_intensity'\n",
    "    }, inplace=True)\n",
    "    donki_cdaw_cmes = pd.concat([donki_cdaw_cmes, unmatched_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DONKI_CDAW_CMEs to a new CSV file\n",
    "updated_donki_cdaw_cmes_path = '../cme_and_electron/DONKI_CDAW_CMEs_updated.csv'\n",
    "donki_cdaw_cmes.to_csv(updated_donki_cdaw_cmes_path, index=False)\n",
    "\n",
    "updated_donki_cdaw_cmes_path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T01:01:56.257587500Z",
     "start_time": "2023-10-19T01:01:50.330084300Z"
    }
   },
   "id": "4394b51379d32c42"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'../cme_and_electron/DONKI_CDAW_CMEs_updated_2.csv'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "merged_cme_seps_elevated_df = pd.read_csv('../cme_and_electron/merged_CME_SEPs_Elevated.csv')\n",
    "donki_cdaw_cmes_df = pd.read_csv('../cme_and_electron/DONKI_CDAW_CMEs_original.csv')\n",
    "\n",
    "# Convert 'CME_time' in merged_cme_seps_elevated_df and 'donki_date' in donki_cdaw_cmes_df to datetime objects\n",
    "merged_cme_seps_elevated_df['CME_time'] = pd.to_datetime(merged_cme_seps_elevated_df['CME_time'])\n",
    "donki_cdaw_cmes_df['donki_date'] = pd.to_datetime(donki_cdaw_cmes_df['donki_date'])\n",
    "\n",
    "# Prepare empty lists to keep track of updated rows and new rows\n",
    "updated_rows = []\n",
    "new_rows = []\n",
    "\n",
    "# Loop through each row in the merged_cme_seps_elevated_df to find matching rows in donki_cdaw_cmes_df\n",
    "for idx, merged_row in merged_cme_seps_elevated_df.iterrows():\n",
    "    matching_rows = donki_cdaw_cmes_df[\n",
    "        (donki_cdaw_cmes_df['donki_date'] == merged_row['CME_time']) &\n",
    "        (donki_cdaw_cmes_df['donki_speed'] == merged_row['CME_speed']) &\n",
    "        (donki_cdaw_cmes_df['latitude'] == merged_row['CME_latitude']) &\n",
    "        (donki_cdaw_cmes_df['longitude'] == merged_row['CME_longitude'])\n",
    "        ]\n",
    "\n",
    "    if not matching_rows.empty:\n",
    "        # Update the SEP information in the existing rows\n",
    "        donki_cdaw_cmes_df.loc[matching_rows.index, 'SEP_onset_time'] = merged_row['SEP_onset_time']\n",
    "        donki_cdaw_cmes_df.loc[matching_rows.index, 'SEP_peak_intensity'] = merged_row['SEP_peak_intensity']\n",
    "        updated_rows.append(merged_row)\n",
    "    else:\n",
    "        # Add this row to the end of DONKI_CDAW_CMEs dataframe\n",
    "        new_row = {\n",
    "            'donki_date': merged_row['CME_time'],\n",
    "            'donki_speed': merged_row['CME_speed'],\n",
    "            'latitude': merged_row['CME_latitude'],\n",
    "            'longitude': merged_row['CME_longitude'],\n",
    "            'SEP_onset_time': merged_row['SEP_onset_time'],\n",
    "            'SEP_peak_intensity': merged_row['SEP_peak_intensity']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Append the new rows to the donki_cdaw_cmes_df DataFrame\n",
    "if new_rows:\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    donki_cdaw_cmes_df = pd.concat([donki_cdaw_cmes_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DONKI_CDAW_CMEs DataFrame to a new CSV file\n",
    "updated_donki_cdaw_cmes_path = '../cme_and_electron/DONKI_CDAW_CMEs_updated_2.csv'\n",
    "donki_cdaw_cmes_df.to_csv(updated_donki_cdaw_cmes_path, index=False)\n",
    "\n",
    "updated_donki_cdaw_cmes_path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T01:13:55.629514800Z",
     "start_time": "2023-10-19T01:13:50.972031500Z"
    }
   },
   "id": "d25b1f633084fd87"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'../cme_and_electron/DONKI_CDAW_CMEs_updated3.csv'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "merged_cme_seps_elevated_df = pd.read_csv('../cme_and_electron/merged_CME_SEPs_Elevated.csv')\n",
    "donki_cdaw_cmes_df = pd.read_csv('../cme_and_electron/DONKI_CDAW_CMEs_original.csv')\n",
    "\n",
    "# Convert 'CME_time' in merged_cme_seps_elevated_df and 'donki_date' in donki_cdaw_cmes_df to datetime objects\n",
    "merged_cme_seps_elevated_df['CME_time'] = pd.to_datetime(merged_cme_seps_elevated_df['CME_time'])\n",
    "donki_cdaw_cmes_df['donki_date'] = pd.to_datetime(donki_cdaw_cmes_df['donki_date'])\n",
    "\n",
    "# Add 'SEP_onset_time' and 'SEP_peak_intensity' columns to donki_cdaw_cmes_df if they don't exist\n",
    "if 'SEP_onset_time' not in donki_cdaw_cmes_df.columns:\n",
    "    donki_cdaw_cmes_df['SEP_onset_time'] = None\n",
    "if 'SEP_peak_intensity' not in donki_cdaw_cmes_df.columns:\n",
    "    donki_cdaw_cmes_df['SEP_peak_intensity'] = None\n",
    "\n",
    "# Prepare empty lists to keep track of updated rows and new rows\n",
    "updated_rows = []\n",
    "new_rows = []\n",
    "\n",
    "# Loop through each row in the merged_cme_seps_elevated_df to find matching rows in donki_cdaw_cmes_df\n",
    "for idx, merged_row in merged_cme_seps_elevated_df.iterrows():\n",
    "    matching_rows = donki_cdaw_cmes_df[\n",
    "        (donki_cdaw_cmes_df['donki_date'] == merged_row['CME_time']) &\n",
    "        (donki_cdaw_cmes_df['donki_speed'] == merged_row['CME_speed']) &\n",
    "        (donki_cdaw_cmes_df['latitude'] == merged_row['CME_latitude']) &\n",
    "        (donki_cdaw_cmes_df['longitude'] == merged_row['CME_longitude'])\n",
    "        ]\n",
    "\n",
    "    if not matching_rows.empty:\n",
    "        # Update the SEP information in the existing rows\n",
    "        donki_cdaw_cmes_df.loc[matching_rows.index, 'SEP_onset_time'] = merged_row['SEP_onset_time']\n",
    "        donki_cdaw_cmes_df.loc[matching_rows.index, 'SEP_peak_intensity'] = merged_row['SEP_peak_intensity']\n",
    "        updated_rows.append(merged_row)\n",
    "    else:\n",
    "        # Add this row to the new_rows list\n",
    "        new_row = {\n",
    "            'donki_date': merged_row['CME_time'],\n",
    "            'donki_speed': merged_row['CME_speed'],\n",
    "            'latitude': merged_row['CME_latitude'],\n",
    "            'longitude': merged_row['CME_longitude'],\n",
    "            'SEP_onset_time': merged_row['SEP_onset_time'],\n",
    "            'SEP_peak_intensity': merged_row['SEP_peak_intensity']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Append the new rows to the donki_cdaw_cmes_df DataFrame\n",
    "if new_rows:\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    donki_cdaw_cmes_df = pd.concat([donki_cdaw_cmes_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DONKI_CDAW_CMEs DataFrame to a new CSV file\n",
    "updated_donki_cdaw_cmes_path = '../cme_and_electron/DONKI_CDAW_CMEs_updated3.csv'\n",
    "donki_cdaw_cmes_df.to_csv(updated_donki_cdaw_cmes_path, index=False)\n",
    "\n",
    "updated_donki_cdaw_cmes_path\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T01:21:03.496730800Z",
     "start_time": "2023-10-19T01:20:57.712738100Z"
    }
   },
   "id": "a32e8a5636394ffb"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from dataload.calc_cme_history import cme_statistics_for_row,\\\n",
    "    cme_counts_with_speed_threshold, \\\n",
    "    cme_counts_in_timeframe, \\\n",
    "    max_cme_speed_in_timeframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T03:16:03.352672900Z",
     "start_time": "2023-10-24T03:16:02.428172200Z"
    }
   },
   "id": "fb738c59abb847be"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 1, 0, 620)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the updated DataFrame from the provided CSV file\n",
    "df_path = '../cme_and_electron/new_data/matched_and_augmented_dataframe_updated.csv'\n",
    "result_df_final = pd.read_csv(df_path)\n",
    "\n",
    "# Test the corrected functions\n",
    "test_row = result_df_final.iloc[0]\n",
    "cme_statistics_for_row(result_df_final, test_row['CME_DONKI_time'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T03:16:05.571170700Z",
     "start_time": "2023-10-24T03:16:05.330169900Z"
    }
   },
   "id": "2c9301cf9d1d4d26"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Apply the functions to each row in the DataFrame and store the results in new columns\n",
    "result_df_final['CMEs_in_past_month'] = result_df_final['CME_DONKI_time'].apply(\n",
    "    lambda x: cme_counts_in_timeframe(result_df_final, x, hours=30 * 24))\n",
    "result_df_final['CMEs_in_past_9hours'] = result_df_final['CME_DONKI_time'].apply(\n",
    "    lambda x: cme_counts_in_timeframe(result_df_final, x, hours=9))\n",
    "result_df_final['CMEs_with_speed_over_1000_in_past_9hours'] = result_df_final['CME_DONKI_time'].apply(\n",
    "    lambda x: cme_counts_with_speed_threshold(result_df_final, x, hours=9, speed=1000))\n",
    "result_df_final['max_CME_speed_in_past_day'] = result_df_final['CME_DONKI_time'].apply(\n",
    "    lambda x: max_cme_speed_in_timeframe(result_df_final, x, hours=24))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T03:19:58.050152400Z",
     "start_time": "2023-10-24T03:16:06.684670100Z"
    }
   },
   "id": "b3dc97c357058e9b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Save the updated DONKI_CDAW_CMEs DataFrame to a new CSV file\n",
    "result_df_final_path = '../cme_and_electron/new_data/features_dataset.csv'\n",
    "result_df_final.to_csv(result_df_final_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T03:19:58.136886400Z",
     "start_time": "2023-10-24T03:19:58.052153700Z"
    }
   },
   "id": "a76ee690c04a6669"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dbc846d5e75d4894"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
