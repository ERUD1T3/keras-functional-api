{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:57:14.593655500Z",
     "start_time": "2023-09-26T18:57:13.899655100Z"
    }
   },
   "id": "fd3bbe0b3382a620"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load the original data again\n",
    "original_data = pd.read_csv(\"../cme_and_electron/CME_daniel.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T18:58:33.395267600Z",
     "start_time": "2023-09-26T18:58:33.259279Z"
    }
   },
   "id": "60077859ed46edd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Feature/Target Variable        | Preprocessing Step                                                                 |\n",
    "|-------------------------------|------------------------------------------------------------------------------------|\n",
    "| peak_intensity                 | Take the natural log, then divide by the max of the natural log                    |\n",
    "| CMEs_over_1000_past_9_hrs      | Divide by max (2)                                                                  |\n",
    "| CMEs_past_9_hours              | Divide by max (6)                                                                  |\n",
    "| V log V                        | Take the natural log, then divide by the max of the natural log                     |\n",
    "| longitude                      | Normalize to range \\([-1, 1]\\) by dividing by 180                                  |\n",
    "| MPA                            | Normalize to range \\([0, 1]\\) by dividing by 360                                   |\n",
    "| latitude                       | Normalize to range \\([-1, 1]\\) by dividing by 90                                   |\n",
    "| Acceleration (Accel)           | Divide by max                                                                      |\n",
    "| Linear Speed (donki_speed)     | Divide by max                                                                      |\n",
    "| Richardson's Equation          | Take the natural log, then divide by the absolute value of the min of the natural log |\n",
    "| 2nd Order Speed Final          | Divide by max                                                                      |\n",
    "| 2nd Order Speed at 20 Solar Radii | Divide by max                                                              |\n",
    "| Max Speed Past Day             | Divide by max                                                                      |\n",
    "| CMEs in the Past Month         | Divide by max                                                                      |\n",
    "| Daily Sunspot Count            | Divide by max                                                                      |\n",
    "| Half Width (donki_ha)          | Divide by max                                                                      |\n",
    "| CPA (Central_PA)               | Divide by max                                                                      |\n",
    "| Diffusive Shock (V^V^2_replacement) | Take the natural log, then divide by the absolute value of the min of the natural log |\n",
    "| Halo                           | No transformation (categorical)                                                    |\n",
    "| Type II Visualization Area     | If zero, leave as zero. Else, take the natural log, then divide by the max of the natural log |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e9f8f04adf10103"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define the updated preprocessing functions based on the new table\n",
    "def updated_preprocess_data(df):\n",
    "    new_data = pd.DataFrame()\n",
    "    \n",
    "    # Apply transformations as specified in the updated table\n",
    "    log_peak_intensity_max = np.log(df['peak_intensity']).max()\n",
    "    new_data['log_peak_intensity_norm'] = np.log(df['peak_intensity']) / log_peak_intensity_max\n",
    "    \n",
    "    new_data['CMEs_over_1000_past_9_hrs_norm'] = df['CMEs_over_1000_past_9_hrs'] / 2\n",
    "    new_data['CMEs_past_9_hours_norm'] = df['CMEs_past_9_hours'] / 6\n",
    "    \n",
    "    log_v_log_v_max = np.log(df['V log V']).max()\n",
    "    new_data['log_V_log_V_norm'] = np.log(df['V log V']) / log_v_log_v_max\n",
    "    \n",
    "    new_data['longitude_norm'] = df['longitude'] / 180\n",
    "    new_data['MPA_norm'] = df['MPA'] / 360\n",
    "    new_data['latitude_norm'] = df['latitude'] / 90\n",
    "    new_data['Accel_norm'] = df['Accel'] / df['Accel'].max()\n",
    "    new_data['donki_speed_norm'] = df['donki_speed'] / df['donki_speed'].max()\n",
    "\n",
    "    # Take the natural log of the 'V^V^2_replacement' (Diffusive Shock) and 'richardson_formula_1.0_c' (Richardson's Equation)\n",
    "    df['log_diffusive_shock'] = np.log(df['V^V^2_replacement'])\n",
    "    df['log_richardson_formula'] = np.log(df['richardson_formula_1.0_c'])\n",
    "    \n",
    "    # Find the absolute value of the minimum of these logged features\n",
    "    abs_min_log_diffusive_shock = np.abs(df['log_diffusive_shock'].min())\n",
    "    abs_min_log_richardson_formula = np.abs(df['log_richardson_formula'].min())\n",
    "    \n",
    "    # Divide by the absolute value of the min\n",
    "    new_data['log_diffusive_shock_norm'] = df['log_diffusive_shock'] / abs_min_log_diffusive_shock\n",
    "    new_data['log_richardson_formula_norm'] = df['log_richardson_formula'] / abs_min_log_richardson_formula\n",
    "    \n",
    "    new_data['2nd_order_speed_final_norm'] = df['2nd_order_speed_final'] / df['2nd_order_speed_final'].max()\n",
    "    new_data['2nd_order_speed_20R_norm'] = df['2nd_order_speed_20R'] / df['2nd_order_speed_20R'].max()\n",
    "    new_data['Max_speed_past_day_norm'] = df['Max_speed_past_day'] / df['Max_speed_past_day'].max()\n",
    "    new_data['CMEs_past_month_norm'] = df['CMEs_past_month'] / df['CMEs_past_month'].max()\n",
    "    new_data['sunspots_norm'] = df['sunspots'] / df['sunspots'].max()\n",
    "    new_data['donki_ha_norm'] = df['donki_ha'] / df['donki_ha'].max()\n",
    "    new_data['Central_PA_norm'] = df['Central_PA'] / df['Central_PA'].max()\n",
    "    \n",
    "    new_data['HALO'] = df['HALO']\n",
    "    \n",
    "    log_type_2_area_max = np.log(df[df['Type_2_Area'] > 0]['Type_2_Area']).max()\n",
    "    new_data['log_Type_2_Area_norm'] = df['Type_2_Area'].apply(\n",
    "        lambda x: 0 if x == 0 else np.log(x + 1) / log_type_2_area_max)\n",
    "    \n",
    "    return new_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T19:00:19.674933Z",
     "start_time": "2023-09-26T19:00:19.572441500Z"
    }
   },
   "id": "d4b424e9cbbfe5d8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    amin      amax\nlog_peak_intensity_norm         0.034652  1.000000\nCMEs_over_1000_past_9_hrs_norm  0.000000  1.000000\nCMEs_past_9_hours_norm          0.000000  1.000000\nlog_V_log_V_norm                0.445649  1.000000\nlongitude_norm                 -1.000000  1.000000\nMPA_norm                        0.000000  1.000000\nlatitude_norm                  -0.977778  1.000000\nAccel_norm                     -0.337409  1.000000\ndonki_speed_norm                0.024000  1.000000\nlog_diffusive_shock_norm       -1.000000 -0.175982\nlog_richardson_formula_norm    -1.000000 -0.026725\n2nd_order_speed_final_norm      0.000000  1.000000\n2nd_order_speed_20R_norm        0.000000  1.000000\nMax_speed_past_day_norm         0.000000  1.000000\nCMEs_past_month_norm            0.000000  1.000000\nsunspots_norm                   0.000000  1.000000\ndonki_ha_norm                   0.054348  1.000000\nCentral_PA_norm                 0.000000  1.000000\nHALO                            0.000000  1.000000\nlog_Type_2_Area_norm            0.000000  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amin</th>\n      <th>amax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>log_peak_intensity_norm</th>\n      <td>0.034652</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>CMEs_over_1000_past_9_hrs_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>CMEs_past_9_hours_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>log_V_log_V_norm</th>\n      <td>0.445649</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>longitude_norm</th>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>MPA_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>latitude_norm</th>\n      <td>-0.977778</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>Accel_norm</th>\n      <td>-0.337409</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>donki_speed_norm</th>\n      <td>0.024000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>log_diffusive_shock_norm</th>\n      <td>-1.000000</td>\n      <td>-0.175982</td>\n    </tr>\n    <tr>\n      <th>log_richardson_formula_norm</th>\n      <td>-1.000000</td>\n      <td>-0.026725</td>\n    </tr>\n    <tr>\n      <th>2nd_order_speed_final_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2nd_order_speed_20R_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>Max_speed_past_day_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>CMEs_past_month_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>sunspots_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>donki_ha_norm</th>\n      <td>0.054348</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>Central_PA_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>HALO</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>log_Type_2_Area_norm</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the updated preprocessing\n",
    "updated_preprocessed_data = updated_preprocess_data(original_data)\n",
    "\n",
    "# Calculate the new min and max for each of the new columns in the preprocessed data\n",
    "updated_min_max_values = updated_preprocessed_data.agg([np.min, np.max]).T\n",
    "updated_min_max_values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T19:00:23.325961200Z",
     "start_time": "2023-09-26T19:00:23.209461100Z"
    }
   },
   "id": "c2377b8961788f67"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define the function to save the DataFrame to a CSV file\n",
    "def save_dataframe_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Save a given DataFrame to a CSV file at the specified file path.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame to save.\n",
    "        file_path (str): The file path where the DataFrame should be saved.\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Define the file path for saving the updated preprocessed data\n",
    "file_path_to_save = '../cme_and_electron/cme_josias_10MeV.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "save_dataframe_to_csv(updated_preprocessed_data, file_path_to_save)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T19:04:34.921735600Z",
     "start_time": "2023-09-26T19:04:34.763246800Z"
    }
   },
   "id": "b1dd587fa2d6b414"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
