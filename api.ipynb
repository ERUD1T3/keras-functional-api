{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:39.313577900Z",
     "start_time": "2023-08-13T21:48:39.209605700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Practicing Keras functional api\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "import pydot\n",
    "import graphviz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.807080100Z",
     "start_time": "2023-08-13T21:48:39.228581700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Build a simple model\n",
    "Functional API is more flexible than Sequential API. It can handle models with non-linear topology, shared layers, and even multiple inputs or outputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input layer: , type of input layer:  (None, 784) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name='input_layer') # 784 is the number of input features\n",
    "# shape of input layer \n",
    "print(\"shape of input layer: , type of input layer: \", inputs.shape, inputs.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.824078600Z",
     "start_time": "2023-08-13T21:48:42.806581400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# hidden layer with relu activation\n",
    "h1 = layers.Dense(64, activation='relu', name='hidden_layer1')(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.881079400Z",
     "start_time": "2023-08-13T21:48:42.820578100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "h2 = layers.Dense(64, activation='relu', name='hidden_layer2')(h1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.925580400Z",
     "start_time": "2023-08-13T21:48:42.884078900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# output layer \n",
    "outputs = layers.Dense(10, name='output_layer')(h2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.942578100Z",
     "start_time": "2023-08-13T21:48:42.916580700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 784)]             0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 64)                50240     \n",
      "                                                                 \n",
      " hidden_layer2 (Dense)       (None, 64)                4160      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55050 (215.04 KB)\n",
      "Trainable params: 55050 (215.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
    "# summary of the model\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:42.998078700Z",
     "start_time": "2023-08-13T21:48:42.945581500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# loading training MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')/255  # 60000 is the number of samples, divide by 255 to normalize the data\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')/255\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True) # raw output from the model, not the probability, SparseCategoricalCrossentropy is better for integer labels\n",
    "optimizer = keras.optimizers.RMSprop() # the Root Mean Square Propagation algorithm\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()] # accuracy is the metric to eval\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:43.405078800Z",
     "start_time": "2023-08-13T21:48:42.978579400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.3453 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.1904 - val_sparse_categorical_accuracy: 0.9452\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1460 - val_sparse_categorical_accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2) # 20% of the training data is used for validation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.020580100Z",
     "start_time": "2023-08-13T21:48:43.395080100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1358 - sparse_categorical_accuracy: 0.9599 - 273ms/epoch - 874us/step\n",
      "Test loss: 0.13576193153858185, Test accuracy: 0.9599000215530396\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test loss: {test_scores[0]}, Test accuracy: {test_scores[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.349579Z",
     "start_time": "2023-08-13T21:48:47.020580100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# save the model\n",
    "path = './weights/mnist_model.keras'\n",
    "model.save(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.420081300Z",
     "start_time": "2023-08-13T21:48:47.347079400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# delete the model\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.431081900Z",
     "start_time": "2023-08-13T21:48:47.393082100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = keras.models.load_model(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.502580200Z",
     "start_time": "2023-08-13T21:48:47.409079700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " original_img (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 8, 8, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 16)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18672 (72.94 KB)\n",
      "Trainable params: 18672 (72.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# all models are callable\n",
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.621578900Z",
     "start_time": "2023-08-13T21:48:47.511581200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoded_img (InputLayer)    [(None, 16)]              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 6, 6, 16)          160       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 8, 8, 32)          4640      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 24, 24, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 26, 26, 16)        4624      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 28, 28, 1)         145       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9569 (37.38 KB)\n",
      "Trainable params: 9569 (37.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.772081600Z",
     "start_time": "2023-08-13T21:48:47.596581700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                18672     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         9569      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28241 (110.32 KB)\n",
      "Trainable params: 28241 (110.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.835580400Z",
     "start_time": "2023-08-13T21:48:47.725078900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# composing models by using the Keras.Model with the input and output layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 1)                    129       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 1)                    129       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 1)                    129       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " average (Average)           (None, 1)                    0         ['model[0][0]',               \n",
      "                                                                     'model_1[0][0]',             \n",
      "                                                                     'model_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 387 (1.51 KB)\n",
      "Trainable params: 387 (1.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ensemble model\n",
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "\n",
    "outputs = layers.average([y1, y2, y3]) # average the output of the three models as layer\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "ensemble_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:47.912078700Z",
     "start_time": "2023-08-13T21:48:47.816081100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " title (InputLayer)          [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " body (InputLayer)           [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 64)             640000    ['title[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 64)             640000    ['body[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 128)                  98816     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 32)                   12416     ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " tags (InputLayer)           [(None, 12)]                 0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 172)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'tags[0][0]']                \n",
      "                                                                                                  \n",
      " priority (Dense)            (None, 1)                    173       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " department (Dense)          (None, 4)                    692       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1392097 (5.31 MB)\n",
      "Trainable params: 1392097 (5.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Complex graph topologies\n",
    "\n",
    "# For example, if you're building a system for ranking customer issue tickets by priority and routing them to the correct department, then the model will have three inputs:\n",
    "# \n",
    "# the title of the ticket (text input),\n",
    "# the text body of the ticket (text input), and\n",
    "# any tags added by the user (categorical input)\n",
    "#\n",
    "# This model will have two outputs:\n",
    "# \n",
    "# the priority score between 0 and 1 (scalar sigmoid output), and\n",
    "# the department that should handle the ticket (softmax output over the set of departments).\n",
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name=\"title\")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(shape=(num_tags,), name=\"tags\")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input], # can define multiple inputs\n",
    "    outputs=[priority_pred, department_pred], # can define multiple outputs\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:48.450079200Z",
     "start_time": "2023-08-13T21:48:47.909080300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:48.453578200Z",
     "start_time": "2023-08-13T21:48:48.402082100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "optim = keras.optimizers.RMSprop(1e-3)\n",
    "loss = {\n",
    "    \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "}\n",
    "loss_weights = {\"priority\": 1.0, \"department\": 0.2} # the loss of the priority output is 5 times the loss of the department output\n",
    "model.compile(optimizer=optim, loss=loss, loss_weights=loss_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:48.454577800Z",
     "start_time": "2023-08-13T21:48:48.417580700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40/40 [==============================] - 4s 24ms/step - loss: 1.3169 - priority_loss: 0.6984 - department_loss: 3.0927\n",
      "Epoch 2/2\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 1.3819 - priority_loss: 0.6985 - department_loss: 3.4166\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "History = model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data}, # keys match the input layer names\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets}, # keys match the output layer names\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:53.180581100Z",
     "start_time": "2023-08-13T21:48:48.449079800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet toy model not connected sequentially"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img (InputLayer)            [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)           896       ['img[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 64)           18496     ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 9, 9, 64)             0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 9, 9, 64)             36928     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 9, 9, 64)             36928     ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 9, 9, 64)             0         ['conv2d_7[0][0]',            \n",
      "                                                                     'max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 9, 9, 64)             36928     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 9, 9, 64)             36928     ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 9, 9, 64)             0         ['conv2d_9[0][0]',            \n",
      "                                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 7, 7, 64)             36928     ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 64)                   0         ['conv2d_10[0][0]']           \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  16640     ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 10)                   2570      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 223242 (872.04 KB)\n",
      "Trainable params: 223242 (872.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name=\"img\") # 32x32 RGB images input\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x) # max pooling layer\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output]) # skip connection to the first block\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output]) # skip connection to the second block\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x) # 10 classes output, called functional API because the layers are callable like functions\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:48:53.422079Z",
     "start_time": "2023-08-13T21:48:53.183580600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 - 63s - loss: 1.4755 - categorical_accuracy: 0.4598 - val_loss: 1.2660 - val_categorical_accuracy: 0.5393 - 63s/epoch - 101ms/step\n",
      "Epochs trained: 1\n",
      "625/625 - 57s - loss: 1.2489 - categorical_accuracy: 0.5513 - val_loss: 1.0945 - val_categorical_accuracy: 0.5966 - 57s/epoch - 91ms/step\n",
      "Epochs trained: 2\n",
      "625/625 - 57s - loss: 1.0874 - categorical_accuracy: 0.6147 - val_loss: 0.9787 - val_categorical_accuracy: 0.6495 - 57s/epoch - 92ms/step\n",
      "Epochs trained: 3\n",
      "625/625 - 61s - loss: 0.9627 - categorical_accuracy: 0.6599 - val_loss: 1.1865 - val_categorical_accuracy: 0.6056 - 61s/epoch - 97ms/step\n",
      "Validation loss increased. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0 # normalize the data\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10) # one-hot encoding\n",
    "y_test = keras.utils.to_categorical(y_test, 10) # one-hot encoding\n",
    "\n",
    "optim = keras.optimizers.RMSprop(1e-3)\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metrics = [keras.metrics.CategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss, metrics=metrics)\n",
    "\n",
    "\n",
    "# Train until convergence\n",
    "epochs = 0\n",
    "previous_val_loss = float('inf')\n",
    "while True:\n",
    "    history = model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.2, verbose=2)\n",
    "    \n",
    "    # Check for convergence\n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    if val_loss > previous_val_loss:\n",
    "        print(\"Validation loss increased. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    previous_val_loss = val_loss\n",
    "    epochs += 1\n",
    "    print(f\"Epochs trained: {epochs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T21:59:49.609092900Z",
     "start_time": "2023-08-13T21:55:48.535598300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shared layers and multiple branches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)\n",
    "# NOTE: to share a layer across different inputs, simply instantiate the layer once, then call it on as many inputs as you want."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T22:02:39.934887700Z",
     "start_time": "2023-08-13T22:02:39.899390200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574710816/574710816 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Extract and Reuse Nodes in the Graph of Layers, useful for feature extraction and building complex graphs of layers\n",
    "vgg19 = keras.applications.VGG19()\n",
    "features_list = [layer.output for layer in vgg19.layers]\n",
    "feature_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) # extract features from the VGG19 model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T22:03:00.279672800Z",
     "start_time": "2023-08-13T22:02:43.574739900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
      "array([[[[0.7180326 , 0.81667626, 0.90034145],\n",
      "         [0.5271022 , 0.1656228 , 0.53568804],\n",
      "         [0.52404755, 0.78543353, 0.36643353],\n",
      "         ...,\n",
      "         [0.5591577 , 0.9380828 , 0.22866987],\n",
      "         [0.38242632, 0.38079384, 0.4480558 ],\n",
      "         [0.3188455 , 0.43608773, 0.04878962]],\n",
      "\n",
      "        [[0.37114778, 0.6105545 , 0.16170797],\n",
      "         [0.73311466, 0.92782396, 0.99721014],\n",
      "         [0.77676797, 0.01243306, 0.6632397 ],\n",
      "         ...,\n",
      "         [0.906403  , 0.10811447, 0.9835297 ],\n",
      "         [0.7936445 , 0.12338267, 0.34680247],\n",
      "         [0.980885  , 0.19437666, 0.13995156]],\n",
      "\n",
      "        [[0.7225141 , 0.03970847, 0.7939923 ],\n",
      "         [0.74938434, 0.4180945 , 0.755542  ],\n",
      "         [0.60999465, 0.78831875, 0.6992765 ],\n",
      "         ...,\n",
      "         [0.7255576 , 0.91949815, 0.8065938 ],\n",
      "         [0.9734248 , 0.67175126, 0.76745766],\n",
      "         [0.41174418, 0.5823031 , 0.45413584]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9651948 , 0.36079815, 0.37289166],\n",
      "         [0.8790708 , 0.10489729, 0.5994931 ],\n",
      "         [0.9561759 , 0.9219678 , 0.7986509 ],\n",
      "         ...,\n",
      "         [0.00781089, 0.6316908 , 0.40354207],\n",
      "         [0.5660385 , 0.7324304 , 0.37104252],\n",
      "         [0.41201022, 0.1127385 , 0.40481576]],\n",
      "\n",
      "        [[0.36327472, 0.24536945, 0.30086696],\n",
      "         [0.7511475 , 0.45662737, 0.73139566],\n",
      "         [0.9102231 , 0.9468251 , 0.6368756 ],\n",
      "         ...,\n",
      "         [0.4315439 , 0.4166848 , 0.26928207],\n",
      "         [0.4478278 , 0.37928805, 0.9254133 ],\n",
      "         [0.266807  , 0.0467076 , 0.8879922 ]],\n",
      "\n",
      "        [[0.02314205, 0.8019151 , 0.953297  ],\n",
      "         [0.41669014, 0.27522138, 0.8859712 ],\n",
      "         [0.90708816, 0.36236075, 0.2936672 ],\n",
      "         ...,\n",
      "         [0.5491239 , 0.81555134, 0.67429036],\n",
      "         [0.36678052, 0.77265644, 0.8422163 ],\n",
      "         [0.13921751, 0.20045994, 0.37824452]]]], dtype=float32)>, <tf.Tensor: shape=(1, 224, 224, 64), dtype=float32, numpy=\n",
      "array([[[[0.0000000e+00, 1.8944782e-01, 1.6373233e-01, ...,\n",
      "          4.6467978e-01, 6.8138033e-01, 4.1015458e-01],\n",
      "         [0.0000000e+00, 3.1400743e-01, 4.4272736e-01, ...,\n",
      "          1.1092609e-01, 1.7043313e+00, 1.3571422e+00],\n",
      "         [0.0000000e+00, 2.1099228e-01, 3.2609338e-01, ...,\n",
      "          2.2382289e-01, 1.6390258e+00, 1.2871926e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 4.4860682e-01, 4.1448227e-01, ...,\n",
      "          2.7265286e-01, 1.5446991e+00, 1.3319327e+00],\n",
      "         [9.1039717e-02, 4.2859158e-01, 3.9570320e-01, ...,\n",
      "          2.9203522e-01, 1.5585707e+00, 1.2532128e+00],\n",
      "         [6.9870925e-01, 3.9477217e-01, 3.9756048e-01, ...,\n",
      "          6.8359053e-01, 1.5123529e+00, 1.3497199e+00]],\n",
      "\n",
      "        [[0.0000000e+00, 1.4357969e-01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
      "         [6.8788993e-01, 3.5398167e-01, 3.2373920e-01, ...,\n",
      "          0.0000000e+00, 6.3469195e-01, 7.5038934e-01],\n",
      "         [9.0680742e-01, 2.6906109e-01, 4.0619770e-01, ...,\n",
      "          0.0000000e+00, 1.1884762e+00, 1.2638032e+00],\n",
      "         ...,\n",
      "         [2.0362449e-01, 5.4106152e-01, 3.1200129e-01, ...,\n",
      "          0.0000000e+00, 8.1060708e-01, 5.4882926e-01],\n",
      "         [6.2825286e-01, 5.6326246e-01, 4.5570484e-01, ...,\n",
      "          0.0000000e+00, 1.2593632e+00, 1.0346296e+00],\n",
      "         [1.3699677e+00, 5.3914720e-01, 5.6765610e-01, ...,\n",
      "          3.1500190e-01, 1.7136440e+00, 1.6404190e+00]],\n",
      "\n",
      "        [[0.0000000e+00, 1.4936870e-01, 0.0000000e+00, ...,\n",
      "          1.0385513e-03, 0.0000000e+00, 0.0000000e+00],\n",
      "         [5.4665053e-01, 3.0638635e-01, 3.6692831e-01, ...,\n",
      "          0.0000000e+00, 4.4314364e-01, 5.9160411e-01],\n",
      "         [1.1806241e+00, 2.8201595e-01, 5.0805551e-01, ...,\n",
      "          0.0000000e+00, 1.0186568e+00, 1.1695929e+00],\n",
      "         ...,\n",
      "         [1.0247855e+00, 3.7596101e-01, 4.5936525e-01, ...,\n",
      "          0.0000000e+00, 7.8113073e-01, 1.2500668e+00],\n",
      "         [1.3683171e+00, 4.4114351e-01, 4.8902833e-01, ...,\n",
      "          0.0000000e+00, 1.1028669e+00, 1.4655170e+00],\n",
      "         [2.0210698e+00, 5.1476079e-01, 6.6634637e-01, ...,\n",
      "          2.8520119e-01, 1.7698253e+00, 2.0546892e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000000e+00, 3.4343424e-01, 0.0000000e+00, ...,\n",
      "          1.9891441e-01, 0.0000000e+00, 0.0000000e+00],\n",
      "         [0.0000000e+00, 5.0352085e-01, 2.0049995e-01, ...,\n",
      "          0.0000000e+00, 4.4538075e-01, 2.9443577e-01],\n",
      "         [0.0000000e+00, 5.5246103e-01, 4.5667073e-01, ...,\n",
      "          0.0000000e+00, 1.2123183e+00, 1.0821762e+00],\n",
      "         ...,\n",
      "         [1.3102596e+00, 2.8798833e-01, 3.5165834e-01, ...,\n",
      "          0.0000000e+00, 4.2731822e-01, 6.3015389e-01],\n",
      "         [9.9597013e-01, 1.9461831e-01, 2.4607496e-01, ...,\n",
      "          0.0000000e+00, 6.7807055e-01, 8.1977165e-01],\n",
      "         [1.8454547e+00, 2.3535070e-01, 4.2911953e-01, ...,\n",
      "          3.1371230e-01, 1.5208985e+00, 1.6718245e+00]],\n",
      "\n",
      "        [[0.0000000e+00, 1.0749219e-01, 0.0000000e+00, ...,\n",
      "          9.6148968e-02, 0.0000000e+00, 0.0000000e+00],\n",
      "         [2.3204604e-01, 3.2593957e-01, 9.6141085e-02, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
      "         [1.3996756e+00, 5.3245032e-01, 4.1874534e-01, ...,\n",
      "          0.0000000e+00, 4.6654639e-01, 9.2283922e-01],\n",
      "         ...,\n",
      "         [4.2265132e-01, 2.0231229e-01, 2.3396668e-01, ...,\n",
      "          0.0000000e+00, 3.1004429e-01, 2.5512493e-01],\n",
      "         [8.3411741e-01, 1.7515628e-01, 3.8276640e-01, ...,\n",
      "          0.0000000e+00, 1.0234036e+00, 1.1034305e+00],\n",
      "         [1.9817553e+00, 1.5340000e-01, 4.7823510e-01, ...,\n",
      "          3.5451460e-01, 1.6321287e+00, 1.8423293e+00]],\n",
      "\n",
      "        [[6.2993747e-01, 0.0000000e+00, 3.2192618e-02, ...,\n",
      "          5.3999299e-01, 0.0000000e+00, 1.9667840e-01],\n",
      "         [1.8420374e+00, 1.7781636e-01, 2.6542345e-01, ...,\n",
      "          1.2067205e-01, 0.0000000e+00, 6.3141757e-01],\n",
      "         [2.5042913e+00, 3.3561641e-01, 3.0322734e-01, ...,\n",
      "          5.1851511e-02, 0.0000000e+00, 8.0393815e-01],\n",
      "         ...,\n",
      "         [1.5741798e+00, 1.7793079e-01, 3.5089350e-01, ...,\n",
      "          2.1592534e-01, 7.6346397e-02, 7.8972685e-01],\n",
      "         [2.2897732e+00, 1.2725276e-01, 4.7008538e-01, ...,\n",
      "          3.2896906e-01, 6.9209796e-01, 1.5162089e+00],\n",
      "         [2.4861434e+00, 5.6417637e-02, 3.7519521e-01, ...,\n",
      "          5.8205831e-01, 1.0075953e+00, 1.5461757e+00]]]], dtype=float32)>, <tf.Tensor: shape=(1, 224, 224, 64), dtype=float32, numpy=\n",
      "array([[[[4.101602  , 0.41436982, 1.2901934 , ..., 0.9530645 ,\n",
      "          4.9208484 , 1.7197921 ],\n",
      "         [0.21747738, 0.40713817, 2.44743   , ..., 1.7092156 ,\n",
      "          1.937442  , 1.9342804 ],\n",
      "         [0.        , 0.51085836, 1.7220681 , ..., 1.8910031 ,\n",
      "          0.        , 1.6371737 ],\n",
      "         ...,\n",
      "         [0.46972495, 0.6578529 , 3.9785018 , ..., 1.1334331 ,\n",
      "          0.4635853 , 2.1359668 ],\n",
      "         [0.        , 0.        , 4.1492324 , ..., 0.85151523,\n",
      "          0.        , 2.2730327 ],\n",
      "         [0.        , 0.06348985, 2.5885818 , ..., 0.7110639 ,\n",
      "          0.        , 1.0266228 ]],\n",
      "\n",
      "        [[1.9101791 , 0.14935444, 2.3226035 , ..., 1.5319316 ,\n",
      "          4.674472  , 0.46660906],\n",
      "         [0.        , 0.        , 4.146816  , ..., 2.501918  ,\n",
      "          7.452686  , 0.06324679],\n",
      "         [0.        , 0.        , 2.9739885 , ..., 2.7265575 ,\n",
      "          2.2216282 , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 6.384122  , ..., 2.3539343 ,\n",
      "          4.4701986 , 0.24203461],\n",
      "         [0.        , 0.        , 6.7768154 , ..., 1.853614  ,\n",
      "          3.3607414 , 0.5396716 ],\n",
      "         [0.        , 0.        , 4.146415  , ..., 1.5455029 ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[2.5439744 , 1.0733397 , 2.119181  , ..., 1.6952225 ,\n",
      "          1.5322896 , 0.4316575 ],\n",
      "         [0.        , 0.28237754, 3.8126569 , ..., 2.3086686 ,\n",
      "          5.619132  , 0.26703137],\n",
      "         [0.        , 0.        , 2.6116188 , ..., 2.0412564 ,\n",
      "          3.1819465 , 0.3819552 ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 5.8299007 , ..., 2.0436757 ,\n",
      "          5.4914722 , 0.2473802 ],\n",
      "         [0.        , 0.        , 6.3587394 , ..., 1.5323806 ,\n",
      "          5.6913114 , 0.5500341 ],\n",
      "         [0.        , 0.        , 3.8243127 , ..., 1.4955629 ,\n",
      "          0.5468958 , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.9978971 , 1.5254006 , 4.4783783 , ..., 1.6654205 ,\n",
      "          1.8697988 , 0.6708291 ],\n",
      "         [2.8033462 , 2.3439252 , 7.3978124 , ..., 2.835499  ,\n",
      "          5.673232  , 0.5080568 ],\n",
      "         [0.26334482, 1.6928658 , 6.84343   , ..., 2.903539  ,\n",
      "          2.8155978 , 0.38206905],\n",
      "         ...,\n",
      "         [1.377759  , 0.        , 3.0986009 , ..., 1.7323617 ,\n",
      "          2.014758  , 0.837019  ],\n",
      "         [2.208395  , 0.        , 3.8512087 , ..., 2.2376652 ,\n",
      "          3.6558986 , 0.9983627 ],\n",
      "         [0.6648528 , 0.3115402 , 2.1006722 , ..., 2.251381  ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[1.6810884 , 0.20802706, 3.4881437 , ..., 1.9819351 ,\n",
      "          1.1145049 , 0.9140665 ],\n",
      "         [0.        , 0.        , 6.5779724 , ..., 2.5407643 ,\n",
      "          4.383207  , 1.4502845 ],\n",
      "         [0.        , 0.        , 6.7989564 , ..., 1.7825838 ,\n",
      "          5.3699713 , 2.108687  ],\n",
      "         ...,\n",
      "         [2.7269247 , 0.        , 2.602928  , ..., 2.4642594 ,\n",
      "          3.3138776 , 1.7381613 ],\n",
      "         [0.        , 0.        , 2.9142568 , ..., 2.5875578 ,\n",
      "          3.77007   , 1.5985465 ],\n",
      "         [0.        , 0.        , 1.3537312 , ..., 2.3053403 ,\n",
      "          0.17945068, 0.2366755 ]],\n",
      "\n",
      "        [[0.        , 0.28015202, 1.6145815 , ..., 1.252823  ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 3.4594183 , ..., 1.3851316 ,\n",
      "          1.1621407 , 0.        ],\n",
      "         [0.        , 0.        , 4.025862  , ..., 1.0245726 ,\n",
      "          2.0110595 , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 1.4667348 , ..., 1.27988   ,\n",
      "          3.5223832 , 0.        ],\n",
      "         [0.        , 0.        , 1.3952602 , ..., 1.3260205 ,\n",
      "          5.1033583 , 0.        ],\n",
      "         [2.6903114 , 0.10711378, 0.4787867 , ..., 1.7160717 ,\n",
      "          2.851231  , 0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 112, 112, 64), dtype=float32, numpy=\n",
      "array([[[[4.101602  , 0.41436982, 4.146816  , ..., 2.501918  ,\n",
      "          7.452686  , 1.9342804 ],\n",
      "         [1.5383515 , 1.2243555 , 2.9739885 , ..., 3.0653496 ,\n",
      "          2.2216282 , 1.7225947 ],\n",
      "         [2.8121877 , 1.3191576 , 2.485616  , ..., 2.3858292 ,\n",
      "          3.9616952 , 1.475178  ],\n",
      "         ...,\n",
      "         [2.2978864 , 0.4564185 , 4.5466537 , ..., 1.8915257 ,\n",
      "          4.5857487 , 1.6227949 ],\n",
      "         [0.931632  , 0.7272294 , 6.384122  , ..., 2.3539343 ,\n",
      "          4.4701986 , 2.1359668 ],\n",
      "         [0.        , 0.06348985, 6.7768154 , ..., 1.853614  ,\n",
      "          3.3607414 , 2.2730327 ]],\n",
      "\n",
      "        [[2.5439744 , 1.0733397 , 3.8126569 , ..., 2.3086686 ,\n",
      "          5.619132  , 0.4316575 ],\n",
      "         [1.7112083 , 0.15616733, 2.6116188 , ..., 2.0412564 ,\n",
      "          3.5265899 , 0.9571406 ],\n",
      "         [0.88156754, 0.33478796, 4.6180415 , ..., 1.0524095 ,\n",
      "          3.3455312 , 1.1127274 ],\n",
      "         ...,\n",
      "         [2.2131119 , 2.1588693 , 4.9478774 , ..., 2.3235178 ,\n",
      "          3.51424   , 1.2621768 ],\n",
      "         [2.7990603 , 0.4837493 , 5.8299007 , ..., 2.1780019 ,\n",
      "          5.4914722 , 1.3686762 ],\n",
      "         [1.364356  , 0.        , 6.3587394 , ..., 1.5933045 ,\n",
      "          5.6913114 , 1.1064615 ]],\n",
      "\n",
      "        [[0.        , 0.36122447, 2.5623262 , ..., 2.1022196 ,\n",
      "          1.9399234 , 0.71853536],\n",
      "         [4.6727643 , 1.8995409 , 2.3317542 , ..., 1.9009733 ,\n",
      "          5.791891  , 0.9651323 ],\n",
      "         [2.4712083 , 2.4927876 , 3.703384  , ..., 1.610211  ,\n",
      "          6.43944   , 1.6074147 ],\n",
      "         ...,\n",
      "         [3.7168307 , 2.882737  , 4.2500806 , ..., 2.8811364 ,\n",
      "          3.635445  , 0.73976535],\n",
      "         [2.3975308 , 2.5536911 , 4.89703   , ..., 2.8048477 ,\n",
      "          1.8589114 , 0.69450814],\n",
      "         [1.0263658 , 0.        , 4.7368174 , ..., 1.609958  ,\n",
      "          4.4442186 , 1.0032601 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.9886937 , 0.4561633 , 4.9800587 , ..., 1.6762195 ,\n",
      "          3.3124838 , 0.9545066 ],\n",
      "         [8.242253  , 2.9222977 , 4.345767  , ..., 1.7545533 ,\n",
      "          1.7600327 , 1.5039859 ],\n",
      "         [5.958666  , 4.127318  , 6.1319    , ..., 2.1044486 ,\n",
      "          2.1702108 , 1.5017831 ],\n",
      "         ...,\n",
      "         [3.447702  , 2.0970342 , 4.272306  , ..., 2.6058843 ,\n",
      "          1.8868809 , 1.0616217 ],\n",
      "         [4.9606833 , 2.637118  , 7.3389215 , ..., 2.5854008 ,\n",
      "          2.6507885 , 1.0627177 ],\n",
      "         [0.81062   , 0.        , 7.1612062 , ..., 1.8383048 ,\n",
      "          1.9106063 , 0.89127237]],\n",
      "\n",
      "        [[2.9978971 , 2.3439252 , 7.3978124 , ..., 2.835499  ,\n",
      "          5.673232  , 1.5095358 ],\n",
      "         [6.6988335 , 4.1842933 , 6.84343   , ..., 2.903539  ,\n",
      "          2.8155978 , 1.5612366 ],\n",
      "         [0.        , 1.2173195 , 5.974735  , ..., 1.8082922 ,\n",
      "          3.4678738 , 0.66893643],\n",
      "         ...,\n",
      "         [3.3365855 , 1.4258962 , 2.8832226 , ..., 2.4853346 ,\n",
      "          3.4971623 , 0.80835885],\n",
      "         [1.377759  , 0.14489502, 5.0319915 , ..., 2.138118  ,\n",
      "          2.710286  , 0.837019  ],\n",
      "         [2.208395  , 0.31756097, 5.5983586 , ..., 2.251381  ,\n",
      "          4.2496634 , 0.9983627 ]],\n",
      "\n",
      "        [[1.6810884 , 0.28015202, 6.5779724 , ..., 2.5407643 ,\n",
      "          4.383207  , 1.4502845 ],\n",
      "         [2.67194   , 0.42924768, 6.7989564 , ..., 1.8473746 ,\n",
      "          5.3699713 , 2.3744326 ],\n",
      "         [2.0470717 , 1.0164363 , 4.317527  , ..., 2.3834045 ,\n",
      "          5.0538316 , 2.165646  ],\n",
      "         ...,\n",
      "         [1.0433381 , 0.        , 2.8959453 , ..., 1.5913986 ,\n",
      "          0.73250467, 2.0461888 ],\n",
      "         [2.7269247 , 0.26955265, 2.6193666 , ..., 2.4642594 ,\n",
      "          4.3098907 , 1.7707794 ],\n",
      "         [2.6903114 , 0.10711378, 2.9142568 , ..., 2.5875578 ,\n",
      "          5.1033583 , 1.5985465 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 112, 112, 128), dtype=float32, numpy=\n",
      "array([[[[ 0.        ,  0.        ,  0.        , ...,  8.491038  ,\n",
      "           0.        , 13.667509  ],\n",
      "         [ 0.        ,  0.        ,  3.118383  , ...,  1.136745  ,\n",
      "           0.        ,  0.98137516],\n",
      "         [ 0.        ,  0.        ,  1.7081164 , ...,  4.896898  ,\n",
      "           0.        ,  2.5609586 ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.759696  , ...,  3.3832757 ,\n",
      "           0.        ,  1.7557329 ],\n",
      "         [ 0.        ,  0.        ,  2.1441708 , ...,  5.1372075 ,\n",
      "           0.        ,  2.02773   ],\n",
      "         [ 0.        ,  0.        ,  7.8584313 , ...,  9.272415  ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  6.0334578 ,  0.        , ...,  9.722811  ,\n",
      "           1.5866251 , 16.041813  ],\n",
      "         [ 0.        ,  3.8690143 ,  3.0513077 , ...,  1.3986712 ,\n",
      "           0.        ,  2.4012372 ],\n",
      "         [ 0.        ,  0.44459984,  2.4234698 , ...,  2.0004773 ,\n",
      "           3.450967  ,  2.5323787 ],\n",
      "         ...,\n",
      "         [ 0.        ,  2.2772965 ,  0.        , ...,  5.061158  ,\n",
      "           1.6521475 ,  1.8387905 ],\n",
      "         [ 0.        ,  3.4299963 ,  0.38501582, ...,  7.9412856 ,\n",
      "           1.8627113 ,  1.0123988 ],\n",
      "         [ 0.        ,  1.4073427 , 10.477902  , ..., 14.457227  ,\n",
      "           1.4531292 ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  2.5680456 ,  0.        , ...,  7.4513655 ,\n",
      "           0.        , 15.995928  ],\n",
      "         [ 0.        ,  1.1309044 ,  0.        , ...,  3.7622213 ,\n",
      "           0.        ,  4.587825  ],\n",
      "         [ 0.        ,  0.        ,  2.7255921 , ...,  4.7071867 ,\n",
      "           0.        ,  3.6131506 ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  5.189819  ,\n",
      "           0.        ,  1.6462029 ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  7.7761593 ,\n",
      "           0.        ,  0.6414673 ],\n",
      "         [ 0.        ,  0.        ,  8.104734  , ..., 15.970246  ,\n",
      "           3.3621297 ,  0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        ,  1.9730272 ,  0.        , ..., 10.52288   ,\n",
      "           0.        , 18.51725   ],\n",
      "         [ 0.        ,  0.        ,  2.395433  , ...,  7.5782347 ,\n",
      "           0.        ,  2.2617972 ],\n",
      "         [ 0.        ,  0.        ,  1.5209321 , ...,  5.526111  ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  4.201752  ,\n",
      "           1.0443124 ,  0.        ],\n",
      "         [ 0.        ,  0.70256114,  0.30092016, ...,  9.3716    ,\n",
      "           0.        ,  1.7978716 ],\n",
      "         [ 0.        ,  0.        ,  8.338804  , ..., 12.240727  ,\n",
      "           3.3898714 ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.803185  ,  0.        , ...,  4.8639455 ,\n",
      "           0.        , 20.405766  ],\n",
      "         [ 0.        ,  0.9546528 ,  0.        , ...,  1.7463431 ,\n",
      "           0.        ,  3.11263   ],\n",
      "         [ 0.        ,  1.0895276 ,  1.3750117 , ...,  9.272143  ,\n",
      "           1.6882178 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.37626013, ...,  1.7832626 ,\n",
      "           0.49779612,  0.        ],\n",
      "         [ 0.        ,  2.7372816 ,  0.63369775, ...,  9.126601  ,\n",
      "           5.0445757 ,  1.2009174 ],\n",
      "         [ 0.        ,  1.4095068 , 10.101225  , ...,  8.489612  ,\n",
      "           1.8621478 ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  5.170978  ,  0.        , ...,  8.209172  ,\n",
      "           0.87785107, 15.381507  ],\n",
      "         [ 0.        ,  5.9168787 ,  1.2799532 , ...,  7.970084  ,\n",
      "           0.71718055,  2.1401842 ],\n",
      "         [ 0.        ,  4.7057834 ,  2.7212696 , ...,  7.111281  ,\n",
      "           2.1398766 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  3.2351112 ,  3.160265  , ...,  5.5200086 ,\n",
      "           0.        ,  0.7235505 ],\n",
      "         [ 0.        ,  4.4497066 ,  1.0817909 , ...,  7.1973076 ,\n",
      "           3.2238066 ,  1.127452  ],\n",
      "         [ 0.        ,  3.4810457 ,  7.960417  , ..., 11.179475  ,\n",
      "           0.85008913,  0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 112, 112, 128), dtype=float32, numpy=\n",
      "array([[[[2.34223390e+00, 6.53188944e+00, 9.38884854e-01, ...,\n",
      "          5.28564274e-01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [7.26437283e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          6.61791611e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "         [2.44161725e+00, 1.78284454e+00, 0.00000000e+00, ...,\n",
      "          7.10591793e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [4.90128422e+00, 1.14065671e+00, 0.00000000e+00, ...,\n",
      "          1.32602711e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [7.03610992e+00, 6.87914896e+00, 0.00000000e+00, ...,\n",
      "          1.54569769e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [8.02289581e+00, 0.00000000e+00, 2.02201501e-01, ...,\n",
      "          1.30753107e+01, 0.00000000e+00, 2.00488758e+00]],\n",
      "\n",
      "        [[0.00000000e+00, 4.96830940e+00, 0.00000000e+00, ...,\n",
      "          2.96452641e+00, 1.32933683e+01, 0.00000000e+00],\n",
      "         [9.85440910e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.29321795e+01, 5.72804451e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.29978266e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [4.49083424e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          2.39125214e+01, 3.50219059e+00, 0.00000000e+00],\n",
      "         [4.13019085e+00, 1.60583234e+00, 0.00000000e+00, ...,\n",
      "          2.69934311e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [6.70908260e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          2.10249996e+01, 0.00000000e+00, 1.49669874e+00]],\n",
      "\n",
      "        [[0.00000000e+00, 4.56308985e+00, 0.00000000e+00, ...,\n",
      "          3.16920090e+00, 1.98254700e+01, 0.00000000e+00],\n",
      "         [2.09330529e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.30499659e+01, 9.09366703e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.43468132e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [2.72859883e+00, 0.00000000e+00, 7.72052526e-01, ...,\n",
      "          2.49748058e+01, 9.01875019e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 1.41024947e+00, 0.00000000e+00, ...,\n",
      "          2.64155807e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [1.61413693e+00, 0.00000000e+00, 3.45140755e-01, ...,\n",
      "          1.95250816e+01, 0.00000000e+00, 0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.00000000e+00, 5.88321972e+00, 3.98687601e+00, ...,\n",
      "          5.21233892e+00, 1.76977921e+01, 0.00000000e+00],\n",
      "         [6.33055782e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          2.00387173e+01, 6.26774979e+00, 0.00000000e+00],\n",
      "         [4.37796021e+00, 0.00000000e+00, 1.62307560e+00, ...,\n",
      "          2.03912716e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [5.88336527e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.27387085e+01, 3.20682526e+00, 0.00000000e+00],\n",
      "         [2.63515496e+00, 3.26954269e+00, 8.67718029e+00, ...,\n",
      "          1.39255848e+01, 0.00000000e+00, 0.00000000e+00],\n",
      "         [7.65925980e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.24843321e+01, 0.00000000e+00, 3.80499315e+00]],\n",
      "\n",
      "        [[1.17030799e+00, 3.78632879e+00, 0.00000000e+00, ...,\n",
      "          5.27061701e+00, 2.19693909e+01, 0.00000000e+00],\n",
      "         [1.02039738e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.93248672e+01, 1.35434942e+01, 0.00000000e+00],\n",
      "         [8.64522171e+00, 0.00000000e+00, 1.34954989e+00, ...,\n",
      "          1.74617329e+01, 6.17096329e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [0.00000000e+00, 0.00000000e+00, 1.22011518e+00, ...,\n",
      "          1.36764355e+01, 9.40668583e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 2.56459332e+00, 3.76516008e+00, ...,\n",
      "          1.38442450e+01, 2.46335253e-01, 0.00000000e+00],\n",
      "         [5.50751829e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.11510010e+01, 0.00000000e+00, 5.38983965e+00]],\n",
      "\n",
      "        [[0.00000000e+00, 6.49494678e-03, 3.36299777e+00, ...,\n",
      "          0.00000000e+00, 2.49106159e+01, 0.00000000e+00],\n",
      "         [9.94546786e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          6.11164808e+00, 1.76581173e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          4.99439287e+00, 9.20850849e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [0.00000000e+00, 0.00000000e+00, 9.89291310e-01, ...,\n",
      "          4.67034674e+00, 1.13806829e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          3.85364532e+00, 3.48669434e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          4.15009642e+00, 0.00000000e+00, 2.78842497e+00]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(1, 56, 56, 128), dtype=float32, numpy=\n",
      "array([[[[7.26437283e+00, 6.53188944e+00, 9.38884854e-01, ...,\n",
      "          1.29321795e+01, 1.32933683e+01, 0.00000000e+00],\n",
      "         [2.44161725e+00, 3.05316925e+00, 0.00000000e+00, ...,\n",
      "          1.47986012e+01, 0.00000000e+00, 2.28085256e+00],\n",
      "         [8.71678352e+00, 4.98842859e+00, 0.00000000e+00, ...,\n",
      "          1.57874508e+01, 5.30975819e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [6.34601307e+00, 1.60029650e+00, 2.58747578e+00, ...,\n",
      "          2.04271832e+01, 1.64457333e+00, 0.00000000e+00],\n",
      "         [5.11108589e+00, 1.14065671e+00, 0.00000000e+00, ...,\n",
      "          2.39125214e+01, 6.16186237e+00, 0.00000000e+00],\n",
      "         [8.02289581e+00, 6.87914896e+00, 2.02201501e-01, ...,\n",
      "          2.69934311e+01, 0.00000000e+00, 2.00488758e+00]],\n",
      "\n",
      "        [[1.54219007e+00, 4.59250450e+00, 0.00000000e+00, ...,\n",
      "          1.30499659e+01, 2.38297691e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.55597000e+01, 6.36568165e+00, 3.05449677e+00],\n",
      "         [1.27309418e+00, 3.91897857e-01, 1.67272699e+00, ...,\n",
      "          1.62662601e+01, 8.66881084e+00, 0.00000000e+00],\n",
      "         ...,\n",
      "         [3.54280424e+00, 0.00000000e+00, 8.50873709e-01, ...,\n",
      "          2.09856319e+01, 7.01446247e+00, 0.00000000e+00],\n",
      "         [4.37633133e+00, 0.00000000e+00, 7.72052526e-01, ...,\n",
      "          2.70185661e+01, 1.13626633e+01, 0.00000000e+00],\n",
      "         [1.82721138e+00, 1.41024947e+00, 3.45140755e-01, ...,\n",
      "          2.64155807e+01, 2.17907876e-02, 0.00000000e+00]],\n",
      "\n",
      "        [[5.54626226e+00, 4.32759047e+00, 4.62649441e+00, ...,\n",
      "          1.33253164e+01, 2.22960777e+01, 0.00000000e+00],\n",
      "         [1.18098593e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.30229206e+01, 1.14513588e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 4.12991953e+00, ...,\n",
      "          1.38824482e+01, 1.14463625e+01, 0.00000000e+00],\n",
      "         ...,\n",
      "         [8.87253761e+00, 0.00000000e+00, 3.63149166e+00, ...,\n",
      "          1.95015507e+01, 7.88415003e+00, 0.00000000e+00],\n",
      "         [8.16511440e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          2.17289276e+01, 1.39473553e+01, 0.00000000e+00],\n",
      "         [1.26624651e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.93166714e+01, 2.79703164e+00, 0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[5.78967476e+00, 4.58028316e+00, 3.12621045e+00, ...,\n",
      "          1.76881142e+01, 2.24873924e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.58917494e+01, 9.46082115e+00, 0.00000000e+00],\n",
      "         [4.77915573e+00, 0.00000000e+00, 2.60590672e+00, ...,\n",
      "          1.60106564e+01, 1.06712446e+01, 0.00000000e+00],\n",
      "         ...,\n",
      "         [1.66918027e+00, 0.00000000e+00, 4.46703970e-01, ...,\n",
      "          2.16730499e+01, 8.23280811e+00, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 4.68539953e+00, ...,\n",
      "          1.83891029e+01, 1.03349981e+01, 0.00000000e+00],\n",
      "         [8.51397038e+00, 0.00000000e+00, 3.56529903e+00, ...,\n",
      "          1.36059980e+01, 1.86582839e+00, 0.00000000e+00]],\n",
      "\n",
      "        [[6.33055782e+00, 6.35721207e+00, 3.98687601e+00, ...,\n",
      "          2.00387173e+01, 1.76977921e+01, 0.00000000e+00],\n",
      "         [4.37796021e+00, 0.00000000e+00, 1.62307560e+00, ...,\n",
      "          2.03912716e+01, 3.46879911e+00, 0.00000000e+00],\n",
      "         [6.01679611e+00, 0.00000000e+00, 4.01286602e+00, ...,\n",
      "          1.80435963e+01, 1.04764576e+01, 0.00000000e+00],\n",
      "         ...,\n",
      "         [6.19463062e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.70913372e+01, 1.17322483e+01, 0.00000000e+00],\n",
      "         [3.12667513e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.70091953e+01, 6.97336054e+00, 0.00000000e+00],\n",
      "         [7.65925980e+00, 3.26954269e+00, 8.67718029e+00, ...,\n",
      "          1.39255848e+01, 4.11407471e-01, 3.80499315e+00]],\n",
      "\n",
      "        [[1.02039738e+01, 3.78632879e+00, 3.36299777e+00, ...,\n",
      "          1.93248672e+01, 2.49106159e+01, 0.00000000e+00],\n",
      "         [8.64522171e+00, 0.00000000e+00, 1.34954989e+00, ...,\n",
      "          1.74617329e+01, 9.52329540e+00, 0.00000000e+00],\n",
      "         [1.17341738e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "          1.07688828e+01, 1.22937155e+01, 0.00000000e+00],\n",
      "         ...,\n",
      "         [3.42675352e+00, 3.54509532e-01, 1.39590490e+00, ...,\n",
      "          1.53968439e+01, 1.70184460e+01, 0.00000000e+00],\n",
      "         [0.00000000e+00, 0.00000000e+00, 1.22011518e+00, ...,\n",
      "          1.54720078e+01, 1.13806829e+01, 0.00000000e+00],\n",
      "         [5.50751829e+00, 2.56459332e+00, 3.76516008e+00, ...,\n",
      "          1.38442450e+01, 3.48669434e+00, 5.38983965e+00]]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(1, 56, 56, 256), dtype=float32, numpy=\n",
      "array([[[[ 0.        ,  2.8352368 ,  1.6954705 , ...,  0.        ,\n",
      "           3.5934753 , 16.536783  ],\n",
      "         [ 0.        ,  0.92546314,  2.1252449 , ...,  0.        ,\n",
      "           4.0354867 , 17.287607  ],\n",
      "         [ 0.        ,  0.        ,  2.6973293 , ...,  0.        ,\n",
      "           7.6807857 , 16.491213  ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        , 15.449054  ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        , 15.899049  ],\n",
      "         [ 0.        ,  3.3643036 ,  0.        , ...,  0.        ,\n",
      "           1.0830084 , 18.705206  ]],\n",
      "\n",
      "        [[ 0.41520983,  0.3990551 ,  6.369743  , ...,  0.        ,\n",
      "           2.4991913 ,  6.0952725 ],\n",
      "         [ 0.37330544,  0.        ,  8.718728  , ...,  0.        ,\n",
      "           4.492685  ,  5.048744  ],\n",
      "         [ 0.10563614,  0.        ,  8.28298   , ...,  0.        ,\n",
      "          14.878824  ,  9.544109  ],\n",
      "         ...,\n",
      "         [ 3.3897624 ,  0.        ,  5.175863  , ...,  0.        ,\n",
      "           0.8481955 , 13.502342  ],\n",
      "         [ 4.8608556 ,  0.        ,  6.2393537 , ...,  0.        ,\n",
      "           0.        , 13.181096  ],\n",
      "         [ 0.        ,  0.06265174,  4.7278223 , ...,  0.35383916,\n",
      "           0.        , 18.276188  ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  2.8094804 , ...,  0.        ,\n",
      "           0.        ,  4.8992987 ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  1.4756907 ],\n",
      "         [ 2.5464854 ,  0.        ,  0.        , ...,  0.        ,\n",
      "           8.345131  ,  6.9082546 ],\n",
      "         ...,\n",
      "         [ 6.8590426 ,  0.        ,  0.        , ...,  3.5612009 ,\n",
      "          10.530471  , 11.208231  ],\n",
      "         [ 9.760299  ,  0.        ,  0.53130454, ...,  3.2324395 ,\n",
      "           1.3274375 ,  9.938229  ],\n",
      "         [ 0.        ,  3.6409864 ,  3.0305746 , ...,  4.5825486 ,\n",
      "           0.        , 17.554808  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.8894977 ,  9.800175  ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.5668865 ,\n",
      "           0.        ,  5.0756893 ],\n",
      "         [ 4.7597995 ,  0.        ,  0.        , ...,  4.565839  ,\n",
      "           3.0149045 ,  8.79083   ],\n",
      "         ...,\n",
      "         [ 1.5503348 ,  0.        ,  2.9743364 , ...,  0.        ,\n",
      "           0.        ,  0.6388035 ],\n",
      "         [ 3.445653  ,  0.        ,  2.9669259 , ...,  0.        ,\n",
      "           1.4741081 ,  2.4884624 ],\n",
      "         [ 0.        ,  0.        ,  1.6101278 , ...,  0.        ,\n",
      "           1.4603624 , 11.547784  ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  4.702917  , ...,  0.        ,\n",
      "           0.85975736,  7.5706224 ],\n",
      "         [ 0.67301   ,  0.        ,  5.16187   , ...,  0.5070663 ,\n",
      "           0.        ,  0.756854  ],\n",
      "         [ 6.4403815 ,  0.        ,  3.599923  , ...,  2.4337342 ,\n",
      "           0.7062729 ,  3.3677568 ],\n",
      "         ...,\n",
      "         [ 5.3550024 ,  1.0850698 ,  5.062018  , ...,  0.        ,\n",
      "           0.        ,  0.10350895],\n",
      "         [ 9.27226   ,  0.88396674,  5.6435814 , ...,  0.        ,\n",
      "           0.        ,  0.74234784],\n",
      "         [ 0.        ,  0.        ,  3.4946275 , ...,  0.        ,\n",
      "           3.8846588 , 12.847264  ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "          13.827447  ,  8.566392  ],\n",
      "         [ 1.4127039 ,  0.        ,  0.        , ...,  0.31425637,\n",
      "          13.527149  ,  5.260052  ],\n",
      "         [ 2.4188619 ,  4.3665395 ,  0.        , ...,  0.47539955,\n",
      "          13.9128475 ,  3.0815792 ],\n",
      "         ...,\n",
      "         [ 1.7611034 ,  7.81701   ,  0.        , ...,  0.5394165 ,\n",
      "           6.8878803 ,  2.82207   ],\n",
      "         [ 3.970652  ,  9.663219  ,  0.        , ...,  0.        ,\n",
      "           9.481085  ,  1.8568138 ],\n",
      "         [ 0.        ,  2.1820593 ,  0.        , ...,  0.        ,\n",
      "          10.563241  ,  8.567971  ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 56, 56, 256), dtype=float32, numpy=\n",
      "array([[[[ 3.728035  ,  0.        ,  9.803428  , ...,  0.        ,\n",
      "          11.5398445 ,  2.6524074 ],\n",
      "         [ 0.        ,  0.        ,  0.4433079 , ...,  0.        ,\n",
      "          11.033316  ,  9.277345  ],\n",
      "         [10.374089  ,  0.        ,  3.450494  , ...,  0.        ,\n",
      "           6.1597695 ,  3.2377257 ],\n",
      "         ...,\n",
      "         [ 3.0680594 ,  0.        ,  2.3838801 , ...,  0.        ,\n",
      "           7.888244  ,  2.904089  ],\n",
      "         [ 5.3073287 ,  0.        ,  1.3639877 , ...,  0.        ,\n",
      "           8.935981  ,  0.        ],\n",
      "         [ 7.6040626 ,  0.79499286,  5.720859  , ...,  0.        ,\n",
      "           0.16411033,  3.904795  ]],\n",
      "\n",
      "        [[ 0.        ,  5.18933   ,  7.6739063 , ...,  0.        ,\n",
      "          11.153379  ,  2.2384088 ],\n",
      "         [ 0.        ,  6.07193   ,  2.1576953 , ...,  0.        ,\n",
      "          10.705907  ,  7.691281  ],\n",
      "         [ 6.0539303 ,  4.917732  ,  0.        , ...,  0.        ,\n",
      "           3.6890056 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  7.07678   ,  0.        , ...,  0.        ,\n",
      "           8.693061  ,  0.        ],\n",
      "         [ 0.        ,  2.884876  ,  0.        , ...,  0.        ,\n",
      "          12.195775  ,  0.        ],\n",
      "         [ 4.3251624 ,  7.814409  ,  2.5427387 , ...,  0.        ,\n",
      "           0.        ,  2.4518719 ]],\n",
      "\n",
      "        [[ 0.03613769,  7.300664  ,  6.5424232 , ...,  2.5567322 ,\n",
      "           6.7597327 ,  0.7758577 ],\n",
      "         [ 0.        ,  8.963449  ,  6.663956  , ...,  1.822368  ,\n",
      "           3.1144814 ,  1.7700084 ],\n",
      "         [ 6.453923  ,  8.327873  ,  1.2368051 , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  5.009763  ,  0.        , ...,  0.        ,\n",
      "           4.3718886 ,  0.        ],\n",
      "         [ 0.        ,  1.6663533 ,  0.        , ...,  0.        ,\n",
      "          11.084536  ,  0.        ],\n",
      "         [ 7.2467303 ,  7.566327  ,  4.560135  , ...,  0.        ,\n",
      "           0.        ,  0.5500191 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.318931  ,  4.5447536 ,  5.194753  , ...,  1.3932154 ,\n",
      "          13.259475  ,  0.        ],\n",
      "         [ 0.        ,  0.2401649 ,  0.        , ...,  3.3689754 ,\n",
      "           9.57477   ,  2.0786982 ],\n",
      "         [ 2.4905262 ,  1.3307605 ,  0.        , ...,  1.355066  ,\n",
      "           1.8148501 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  1.2437724 ,  3.6300435 , ...,  0.53201103,\n",
      "           6.569003  ,  0.        ],\n",
      "         [ 0.        ,  2.665698  ,  0.        , ...,  0.86773944,\n",
      "           5.636554  ,  0.        ],\n",
      "         [10.054821  ,  9.28434   ,  6.4072647 , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 4.525038  , 10.463641  ,  3.169278  , ...,  4.2256675 ,\n",
      "          12.27229   ,  0.9678198 ],\n",
      "         [ 0.        ,  8.132772  ,  0.2644191 , ...,  4.717997  ,\n",
      "          10.986945  ,  3.3474805 ],\n",
      "         [ 0.        ,  5.2630196 ,  0.        , ...,  3.6732442 ,\n",
      "           7.169562  ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  7.658203  ,  6.85452   , ...,  3.918264  ,\n",
      "           5.682568  ,  0.        ],\n",
      "         [ 0.        , 10.21576   ,  2.665009  , ...,  0.9045805 ,\n",
      "           8.167407  ,  0.        ],\n",
      "         [ 7.134471  , 13.420758  ,  3.0396266 , ...,  0.        ,\n",
      "           0.07101875,  0.        ]],\n",
      "\n",
      "        [[18.10849   , 11.978896  ,  2.9039383 , ...,  5.571561  ,\n",
      "          11.6806    ,  2.280245  ],\n",
      "         [10.54582   , 17.037792  ,  2.973747  , ...,  3.6083436 ,\n",
      "          10.5184965 ,  3.8908107 ],\n",
      "         [10.27314   , 14.316068  ,  4.305588  , ...,  2.6479952 ,\n",
      "           8.84507   ,  0.        ],\n",
      "         ...,\n",
      "         [ 2.6834402 , 10.96585   ,  4.1109524 , ...,  4.5314283 ,\n",
      "           5.552769  ,  0.        ],\n",
      "         [ 1.7281687 , 15.6598    ,  9.943359  , ...,  6.244738  ,\n",
      "           7.288281  ,  0.        ],\n",
      "         [14.766622  , 14.106253  ,  7.4384394 , ...,  1.495295  ,\n",
      "           2.975722  ,  0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 56, 56, 256), dtype=float32, numpy=\n",
      "array([[[[17.3019    ,  3.9737597 ,  7.5468698 , ...,  8.026865  ,\n",
      "          15.03053   ,  7.669222  ],\n",
      "         [10.49979   , 13.468229  , 10.526508  , ..., 10.174164  ,\n",
      "          13.623318  , 10.841372  ],\n",
      "         [13.118553  , 13.786669  , 11.346485  , ..., 10.464704  ,\n",
      "           2.776165  ,  0.15166534],\n",
      "         ...,\n",
      "         [ 4.3797474 , 12.484746  , 13.70312   , ..., 13.174     ,\n",
      "           6.7616744 ,  0.9779663 ],\n",
      "         [ 5.646952  , 13.325034  , 16.098316  , ..., 14.006048  ,\n",
      "          12.7806835 ,  0.03824748],\n",
      "         [ 9.430725  ,  8.245924  , 10.796462  , ..., 12.326183  ,\n",
      "          11.433857  ,  0.07455964]],\n",
      "\n",
      "        [[20.504301  ,  9.303521  ,  7.9283676 , ...,  4.4827332 ,\n",
      "          24.920149  ,  6.599332  ],\n",
      "         [12.10409   , 21.878061  ,  8.682847  , ...,  3.447134  ,\n",
      "          22.408897  ,  9.298693  ],\n",
      "         [ 6.202225  , 19.928625  ,  8.208317  , ...,  3.4970536 ,\n",
      "           6.0486345 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 18.462538  , 14.529543  , ...,  7.550863  ,\n",
      "           5.931801  ,  0.        ],\n",
      "         [ 0.        , 18.475548  , 17.66845   , ..., 10.932561  ,\n",
      "          16.249334  ,  0.7720579 ],\n",
      "         [ 8.816843  , 12.54071   , 13.507395  , ..., 13.053952  ,\n",
      "          17.51159   ,  0.        ]],\n",
      "\n",
      "        [[14.407167  , 11.567148  ,  3.7846935 , ...,  7.2591133 ,\n",
      "          20.585806  ,  2.474684  ],\n",
      "         [ 9.339714  , 17.930405  ,  3.2037368 , ...,  6.4232388 ,\n",
      "          16.239782  ,  0.21462058],\n",
      "         [ 0.63441575, 15.455301  ,  2.6265974 , ...,  7.286296  ,\n",
      "           2.910133  ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 14.626473  ,  8.598119  , ..., 10.70841   ,\n",
      "           2.1963654 ,  0.        ],\n",
      "         [ 0.        , 14.420037  , 10.395572  , ..., 13.133408  ,\n",
      "          11.348905  ,  0.8945763 ],\n",
      "         [ 9.454096  , 10.757812  ,  8.5391445 , ..., 14.729895  ,\n",
      "          15.940469  ,  0.44621485]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        , 12.810197  ,  5.6969843 , ..., 10.741809  ,\n",
      "          22.146997  ,  0.9772248 ],\n",
      "         [ 0.        , 14.926251  ,  5.053571  , ..., 11.609035  ,\n",
      "          17.781372  ,  0.        ],\n",
      "         [ 0.        ,  8.286178  ,  0.9023601 , ..., 10.418328  ,\n",
      "           8.516569  ,  0.        ],\n",
      "         ...,\n",
      "         [ 6.236345  , 12.853447  ,  5.141551  , ...,  1.9967625 ,\n",
      "           5.8939495 ,  0.        ],\n",
      "         [ 1.3873858 , 16.156044  ,  6.66975   , ...,  0.        ,\n",
      "           7.225787  ,  6.742332  ],\n",
      "         [11.365885  , 12.0475645 ,  4.5932207 , ...,  2.0813758 ,\n",
      "           3.802279  ,  0.        ]],\n",
      "\n",
      "        [[ 0.        , 15.462572  ,  6.1135826 , ...,  9.834333  ,\n",
      "          17.942886  ,  0.5191299 ],\n",
      "         [ 0.        , 18.669336  ,  9.878765  , ..., 14.022673  ,\n",
      "          15.251653  ,  0.        ],\n",
      "         [ 0.        , 16.300097  ,  7.885145  , ..., 16.736177  ,\n",
      "          10.599977  ,  0.        ],\n",
      "         ...,\n",
      "         [17.58942   , 14.204773  ,  5.189174  , ...,  2.3212016 ,\n",
      "          11.42922   ,  0.76158094],\n",
      "         [ 9.765132  , 19.519808  ,  5.6894464 , ...,  0.96406317,\n",
      "          12.072805  ,  7.4993773 ],\n",
      "         [ 4.0076556 , 17.197199  ,  4.798572  , ...,  5.8133473 ,\n",
      "           6.674296  ,  0.        ]],\n",
      "\n",
      "        [[ 5.2779675 , 10.939334  ,  6.9823227 , ...,  7.398152  ,\n",
      "          10.656857  ,  0.        ],\n",
      "         [ 6.6313887 , 17.552242  , 11.501143  , ..., 13.0311775 ,\n",
      "          12.155204  ,  0.        ],\n",
      "         [11.487006  , 18.813171  , 11.498444  , ..., 16.696915  ,\n",
      "          11.264711  ,  0.        ],\n",
      "         ...,\n",
      "         [21.86469   , 13.325566  ,  3.659698  , ...,  5.36102   ,\n",
      "          14.179191  ,  2.1948552 ],\n",
      "         [22.134743  , 19.182701  ,  4.03679   , ...,  4.0292006 ,\n",
      "          14.563528  ,  2.866065  ],\n",
      "         [ 7.388583  , 15.656523  ,  3.9670377 , ...,  7.0834627 ,\n",
      "           9.622877  ,  0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 56, 56, 256), dtype=float32, numpy=\n",
      "array([[[[1.0348892e+01, 2.3074112e+01, 1.5315343e+00, ...,\n",
      "          1.0876222e+01, 2.1421502e+00, 5.3967047e+00],\n",
      "         [2.2665188e+01, 6.3753506e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.8712616e+00, 7.9859056e+00],\n",
      "         [2.7620771e+01, 6.8705711e+01, 0.0000000e+00, ...,\n",
      "          5.1586108e+00, 0.0000000e+00, 8.3448744e+00],\n",
      "         ...,\n",
      "         [4.2234097e+01, 5.8358967e+01, 0.0000000e+00, ...,\n",
      "          6.4906821e+00, 0.0000000e+00, 3.7064338e-01],\n",
      "         [4.7257931e+01, 6.5434204e+01, 0.0000000e+00, ...,\n",
      "          1.1449815e+01, 0.0000000e+00, 0.0000000e+00],\n",
      "         [3.5438488e+01, 7.8980865e+01, 0.0000000e+00, ...,\n",
      "          8.2871056e+00, 0.0000000e+00, 0.0000000e+00]],\n",
      "\n",
      "        [[2.0223386e+00, 1.1000780e+01, 1.4687221e+01, ...,\n",
      "          2.3375002e+01, 5.7185502e+00, 1.0651092e+01],\n",
      "         [8.8189230e+00, 4.3355980e+01, 1.8386957e+01, ...,\n",
      "          2.5968192e+00, 6.3268690e+00, 1.1473085e+01],\n",
      "         [1.2176233e+01, 4.1476700e+01, 1.9767197e+01, ...,\n",
      "          1.1631829e+01, 0.0000000e+00, 9.8145218e+00],\n",
      "         ...,\n",
      "         [3.3820606e+01, 3.7744232e+01, 9.9443302e+00, ...,\n",
      "          1.5040370e+01, 0.0000000e+00, 0.0000000e+00],\n",
      "         [4.1113438e+01, 4.6106022e+01, 7.5613103e+00, ...,\n",
      "          2.4193914e+01, 0.0000000e+00, 0.0000000e+00],\n",
      "         [3.2149441e+01, 7.8794067e+01, 6.6243405e+00, ...,\n",
      "          1.7447193e+01, 0.0000000e+00, 0.0000000e+00]],\n",
      "\n",
      "        [[2.8820353e+00, 1.1413054e+01, 1.0459963e+01, ...,\n",
      "          2.2299376e+01, 3.0701222e+00, 1.0532425e+01],\n",
      "         [8.2783756e+00, 3.8287609e+01, 1.1283357e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 7.1663747e+00],\n",
      "         [6.0561628e+00, 3.2775169e+01, 1.2999560e+01, ...,\n",
      "          4.4801068e+00, 0.0000000e+00, 1.1605062e+01],\n",
      "         ...,\n",
      "         [1.5363874e+01, 3.5001541e+01, 2.1437662e+00, ...,\n",
      "          9.3096380e+00, 0.0000000e+00, 6.4444532e+00],\n",
      "         [2.1153460e+01, 3.7807735e+01, 2.9751308e+00, ...,\n",
      "          2.1138514e+01, 0.0000000e+00, 4.8782806e+00],\n",
      "         [1.8127481e+01, 7.4194130e+01, 5.1424112e+00, ...,\n",
      "          1.9951797e+01, 0.0000000e+00, 2.4455278e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.5791769e+00, 1.8663469e+01, 1.8022907e-01, ...,\n",
      "          2.4604368e+01, 0.0000000e+00, 7.6710992e+00],\n",
      "         [1.7113914e+01, 5.1738392e+01, 0.0000000e+00, ...,\n",
      "          5.7959275e+00, 0.0000000e+00, 2.9367676e+00],\n",
      "         [1.3891829e+01, 4.4751785e+01, 0.0000000e+00, ...,\n",
      "          4.2199097e+00, 0.0000000e+00, 6.9837852e+00],\n",
      "         ...,\n",
      "         [1.2958124e+01, 3.2284767e+01, 4.2626276e+00, ...,\n",
      "          1.3383834e-02, 0.0000000e+00, 1.0580178e+01],\n",
      "         [1.4982016e+01, 3.3507515e+01, 6.6392760e+00, ...,\n",
      "          1.4473380e-01, 0.0000000e+00, 3.5396860e+00],\n",
      "         [9.0225878e+00, 7.1697426e+01, 5.7231450e+00, ...,\n",
      "          9.2640495e+00, 0.0000000e+00, 6.7988998e-01]],\n",
      "\n",
      "        [[1.2988203e+01, 1.8445023e+01, 5.8203959e+00, ...,\n",
      "          2.5327646e+01, 1.4584298e+00, 9.5942373e+00],\n",
      "         [2.6906281e+01, 6.3338360e+01, 0.0000000e+00, ...,\n",
      "          6.5640140e+00, 0.0000000e+00, 4.2084236e+00],\n",
      "         [2.7758528e+01, 6.5577194e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.2453218e+00],\n",
      "         ...,\n",
      "         [1.1345889e+01, 4.0796944e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
      "         [8.7994337e+00, 4.4391987e+01, 5.4944544e+00, ...,\n",
      "          4.0111801e-01, 2.8635528e+00, 0.0000000e+00],\n",
      "         [6.1636324e+00, 7.5068588e+01, 4.9300127e+00, ...,\n",
      "          6.9417753e+00, 0.0000000e+00, 0.0000000e+00]],\n",
      "\n",
      "        [[8.0987895e-01, 3.8669734e+00, 1.5029879e+01, ...,\n",
      "          2.5936424e+01, 9.3271885e+00, 0.0000000e+00],\n",
      "         [6.0918808e+00, 3.0043242e+01, 1.6088337e+01, ...,\n",
      "          1.6510727e+01, 4.0939908e+00, 0.0000000e+00],\n",
      "         [7.2974601e+00, 3.4056808e+01, 1.3505087e+01, ...,\n",
      "          8.9913683e+00, 2.5099688e+00, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 1.8583685e+01, 8.8840446e+00, ...,\n",
      "          8.5815191e+00, 0.0000000e+00, 0.0000000e+00],\n",
      "         [0.0000000e+00, 1.8772957e+01, 1.4973668e+01, ...,\n",
      "          1.0358409e+01, 2.3264887e+00, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.6705482e+01, 1.1184381e+01, ...,\n",
      "          8.0216303e+00, 0.0000000e+00, 2.5119376e-01]]]], dtype=float32)>, <tf.Tensor: shape=(1, 28, 28, 256), dtype=float32, numpy=\n",
      "array([[[[22.665188  , 63.753506  , 18.386957  , ..., 23.375002  ,\n",
      "           6.8712616 , 11.473085  ],\n",
      "         [27.620771  , 68.70571   , 19.767197  , ..., 11.631829  ,\n",
      "           0.        ,  9.814522  ],\n",
      "         [14.592495  , 51.745224  , 13.643083  , ...,  0.42231104,\n",
      "           0.29217172,  2.5608056 ],\n",
      "         ...,\n",
      "         [32.75771   , 59.108192  , 17.760805  , ..., 18.442938  ,\n",
      "           0.        ,  5.0156965 ],\n",
      "         [42.234097  , 58.358967  , 12.78999   , ..., 17.077013  ,\n",
      "           0.        ,  2.2282405 ],\n",
      "         [47.25793   , 78.980865  ,  7.5613103 , ..., 24.193914  ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 8.278376  , 40.493507  , 11.283357  , ..., 22.299376  ,\n",
      "           3.0701222 , 10.532425  ],\n",
      "         [ 7.047422  , 33.883583  , 12.99956   , ...,  4.480107  ,\n",
      "           0.        , 12.380673  ],\n",
      "         [10.571162  , 39.528786  ,  6.6800103 , ...,  0.        ,\n",
      "           0.        , 13.43247   ],\n",
      "         ...,\n",
      "         [17.2302    , 31.816345  ,  7.143551  , ..., 15.280918  ,\n",
      "           0.        ,  8.177034  ],\n",
      "         [15.363874  , 35.00154   ,  3.7398884 , ..., 10.307297  ,\n",
      "           0.        ,  6.4444532 ],\n",
      "         [21.15346   , 74.19413   ,  5.142411  , ..., 21.138514  ,\n",
      "           0.        ,  4.8782806 ]],\n",
      "\n",
      "        [[12.345994  , 50.44261   ,  7.635971  , ..., 27.893095  ,\n",
      "           0.        ,  0.8904672 ],\n",
      "         [ 9.728252  , 36.30772   ,  0.3053733 , ...,  0.        ,\n",
      "           0.        ,  0.69453543],\n",
      "         [ 8.929522  , 33.71217   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 37.17946   ,  1.2601104 , ...,  4.600767  ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 34.76693   ,  3.5595171 , ...,  4.4546595 ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 3.838422  , 71.70131   ,  9.002298  , ..., 13.424024  ,\n",
      "           0.        ,  8.995236  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[13.271701  , 43.94189   ,  6.1834373 , ..., 21.968588  ,\n",
      "           0.        ,  3.8028324 ],\n",
      "         [ 2.0145962 , 26.420631  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [14.417634  , 37.110035  ,  0.        , ...,  1.0897969 ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 34.67973   ,  5.956346  , ..., 18.361063  ,\n",
      "           0.        ,  0.73526746],\n",
      "         [ 2.0842516 , 37.718487  ,  3.7579217 , ..., 11.98042   ,\n",
      "           0.        ,  3.7111685 ],\n",
      "         [13.053251  , 66.99479   ,  2.7638485 , ...,  6.411168  ,\n",
      "           0.        ,  2.453866  ]],\n",
      "\n",
      "        [[17.113914  , 51.73839   ,  0.6978808 , ..., 24.819355  ,\n",
      "           0.        ,  7.671099  ],\n",
      "         [13.891829  , 44.751785  ,  0.        , ...,  5.032208  ,\n",
      "           0.        ,  8.592453  ],\n",
      "         [ 7.8584723 , 36.561832  ,  0.        , ...,  0.89973253,\n",
      "           0.        ,  7.2451963 ],\n",
      "         ...,\n",
      "         [19.210941  , 39.43784   ,  3.9805973 , ..., 13.631037  ,\n",
      "           0.        ,  9.648134  ],\n",
      "         [16.524374  , 40.506954  ,  4.489667  , ...,  7.8007526 ,\n",
      "           0.        , 12.5113    ],\n",
      "         [17.14983   , 71.697426  ,  6.639276  , ...,  9.26405   ,\n",
      "           0.        ,  6.9188843 ]],\n",
      "\n",
      "        [[26.90628   , 63.33836   , 16.088337  , ..., 25.936424  ,\n",
      "           9.3271885 ,  9.594237  ],\n",
      "         [27.758528  , 65.577194  , 13.505087  , ...,  8.991368  ,\n",
      "           4.5848646 ,  1.2453218 ],\n",
      "         [22.853249  , 51.97743   , 11.528321  , ...,  8.219336  ,\n",
      "           1.9640691 ,  0.        ],\n",
      "         ...,\n",
      "         [26.670324  , 45.329407  ,  6.2381253 , ...,  1.5848202 ,\n",
      "           0.        , 13.138973  ],\n",
      "         [19.609386  , 44.210903  ,  8.884045  , ...,  8.581519  ,\n",
      "           0.        ,  3.1541312 ],\n",
      "         [ 8.799434  , 75.06859   , 14.973668  , ..., 10.358409  ,\n",
      "           2.8635528 ,  0.25119376]]]], dtype=float32)>, <tf.Tensor: shape=(1, 28, 28, 512), dtype=float32, numpy=\n",
      "array([[[[1.0978654e+01, 9.9611607e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 4.3451469e+01, 0.0000000e+00],\n",
      "         [8.4497375e+00, 1.9531797e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 5.7591972e+01, 0.0000000e+00],\n",
      "         [1.7684894e+00, 2.2010027e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 5.3080215e+01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 8.2505932e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.2401897e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 4.9728832e+01, 0.0000000e+00],\n",
      "         [2.5780788e+01, 0.0000000e+00, 6.4155793e+00, ...,\n",
      "          0.0000000e+00, 3.5840595e+01, 2.8735012e-01]],\n",
      "\n",
      "        [[1.2872753e+01, 2.0252218e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.8645569e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.4410061e+01, 1.4946350e+01, ...,\n",
      "          0.0000000e+00, 2.4923685e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.7434963e+01, 1.7196537e+01, ...,\n",
      "          0.0000000e+00, 2.1895685e+01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 2.7932356e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.7849257e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 2.2562588e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.7501812e+01, 0.0000000e+00],\n",
      "         [5.1539044e+00, 1.6279589e+01, 1.4856531e+01, ...,\n",
      "          0.0000000e+00, 1.6364731e+01, 0.0000000e+00]],\n",
      "\n",
      "        [[5.6152377e+00, 1.4758203e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.3404199e+01, 7.8380699e+00],\n",
      "         [3.2716558e+00, 2.8524511e+01, 2.0439401e+00, ...,\n",
      "          0.0000000e+00, 1.0524076e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.7510117e+01, 1.6787989e+00, ...,\n",
      "          0.0000000e+00, 1.7620756e+01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 3.2503975e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.3521664e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.5456184e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.7793802e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 3.0389011e+01, 1.0071441e+01, ...,\n",
      "          0.0000000e+00, 1.8695692e+01, 0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0331889e+01, 7.3317676e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.8122183e+01, 2.9226768e-01],\n",
      "         [8.6227407e+00, 2.4354153e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.7058661e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 2.4910404e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.1948601e+01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 2.9576406e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.9732428e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 2.5865839e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.2141935e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 2.3085588e+01, 1.0708884e+01, ...,\n",
      "          0.0000000e+00, 2.2440916e+01, 0.0000000e+00]],\n",
      "\n",
      "        [[1.1532707e+01, 1.1785826e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.3559687e+01, 1.1723741e+00],\n",
      "         [1.6969490e+01, 2.7707960e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.5094248e+01, 0.0000000e+00],\n",
      "         [3.0294406e+00, 3.3512112e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.3820162e+01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 3.1010075e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.5790686e+01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 2.9925800e+01, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.9447809e+01, 0.0000000e+00],\n",
      "         [2.5745952e+00, 2.3519342e+01, 1.3648120e+01, ...,\n",
      "          0.0000000e+00, 1.8663406e+01, 5.4422388e+00]],\n",
      "\n",
      "        [[5.6795015e+00, 4.2565689e+01, 6.3640876e+00, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 2.2589809e+01],\n",
      "         [3.8087797e+00, 6.2835598e+01, 2.3154943e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.7852381e+01],\n",
      "         [0.0000000e+00, 6.2312653e+01, 2.1294977e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.5578411e+01],\n",
      "         ...,\n",
      "         [1.3916594e-01, 5.5893337e+01, 2.6821939e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.7066786e+01],\n",
      "         [8.7182000e-03, 5.3402214e+01, 2.2319826e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.5861510e+01],\n",
      "         [1.9619486e+00, 3.5906799e+01, 3.3881508e+01, ...,\n",
      "          0.0000000e+00, 0.0000000e+00, 1.7161972e+01]]]], dtype=float32)>, <tf.Tensor: shape=(1, 28, 28, 512), dtype=float32, numpy=\n",
      "array([[[[14.006414  ,  0.        ,  0.        , ...,  6.2670264 ,\n",
      "           7.316065  ,  5.1917644 ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.7776271 ,\n",
      "           5.195592  ,  4.646786  ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  4.2426033 ,\n",
      "           6.5031157 ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  2.9652476 ,\n",
      "          24.580467  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.4552379 ,\n",
      "          26.503752  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  4.763137  , ...,  0.45112124,\n",
      "          24.1503    ,  5.6530175 ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ..., 24.580305  ,\n",
      "           0.29733196,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 22.560555  ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 23.399841  ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 24.636526  ,\n",
      "          31.683273  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 30.005545  ,\n",
      "          29.936186  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.85750085, ..., 26.950115  ,\n",
      "          31.833185  ,  8.691916  ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ..., 30.00242   ,\n",
      "           0.8089667 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 22.648443  ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 20.683126  ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 28.276114  ,\n",
      "          16.167545  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 34.812138  ,\n",
      "           6.2456536 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  3.2990267 , ..., 42.048866  ,\n",
      "          12.676552  ,  6.6039867 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ..., 21.47159   ,\n",
      "           6.1386366 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 17.444523  ,\n",
      "           5.8865724 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 25.39059   ,\n",
      "          10.944647  ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  3.2022395 ,\n",
      "          18.503347  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           5.3154593 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  1.1315147 , ..., 19.759144  ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ..., 24.60982   ,\n",
      "          10.768049  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 31.074175  ,\n",
      "          11.432505  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 31.046677  ,\n",
      "           9.823554  ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  3.6331024 ,\n",
      "          15.691267  ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  5.478023  ,\n",
      "           2.1370673 ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  1.5486882 , ..., 27.839968  ,\n",
      "           0.        ,  7.7671323 ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ..., 13.058977  ,\n",
      "           2.9036622 , 11.32984   ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 15.7394285 ,\n",
      "           9.243391  ,  4.6110697 ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 10.917413  ,\n",
      "           9.904387  ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.18839593,\n",
      "           0.06034319,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 12.099063  ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ..., 30.628607  ,\n",
      "           0.        ,  1.2378556 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 28, 28, 512), dtype=float32, numpy=\n",
      "array([[[[ 0.        ,  3.4909422 , 12.365133  , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  1.6101325 , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        , 13.500944  , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        , 36.098297  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 36.587696  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 35.12643   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 41.701668  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 31.582127  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 21.630796  , 11.618856  , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        , 21.749321  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 21.966078  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 23.691788  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 36.416782  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 35.328228  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 35.29429   ,  8.165657  , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        , 27.606167  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 23.844833  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 26.960386  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 34.893307  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 23.222239  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 28.036272  ,  8.549929  , ...,  0.        ,\n",
      "           6.2207904 ,  0.        ]],\n",
      "\n",
      "        [[ 0.        , 23.33663   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 15.736665  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 18.50987   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 30.351786  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 31.605562  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 38.03512   , 12.352361  , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        , 25.42235   ,  0.        , ...,  0.        ,\n",
      "          14.86862   ,  0.        ],\n",
      "         [ 0.        , 25.683912  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 21.635302  ,  0.        , ...,  0.        ,\n",
      "           0.88841295,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        , 22.76756   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 33.84475   ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 40.706165  ,  0.        , ...,  0.        ,\n",
      "           2.6993387 ,  0.88646626]]]], dtype=float32)>, <tf.Tensor: shape=(1, 28, 28, 512), dtype=float32, numpy=\n",
      "array([[[[ 0.        ,  6.7435117 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  2.7793126 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  3.2542338 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  8.969662  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  5.033818  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  5.648046  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  1.2489367 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  1.6232806 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  6.539703  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  5.0854278 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 2.5465636 ,  5.176187  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 4.4647136 , 14.189633  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.03818143,  0.        ],\n",
      "         [ 1.9724649 ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 2.9409978 ,  3.9836345 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  1.9099644 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.8420173 ,  0.        ,  0.        , ...,  0.        ,\n",
      "           1.630357  ,  0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 14, 14, 512), dtype=float32, numpy=\n",
      "array([[[[ 0.        ,  6.7435117 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  7.8684306 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  9.930379  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  8.670688  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        , 10.394834  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 4.4647136 , 14.189633  ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.03818143,  0.        ],\n",
      "         [ 2.9409978 ,  3.9836345 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.12280877, ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.74102736,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.6363295 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  1.9099644 ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ]],\n",
      "\n",
      "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         ...,\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "           0.        ,  0.        ],\n",
      "         [ 0.8420173 ,  0.        ,  0.        , ...,  0.        ,\n",
      "           1.630357  ,  0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 14, 14, 512), dtype=float32, numpy=\n",
      "array([[[[0.1871023 , 0.        , 3.0226572 , ..., 1.1445593 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.12625258,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 1.7318766 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 2.7184305 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.24139397, 0.        , 2.9392388 , ..., 0.42203748,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 1.3836844 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 2.6625905 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.02955795, 0.        , 0.9488066 , ..., 1.597804  ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.62417716,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.71077245, 0.        , 0.2488871 , ..., 0.10669135,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.12350698, 0.        , 2.5500896 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.23500298,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[2.6189506 , 0.        , 4.9950156 , ..., 0.3404646 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.6096893 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 1.8993059 , ..., 0.88862133,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 14, 14, 512), dtype=float32, numpy=\n",
      "array([[[[0.        , 0.        , 4.055825  , ..., 0.        ,\n",
      "          4.115074  , 1.5357077 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          5.2469697 , 1.167226  ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          4.360376  , 0.86899346],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          4.801996  , 0.8833018 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          5.726312  , 0.13746493],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          4.7190633 , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 4.2119513 , ..., 0.        ,\n",
      "          0.        , 1.7890542 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.8056001 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.28381354, 0.10768025],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          1.6316177 , 0.317227  ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          1.1128471 , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.4991439 , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 3.9566224 , ..., 0.38716364,\n",
      "          0.        , 1.7014997 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.3298382 ,\n",
      "          0.20436314, 1.3213204 ],\n",
      "         [0.        , 0.        , 0.        , ..., 1.2663988 ,\n",
      "          0.40532014, 0.5926585 ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 1.155878  ,\n",
      "          1.432787  , 0.23232988],\n",
      "         [0.        , 0.        , 0.        , ..., 1.5593696 ,\n",
      "          0.81241226, 0.02018674],\n",
      "         [0.        , 0.        , 0.        , ..., 1.111189  ,\n",
      "          0.        , 0.43964404]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        , 0.        , 4.213711  , ..., 0.        ,\n",
      "          0.        , 2.0059893 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 1.9834471 ],\n",
      "         [0.        , 0.        , 0.42790532, ..., 0.36352158,\n",
      "          0.        , 1.1163086 ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.72548467,\n",
      "          0.5984365 , 0.9673963 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.0795157 ,\n",
      "          1.0013372 , 0.55767524],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.6571228 , 0.6772603 ]],\n",
      "\n",
      "        [[0.        , 0.        , 3.8768597 , ..., 0.        ,\n",
      "          0.        , 1.4849677 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.8492227 ],\n",
      "         [0.        , 0.        , 0.22965156, ..., 0.18339553,\n",
      "          0.        , 0.29523006],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.52151465,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.4073059 , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          1.0717015 , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 3.2890825 , ..., 0.10487932,\n",
      "          0.        , 1.1681129 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.42381334,\n",
      "          0.        , 0.5053773 ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.8233306 ,\n",
      "          0.        , 0.26404238],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 1.0542024 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.5520884 ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.752934  , ..., 0.24305153,\n",
      "          0.        , 0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 14, 14, 512), dtype=float32, numpy=\n",
      "array([[[[0.        , 0.        , 0.0704616 , ..., 0.40256184,\n",
      "          0.        , 0.23071565],\n",
      "         [0.        , 0.        , 0.        , ..., 0.03646407,\n",
      "          0.        , 0.32864493],\n",
      "         [0.        , 0.        , 0.10950901, ..., 0.13963632,\n",
      "          0.        , 0.28050193],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.16840062, ..., 0.07776047,\n",
      "          0.        , 0.02477772],\n",
      "         [0.        , 0.        , 0.36320412, ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.06616858, ..., 0.19167253,\n",
      "          0.15810575, 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.43549132],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.89947873],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.37619627],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.02284013, ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.04581315, 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.875288  , ..., 0.        ,\n",
      "          0.        , 0.4171436 ],\n",
      "         [0.        , 0.        , 0.38508463, ..., 0.        ,\n",
      "          0.        , 0.39920235],\n",
      "         [0.        , 0.        , 0.7601681 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.5489549 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.77767754, ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.189204  , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.        , 0.        , 0.84868884, ..., 0.        ,\n",
      "          0.        , 0.19983226],\n",
      "         [0.        , 0.        , 0.5660064 , ..., 0.        ,\n",
      "          0.        , 0.04654333],\n",
      "         [0.        , 0.        , 0.84267026, ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.8555224 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 1.1092776 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.1973449 , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.9799988 , ..., 0.00750041,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.8480686 , ..., 0.        ,\n",
      "          0.        , 0.04782275],\n",
      "         [0.        , 0.        , 1.1216164 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.8826422 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 1.1935357 , ..., 0.        ,\n",
      "          0.        , 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.        , 0.        , 0.3894572 , ..., 0.57092625,\n",
      "          0.37360296, 0.37033147],\n",
      "         [0.        , 0.        , 0.01757783, ..., 0.17020667,\n",
      "          0.3965849 , 0.87721777],\n",
      "         [0.        , 0.        , 0.2751342 , ..., 0.02826676,\n",
      "          0.        , 0.14645098],\n",
      "         ...,\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.04228646, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.26862347, 0.        ],\n",
      "         [0.        , 0.        , 0.        , ..., 0.12251374,\n",
      "          0.6233709 , 0.34745196]]]], dtype=float32)>, <tf.Tensor: shape=(1, 14, 14, 512), dtype=float32, numpy=\n",
      "array([[[[3.4212756e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.6902142e-01, 0.0000000e+00],\n",
      "         [4.7721925e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 4.6433696e-01, 0.0000000e+00],\n",
      "         [4.4345164e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 5.7989490e-01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [3.7455079e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.5617146e-01, 0.0000000e+00],\n",
      "         [4.6478024e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.1225986e-01, 0.0000000e+00],\n",
      "         [3.5842448e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.4178282e-01, 0.0000000e+00]],\n",
      "\n",
      "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.5150146e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 2.6765054e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 3.2939482e-01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 4.2289752e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.8404734e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 4.2060423e-01, 0.0000000e+00]],\n",
      "\n",
      "        [[2.9983938e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.1085671e+00, 0.0000000e+00],\n",
      "         [1.2587273e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.0735893e-01, 0.0000000e+00],\n",
      "         [1.4302671e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.3686931e-01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [1.1312366e-03, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.7754726e-01, 0.0000000e+00],\n",
      "         [1.1407387e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.5187645e-01, 0.0000000e+00],\n",
      "         [6.6865921e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.5400007e-01, 0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.4276328e-03, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.2901554e+00, 0.0000000e+00],\n",
      "         [7.5512469e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.7824044e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 9.2144394e-01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [5.3580999e-03, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.6518294e-01, 0.0000000e+00],\n",
      "         [1.7975336e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.8157657e-01, 0.0000000e+00],\n",
      "         [1.1027646e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.3057386e-01, 0.0000000e+00]],\n",
      "\n",
      "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.2006148e+00, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.0933592e-01, 0.0000000e+00],\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 9.7538894e-01, 0.0000000e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.3026993e-01, 0.0000000e+00],\n",
      "         [1.7907619e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.2015253e-01, 0.0000000e+00],\n",
      "         [4.0774703e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.9457352e-01, 0.0000000e+00]],\n",
      "\n",
      "        [[1.4074409e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.2539239e+00, 0.0000000e+00],\n",
      "         [8.3046794e-02, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 9.1930461e-01, 0.0000000e+00],\n",
      "         [1.6620696e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 1.0273184e+00, 0.0000000e+00],\n",
      "         ...,\n",
      "         [3.1145775e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 8.3498627e-01, 0.0000000e+00],\n",
      "         [4.3260309e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 6.5999687e-01, 0.0000000e+00],\n",
      "         [3.5543871e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
      "          0.0000000e+00, 7.0910549e-01, 0.0000000e+00]]]], dtype=float32)>, <tf.Tensor: shape=(1, 7, 7, 512), dtype=float32, numpy=\n",
      "array([[[[0.47721925, 0.        , 0.        , ..., 0.        ,\n",
      "          0.8690214 , 0.        ],\n",
      "         [0.6109186 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.5798949 , 0.        ],\n",
      "         [0.6902978 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.7598969 , 0.        ],\n",
      "         ...,\n",
      "         [0.68400294, 0.        , 0.        , ..., 0.        ,\n",
      "          0.830168  , 0.        ],\n",
      "         [0.6444609 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.75617146, 0.        ],\n",
      "         [0.46478024, 0.        , 0.        , ..., 0.        ,\n",
      "          0.6417828 , 0.        ]],\n",
      "\n",
      "        [[0.16492462, 0.        , 0.        , ..., 0.        ,\n",
      "          1.2170529 , 0.        ],\n",
      "         [0.2839189 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.6715036 , 0.        ],\n",
      "         [0.38322666, 0.        , 0.        , ..., 0.        ,\n",
      "          0.79410994, 0.        ],\n",
      "         ...,\n",
      "         [0.38877472, 0.        , 0.        , ..., 0.        ,\n",
      "          0.9934298 , 0.        ],\n",
      "         [0.29586124, 0.        , 0.        , ..., 0.        ,\n",
      "          1.0020316 , 0.        ],\n",
      "         [0.21182227, 0.        , 0.        , ..., 0.        ,\n",
      "          0.8905306 , 0.        ]],\n",
      "\n",
      "        [[0.31469604, 0.        , 0.        , ..., 0.        ,\n",
      "          1.2332984 , 0.        ],\n",
      "         [0.31004363, 0.        , 0.        , ..., 0.        ,\n",
      "          0.6641816 , 0.        ],\n",
      "         [0.31790775, 0.        , 0.        , ..., 0.        ,\n",
      "          0.88145614, 0.        ],\n",
      "         ...,\n",
      "         [0.46114928, 0.        , 0.        , ..., 0.        ,\n",
      "          0.9962327 , 0.        ],\n",
      "         [0.42612118, 0.        , 0.        , ..., 0.        ,\n",
      "          1.0462635 , 0.        ],\n",
      "         [0.44003195, 0.        , 0.        , ..., 0.        ,\n",
      "          0.9541824 , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.09169805, 0.        , 0.        , ..., 0.        ,\n",
      "          1.2286378 , 0.        ],\n",
      "         [0.0907445 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.7896156 , 0.        ],\n",
      "         [0.24595344, 0.        , 0.        , ..., 0.        ,\n",
      "          0.97293496, 0.        ],\n",
      "         ...,\n",
      "         [0.277295  , 0.        , 0.        , ..., 0.        ,\n",
      "          0.90420794, 0.        ],\n",
      "         [0.3385073 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.7421097 , 0.        ],\n",
      "         [0.31193608, 0.        , 0.        , ..., 0.        ,\n",
      "          0.8414632 , 0.        ]],\n",
      "\n",
      "        [[0.08278298, 0.        , 0.        , ..., 0.        ,\n",
      "          1.2901554 , 0.        ],\n",
      "         [0.12471497, 0.        , 0.        , ..., 0.        ,\n",
      "          0.92144394, 0.        ],\n",
      "         [0.23745689, 0.        , 0.        , ..., 0.        ,\n",
      "          1.024641  , 0.        ],\n",
      "         ...,\n",
      "         [0.25089386, 0.        , 0.        , ..., 0.        ,\n",
      "          1.1461474 , 0.        ],\n",
      "         [0.29909894, 0.        , 0.        , ..., 0.        ,\n",
      "          0.8723631 , 0.        ],\n",
      "         [0.32240957, 0.        , 0.        , ..., 0.        ,\n",
      "          0.83057386, 0.        ]],\n",
      "\n",
      "        [[0.14074409, 0.        , 0.        , ..., 0.        ,\n",
      "          1.2539239 , 0.        ],\n",
      "         [0.3141954 , 0.        , 0.        , ..., 0.        ,\n",
      "          1.0273184 , 0.        ],\n",
      "         [0.43866435, 0.        , 0.        , ..., 0.        ,\n",
      "          1.0195038 , 0.        ],\n",
      "         ...,\n",
      "         [0.34904885, 0.        , 0.        , ..., 0.        ,\n",
      "          1.1312345 , 0.        ],\n",
      "         [0.34774572, 0.        , 0.        , ..., 0.        ,\n",
      "          0.902182  , 0.        ],\n",
      "         [0.4326031 , 0.        , 0.        , ..., 0.        ,\n",
      "          0.7091055 , 0.        ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 25088), dtype=float32, numpy=\n",
      "array([[0.47721925, 0.        , 0.        , ..., 0.        , 0.7091055 ,\n",
      "        0.        ]], dtype=float32)>, <tf.Tensor: shape=(1, 4096), dtype=float32, numpy=\n",
      "array([[0.       , 1.79417  , 0.       , ..., 0.       , 2.7876472,\n",
      "        1.278234 ]], dtype=float32)>, <tf.Tensor: shape=(1, 4096), dtype=float32, numpy=\n",
      "array([[0.52336526, 0.        , 0.45245817, ..., 0.        , 0.5525368 ,\n",
      "        0.        ]], dtype=float32)>, <tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
      "array([[1.90778184e-04, 1.35730032e-03, 6.57147320e-04, 1.56361959e-03,\n",
      "        2.24259356e-03, 1.98450824e-03, 7.99974054e-03, 1.75563895e-04,\n",
      "        2.70454620e-04, 2.32128659e-04, 6.48293004e-04, 2.98938452e-04,\n",
      "        3.97020078e-04, 8.43784481e-04, 3.49745533e-04, 3.45274515e-04,\n",
      "        7.19234638e-04, 3.81978549e-04, 7.36208633e-04, 1.08938548e-03,\n",
      "        1.45698327e-03, 9.38935729e-04, 7.02226418e-04, 5.62098750e-04,\n",
      "        1.41204015e-04, 2.63491151e-04, 1.17293454e-03, 1.14954764e-03,\n",
      "        2.84068432e-04, 4.70344396e-03, 3.74721887e-04, 4.50975145e-04,\n",
      "        4.42689139e-04, 1.48475263e-03, 9.67456901e-04, 5.38682390e-04,\n",
      "        1.32243126e-03, 4.12617665e-04, 2.57343589e-03, 2.87247589e-04,\n",
      "        8.11950129e-04, 7.02569901e-04, 1.06783910e-03, 5.61877154e-04,\n",
      "        9.11391922e-04, 2.00885069e-03, 9.92066110e-04, 7.23694684e-04,\n",
      "        5.27634576e-04, 5.52384823e-04, 9.29844216e-04, 3.12409597e-04,\n",
      "        2.81235157e-03, 2.83606909e-03, 8.64243077e-04, 3.26777605e-04,\n",
      "        1.53314101e-03, 2.28800025e-04, 1.12854512e-02, 4.11435525e-04,\n",
      "        1.40486204e-03, 1.05288473e-03, 1.03115698e-03, 9.43856663e-04,\n",
      "        2.72880122e-03, 1.62862288e-03, 2.58885766e-03, 1.07562507e-03,\n",
      "        1.23568100e-03, 2.29830947e-03, 1.62031676e-03, 2.27303826e-03,\n",
      "        6.25291897e-04, 1.17051415e-03, 5.09812671e-04, 4.98918677e-03,\n",
      "        1.37104630e-03, 2.24359240e-03, 9.48329922e-03, 5.21600386e-03,\n",
      "        1.08229101e-03, 4.61778231e-03, 5.92405384e-04, 6.90341112e-04,\n",
      "        3.00018321e-04, 1.76479109e-03, 1.50492054e-03, 2.20481306e-03,\n",
      "        2.47812859e-04, 2.51544523e-03, 8.16736865e-05, 4.11321729e-04,\n",
      "        9.79441800e-04, 1.79610666e-04, 8.00721755e-04, 1.56846145e-04,\n",
      "        4.69912629e-04, 2.42153081e-04, 9.16452380e-04, 6.68213703e-04,\n",
      "        2.93378951e-04, 2.35914951e-04, 3.24651395e-04, 1.85042107e-03,\n",
      "        2.59057153e-04, 8.91677919e-05, 6.09550800e-04, 5.93688106e-04,\n",
      "        5.31657250e-04, 5.22590533e-04, 1.96050212e-04, 3.26337270e-03,\n",
      "        1.25513447e-03, 5.52427839e-04, 6.29968476e-04, 7.22121404e-05,\n",
      "        1.67019898e-04, 1.45972380e-03, 3.56266479e-04, 2.28417412e-04,\n",
      "        2.12296424e-03, 7.54717912e-05, 1.05507039e-04, 9.16163335e-05,\n",
      "        1.25376857e-03, 1.34206412e-03, 1.98601349e-03, 9.71752102e-04,\n",
      "        1.12366641e-03, 8.96237209e-04, 2.29963363e-04, 8.43358634e-04,\n",
      "        2.03797291e-03, 3.27184884e-04, 7.96204316e-04, 2.81686895e-04,\n",
      "        1.79991417e-04, 1.19594566e-03, 2.42850580e-03, 6.36473938e-04,\n",
      "        1.73427444e-03, 1.93885516e-03, 1.47223659e-03, 8.45281931e-04,\n",
      "        4.59983887e-04, 6.36868936e-04, 1.79996574e-03, 1.35228722e-04,\n",
      "        1.85023484e-04, 1.97446230e-03, 6.91610272e-04, 1.32736145e-03,\n",
      "        2.75452796e-04, 4.13651625e-03, 1.85459666e-03, 1.36350410e-03,\n",
      "        6.69796951e-04, 9.48718167e-04, 5.62221801e-04, 2.10289247e-04,\n",
      "        2.53798091e-04, 6.31907373e-04, 1.34083757e-03, 5.17055916e-04,\n",
      "        3.36642523e-04, 9.12469259e-05, 7.22266268e-04, 1.63106393e-04,\n",
      "        4.18145908e-04, 3.94859060e-04, 5.95354184e-04, 1.32187083e-03,\n",
      "        1.66689989e-03, 6.57243421e-04, 4.73191438e-04, 1.40704156e-04,\n",
      "        3.10849311e-04, 2.00093098e-04, 9.93745402e-04, 7.60443683e-04,\n",
      "        7.08162785e-04, 6.47947309e-04, 5.49711753e-04, 8.04333758e-05,\n",
      "        4.25399223e-04, 4.13977308e-04, 3.07822280e-04, 2.67920550e-04,\n",
      "        3.26829206e-04, 2.69147771e-04, 1.03876484e-03, 1.65520818e-04,\n",
      "        1.14900840e-03, 2.27687196e-04, 3.73466435e-04, 4.48186824e-04,\n",
      "        5.04849420e-04, 1.10074136e-04, 9.45840584e-05, 6.43252977e-04,\n",
      "        2.21287890e-04, 1.46982144e-04, 9.16769437e-04, 4.09364700e-03,\n",
      "        1.74473471e-03, 8.50022625e-05, 6.71774033e-05, 6.05537032e-04,\n",
      "        6.10506511e-04, 1.51050440e-03, 2.23335301e-04, 2.91873759e-04,\n",
      "        7.85089389e-04, 1.46431033e-04, 1.26370083e-04, 6.63538231e-04,\n",
      "        3.26987705e-04, 5.17455628e-04, 4.58105904e-04, 2.59008870e-04,\n",
      "        1.03262100e-04, 7.01866520e-05, 1.48149359e-03, 3.82891420e-04,\n",
      "        8.82925815e-05, 2.49252626e-04, 1.71294349e-04, 1.68779865e-04,\n",
      "        3.68201814e-04, 1.03556225e-03, 5.95110410e-04, 2.43758754e-04,\n",
      "        2.49302044e-04, 1.62083525e-04, 1.94159133e-04, 1.38907300e-04,\n",
      "        2.65520910e-04, 1.03972841e-03, 5.54977974e-04, 4.59328381e-04,\n",
      "        1.90756167e-04, 2.51994294e-04, 9.68274719e-04, 2.82954192e-04,\n",
      "        6.85184204e-05, 1.30250538e-03, 2.91825912e-04, 3.71774047e-04,\n",
      "        4.68341634e-04, 4.98563226e-04, 1.37428043e-03, 5.12201514e-04,\n",
      "        1.28485350e-04, 5.06812648e-04, 8.28365330e-04, 7.97688917e-05,\n",
      "        1.23926744e-04, 2.44287611e-03, 6.34637009e-03, 1.23189995e-03,\n",
      "        3.87652806e-04, 3.25997127e-04, 1.08833148e-04, 1.25389802e-03,\n",
      "        5.08129771e-04, 1.53514103e-03, 5.47920587e-04, 2.39937639e-04,\n",
      "        3.56918055e-04, 2.13683132e-04, 1.09264161e-03, 1.27822568e-04,\n",
      "        4.44238714e-04, 9.12241288e-04, 3.23182525e-04, 2.27492288e-04,\n",
      "        5.58461761e-04, 5.57179330e-04, 4.17734933e-04, 4.12299484e-03,\n",
      "        3.83893610e-04, 4.57606802e-04, 6.81280508e-04, 3.23292264e-03,\n",
      "        3.58003378e-03, 8.12917890e-04, 5.39102999e-04, 1.17795367e-03,\n",
      "        2.64123519e-04, 5.44050126e-04, 1.02157792e-04, 3.60472710e-04,\n",
      "        1.02369922e-04, 2.02725321e-04, 8.85288318e-05, 6.39098798e-05,\n",
      "        1.34352618e-03, 2.53616628e-04, 8.81442393e-04, 1.17579103e-03,\n",
      "        3.90563015e-04, 1.51356647e-03, 4.33177018e-04, 4.23325109e-04,\n",
      "        3.19376675e-04, 9.46508080e-04, 6.16150326e-04, 5.23956667e-04,\n",
      "        7.03702506e-04, 1.02258775e-04, 2.12794053e-03, 9.25617875e-04,\n",
      "        1.60471920e-03, 2.05484871e-03, 1.01050353e-02, 1.22579362e-03,\n",
      "        8.20928137e-04, 5.72490564e-04, 3.98321077e-03, 9.57881100e-04,\n",
      "        4.92006307e-04, 8.94368277e-05, 2.02056428e-04, 5.61534944e-05,\n",
      "        2.77659128e-04, 7.84969961e-05, 1.84872944e-04, 6.87874679e-04,\n",
      "        2.72924604e-04, 5.60361310e-04, 1.24687236e-03, 1.81690603e-03,\n",
      "        2.57255509e-03, 4.05254634e-03, 4.35545429e-04, 2.50540616e-04,\n",
      "        3.49006325e-04, 3.10318370e-04, 4.84486896e-04, 3.09344032e-05,\n",
      "        1.11103371e-04, 3.57283629e-04, 1.41839497e-04, 2.55504856e-04,\n",
      "        4.31996275e-04, 1.23417296e-04, 3.00201762e-04, 1.10075816e-04,\n",
      "        2.28586723e-04, 3.79885489e-04, 8.11911072e-04, 3.58938298e-04,\n",
      "        1.73220484e-04, 4.23604972e-04, 4.06365900e-04, 1.65941150e-04,\n",
      "        2.74660741e-03, 5.27178112e-04, 2.44141347e-03, 3.46879358e-03,\n",
      "        6.30861148e-04, 3.83539940e-04, 9.76008596e-04, 1.24551065e-03,\n",
      "        1.59025498e-04, 1.65669888e-04, 1.24708167e-04, 2.56943487e-04,\n",
      "        1.59197865e-04, 7.18422816e-05, 2.04024211e-04, 3.91503534e-04,\n",
      "        3.31933581e-04, 3.56179487e-04, 9.15095210e-04, 1.31971363e-04,\n",
      "        2.99789652e-04, 6.59918063e-04, 3.84537445e-04, 1.16696683e-04,\n",
      "        4.96492372e-04, 1.02375678e-04, 3.37136036e-04, 3.30783805e-04,\n",
      "        9.07895228e-05, 2.44952593e-04, 3.97332158e-04, 1.58359064e-04,\n",
      "        1.60691648e-04, 3.44367203e-04, 3.66658118e-04, 7.95633590e-04,\n",
      "        7.40784162e-05, 2.84334179e-04, 5.16198343e-04, 1.01360295e-03,\n",
      "        1.59341405e-04, 6.87048305e-04, 1.96330569e-04, 4.13089758e-04,\n",
      "        1.98338676e-05, 1.33492809e-04, 2.31003607e-04, 7.99969057e-05,\n",
      "        7.38545088e-04, 2.17339746e-03, 6.62664097e-05, 1.87480793e-04,\n",
      "        5.39634239e-05, 3.73727788e-04, 7.79521215e-05, 7.35216541e-04,\n",
      "        5.70868899e-04, 3.90629692e-04, 3.14234232e-04, 1.82476448e-04,\n",
      "        4.40585020e-04, 1.21475826e-03, 4.67204070e-03, 2.08550412e-02,\n",
      "        5.21124515e-04, 7.25110411e-04, 2.07833553e-04, 1.77454334e-04,\n",
      "        1.79711409e-04, 7.81542549e-05, 8.74117424e-04, 2.80914799e-04,\n",
      "        1.54038309e-04, 9.33322532e-04, 1.49654501e-04, 6.86796056e-03,\n",
      "        3.52278585e-04, 1.06122927e-03, 6.10179082e-03, 3.56356846e-03,\n",
      "        2.21024136e-04, 3.66021908e-04, 1.26093649e-03, 7.78539761e-05,\n",
      "        3.50035145e-04, 9.61416692e-04, 2.36289838e-04, 4.69483621e-03,\n",
      "        7.28739033e-05, 2.10744285e-04, 4.55081789e-03, 3.45321459e-04,\n",
      "        4.77149413e-04, 6.26269975e-05, 8.41395697e-04, 3.25218018e-04,\n",
      "        1.31400861e-03, 4.79188719e-04, 1.31513283e-04, 2.45243963e-03,\n",
      "        7.52121559e-04, 3.89958208e-04, 8.51427438e-04, 1.58660044e-03,\n",
      "        3.49261885e-04, 5.95679216e-04, 1.41450530e-03, 5.54134138e-04,\n",
      "        4.48223291e-04, 1.17424619e-03, 3.71396454e-04, 3.78972509e-05,\n",
      "        1.18596363e-04, 3.48615984e-04, 7.98494439e-04, 2.50578829e-04,\n",
      "        5.01698014e-05, 1.67152006e-03, 5.42058086e-04, 6.88069558e-04,\n",
      "        3.90093592e-05, 1.16806470e-04, 5.58002619e-03, 2.18792731e-04,\n",
      "        3.52198631e-03, 1.27803674e-03, 2.29572674e-04, 3.79260673e-05,\n",
      "        1.90496750e-04, 1.59768621e-03, 9.27390283e-05, 2.17903056e-03,\n",
      "        4.49666259e-04, 2.26461591e-04, 1.93484098e-04, 1.92114298e-04,\n",
      "        1.57314620e-03, 2.81814253e-04, 3.61911865e-04, 6.69167785e-04,\n",
      "        5.46526397e-04, 1.14019502e-04, 2.04435666e-04, 2.20556231e-03,\n",
      "        4.31893102e-04, 1.36346396e-04, 6.85826293e-04, 4.45729092e-04,\n",
      "        1.16598792e-03, 4.39285475e-04, 2.37254135e-04, 3.96026444e-04,\n",
      "        1.31143827e-03, 4.69411862e-05, 3.76382639e-04, 7.90355552e-05,\n",
      "        3.23076529e-04, 1.66693935e-04, 1.16270785e-04, 5.44318638e-04,\n",
      "        3.55780683e-03, 2.46829528e-04, 2.90517055e-04, 1.41550996e-03,\n",
      "        5.66656375e-03, 5.91466320e-04, 9.52656410e-05, 5.12529456e-04,\n",
      "        2.80055363e-04, 3.39492573e-04, 5.77482278e-04, 2.01010786e-04,\n",
      "        7.00033095e-04, 4.28295135e-03, 5.33271173e-04, 5.45426970e-04,\n",
      "        7.92304636e-04, 5.71252021e-04, 2.85402406e-03, 4.77565860e-04,\n",
      "        3.11192489e-05, 2.34193809e-04, 1.26028364e-03, 7.81631970e-04,\n",
      "        2.36374486e-04, 3.45963083e-04, 1.61343231e-03, 2.55971914e-04,\n",
      "        1.38009666e-04, 4.90150880e-03, 1.74629356e-04, 3.24641769e-05,\n",
      "        1.55732225e-04, 2.38990709e-02, 7.58255555e-05, 2.93782959e-03,\n",
      "        1.72946558e-04, 8.99612962e-04, 1.22951879e-03, 6.93736147e-05,\n",
      "        3.44857597e-03, 4.00686084e-04, 8.03558272e-04, 6.63303013e-04,\n",
      "        2.98140541e-04, 1.19219876e-04, 6.27480331e-05, 1.53957831e-03,\n",
      "        5.60707587e-04, 2.17852052e-04, 1.05873070e-04, 4.40394942e-04,\n",
      "        2.31426413e-04, 9.42071856e-05, 8.03938776e-04, 8.56207189e-05,\n",
      "        8.02774681e-04, 2.00639202e-04, 1.43419753e-03, 6.70657973e-05,\n",
      "        1.23392820e-04, 1.03314896e-03, 2.48046912e-04, 1.74521556e-04,\n",
      "        8.11763166e-05, 3.20854706e-05, 9.39456513e-05, 7.95684697e-04,\n",
      "        5.63655398e-04, 8.83622037e-04, 2.36887994e-04, 8.25753785e-04,\n",
      "        1.71514298e-03, 1.94979215e-03, 3.12748831e-04, 7.72379851e-03,\n",
      "        9.47595341e-04, 5.55584033e-04, 1.13175636e-04, 7.19868840e-05,\n",
      "        8.29982397e-04, 3.98330943e-04, 3.00460408e-04, 4.98226669e-04,\n",
      "        1.57100568e-03, 1.76164904e-03, 1.65654725e-04, 1.17433752e-04,\n",
      "        1.56412902e-03, 2.56782211e-03, 1.49152183e-03, 1.99677626e-04,\n",
      "        1.92527688e-04, 2.27078184e-04, 2.61128321e-03, 6.07120979e-04,\n",
      "        3.62404535e-05, 5.13559673e-04, 1.26799248e-04, 8.17849708e-04,\n",
      "        6.80811063e-04, 6.37554098e-04, 3.71678500e-03, 1.85923907e-03,\n",
      "        2.54604523e-03, 1.75966765e-04, 2.71753548e-03, 2.80734431e-03,\n",
      "        1.28150903e-04, 2.80152337e-04, 1.48277765e-03, 1.20933793e-04,\n",
      "        3.95156880e-04, 1.15700264e-03, 4.84593154e-04, 2.88298586e-03,\n",
      "        5.84641180e-04, 9.48031491e-04, 1.22226891e-04, 5.47446602e-04,\n",
      "        1.41984003e-03, 2.56662839e-04, 2.82863679e-04, 2.08501486e-04,\n",
      "        8.53743579e-04, 5.08005382e-04, 8.37848856e-05, 4.14439273e-04,\n",
      "        1.38740928e-03, 3.45552216e-05, 6.22483669e-04, 2.80730752e-03,\n",
      "        1.16769143e-03, 2.65007722e-04, 7.95948785e-04, 1.01237185e-03,\n",
      "        5.56772051e-04, 1.33622962e-03, 1.66992031e-04, 3.24342080e-04,\n",
      "        3.13306315e-04, 8.19147739e-04, 2.90932803e-04, 2.63320236e-03,\n",
      "        9.54869392e-05, 3.92638322e-05, 3.43549484e-03, 7.00899327e-05,\n",
      "        3.28260183e-04, 1.16995332e-04, 1.43478240e-03, 9.16501522e-05,\n",
      "        5.89814794e-04, 2.12760568e-02, 1.34650269e-04, 1.07220563e-04,\n",
      "        2.30231075e-04, 2.61763297e-03, 2.24446668e-03, 1.95921428e-04,\n",
      "        4.25269012e-04, 1.03316305e-03, 5.87628921e-04, 5.35360363e-04,\n",
      "        4.95832087e-03, 1.45932403e-03, 3.76871874e-04, 3.68098263e-04,\n",
      "        1.22044014e-03, 5.13730221e-04, 1.58376899e-03, 1.20435267e-04,\n",
      "        5.27292490e-04, 2.76286912e-04, 6.20497376e-05, 2.23214948e-03,\n",
      "        2.46863440e-03, 3.02729459e-04, 1.60820564e-04, 2.16206099e-04,\n",
      "        1.02773600e-03, 2.97347608e-04, 7.23273042e-05, 1.97609246e-04,\n",
      "        1.07805338e-02, 1.22496160e-03, 1.94704844e-04, 4.18435520e-05,\n",
      "        6.87231252e-04, 4.30924811e-05, 1.60362193e-04, 2.82446825e-04,\n",
      "        6.88929518e-04, 2.06572958e-03, 6.58500590e-04, 1.31218822e-03,\n",
      "        1.01287263e-02, 5.49267512e-03, 2.16362253e-03, 5.98940067e-04,\n",
      "        3.22449050e-04, 3.24285611e-05, 3.46495508e-04, 1.14960480e-03,\n",
      "        2.50862306e-03, 2.48270226e-03, 3.31182033e-03, 4.02530248e-04,\n",
      "        9.90666376e-05, 1.32712419e-03, 4.28138301e-04, 4.64231940e-04,\n",
      "        6.02523051e-03, 9.07204580e-04, 1.95134417e-04, 2.11653789e-03,\n",
      "        1.96666195e-04, 2.19951224e-04, 1.00018078e-04, 4.76208981e-04,\n",
      "        9.40252503e-05, 5.27497963e-04, 2.88084324e-04, 1.18864782e-03,\n",
      "        3.59397120e-04, 4.31912456e-04, 8.81044834e-04, 2.13511623e-04,\n",
      "        5.20394475e-04, 1.46459742e-03, 1.39824918e-03, 3.95888026e-04,\n",
      "        2.02738843e-03, 2.01241625e-03, 3.66146653e-03, 3.82607075e-04,\n",
      "        1.12812116e-03, 2.61024106e-03, 2.22347604e-04, 9.50368529e-04,\n",
      "        3.54083400e-04, 1.49788219e-04, 3.54353135e-04, 1.48166291e-04,\n",
      "        2.32775975e-03, 3.23915249e-03, 4.97852197e-05, 6.60468475e-04,\n",
      "        9.12376621e-04, 4.92999912e-04, 9.59826939e-05, 3.81385302e-03,\n",
      "        5.65027061e-04, 2.83833523e-03, 5.35162457e-04, 7.67206482e-04,\n",
      "        2.63751508e-03, 1.30314834e-03, 9.78668337e-04, 1.34318470e-04,\n",
      "        1.53124885e-04, 6.35448552e-04, 1.69405632e-03, 6.59844882e-05,\n",
      "        4.23548627e-04, 1.16825082e-04, 5.49376069e-04, 2.00056424e-03,\n",
      "        2.10793782e-03, 6.69140194e-04, 4.76519694e-04, 5.65183233e-04,\n",
      "        1.26255996e-04, 1.83273735e-03, 1.70422441e-04, 3.94964707e-04,\n",
      "        1.07263576e-03, 3.79739772e-03, 1.22680170e-02, 3.66417255e-04,\n",
      "        3.09277530e-04, 7.29358173e-04, 1.15885760e-03, 1.02188182e-03,\n",
      "        3.95165698e-05, 4.99654911e-04, 1.72057218e-04, 5.33817511e-04,\n",
      "        2.72410805e-03, 5.23256487e-04, 2.40244102e-04, 2.17997731e-04,\n",
      "        2.36102656e-04, 9.80932033e-04, 7.79987662e-04, 7.28899613e-04,\n",
      "        1.67829986e-03, 3.54640256e-03, 1.50288091e-04, 7.28855783e-04,\n",
      "        1.34925288e-03, 5.03206247e-05, 8.13838036e-04, 3.99543242e-05,\n",
      "        7.24671918e-05, 1.18336277e-04, 9.30331662e-05, 7.51538319e-04,\n",
      "        2.86060211e-04, 1.49097861e-04, 5.23950672e-04, 1.18478565e-04,\n",
      "        1.95862306e-03, 4.15723989e-05, 3.25138622e-04, 1.53477106e-03,\n",
      "        3.72401584e-04, 2.58830347e-04, 2.80497596e-04, 1.84981312e-04,\n",
      "        5.72994875e-04, 6.81632257e-04, 2.03777454e-03, 1.25678285e-04,\n",
      "        1.20048970e-03, 3.62366030e-04, 6.06702932e-04, 1.60683514e-04,\n",
      "        2.41409801e-03, 4.94196778e-03, 1.05619919e-03, 1.34148286e-04,\n",
      "        4.96911001e-04, 1.50771590e-03, 1.06130226e-03, 7.73692445e-04,\n",
      "        6.33676711e-04, 8.76131671e-05, 5.27066004e-05, 1.79684511e-03,\n",
      "        3.53913929e-05, 1.25861567e-04, 2.82842782e-04, 1.30293996e-03,\n",
      "        6.07624897e-05, 8.09998903e-03, 2.63474212e-04, 1.02880804e-04,\n",
      "        6.39466089e-05, 3.57262652e-05, 8.33830200e-05, 1.32464891e-04,\n",
      "        4.51440876e-03, 1.94878899e-04, 1.96943714e-04, 1.63955730e-04,\n",
      "        4.40011354e-04, 1.40849355e-04, 6.49112699e-05, 3.12454562e-04,\n",
      "        2.55325832e-03, 2.12675659e-04, 1.02615457e-04, 1.89724407e-04,\n",
      "        2.20402682e-04, 1.47247585e-04, 7.56056514e-04, 1.63830339e-03,\n",
      "        3.72580462e-03, 8.35509796e-04, 9.37130390e-05, 2.18028712e-04,\n",
      "        1.26224710e-04, 1.52572771e-04, 3.34997341e-04, 4.43063327e-04,\n",
      "        4.55558579e-03, 2.05533626e-03, 1.01859728e-03, 8.18124274e-04,\n",
      "        1.93963700e-03, 2.97951535e-03, 2.01455294e-03, 1.85733999e-03,\n",
      "        8.29357305e-04, 2.97105685e-03, 1.40211720e-03, 2.31865270e-04,\n",
      "        1.47060526e-03, 1.02232781e-03, 6.19635859e-04, 5.49647666e-04,\n",
      "        3.32624582e-03, 5.25990559e-04, 1.97522156e-03, 1.51464145e-03,\n",
      "        8.35510509e-05, 6.01151201e-04, 3.59035854e-04, 2.71594210e-04,\n",
      "        8.92459357e-05, 8.86621128e-05, 1.44724478e-03, 5.70318487e-04,\n",
      "        1.88540987e-04, 5.08851884e-03, 2.63620121e-03, 4.01263678e-04,\n",
      "        9.23040716e-05, 1.22497766e-03, 6.78386132e-05, 2.77262618e-04,\n",
      "        5.29533369e-04, 9.51832219e-04, 2.72556557e-04, 8.18728586e-04,\n",
      "        3.58249556e-04, 3.32849857e-04, 2.59944878e-04, 5.32783801e-04,\n",
      "        1.98207257e-04, 1.78178001e-04, 4.20016324e-04, 1.28040774e-04,\n",
      "        2.88868672e-04, 1.63019009e-04, 1.05915742e-03, 2.64393835e-04,\n",
      "        1.54725873e-04, 1.53189278e-04, 6.80281446e-05, 2.17047127e-04,\n",
      "        8.09955236e-04, 8.88917639e-05, 1.99743241e-04, 2.85116461e-04,\n",
      "        2.52583181e-04, 1.25267848e-04, 4.18541487e-04, 8.56007173e-05,\n",
      "        3.13015742e-04, 1.71264051e-04, 1.54140595e-04, 1.93542131e-04,\n",
      "        1.98759037e-04, 1.29909171e-02, 8.67029303e-05, 9.24885389e-05,\n",
      "        2.22920455e-04, 1.39985955e-03, 5.44299488e-04, 5.56570012e-04,\n",
      "        6.44223765e-04, 5.08246478e-04, 4.06200095e-04, 1.42471120e-03,\n",
      "        1.83100958e-04, 4.38081079e-05, 4.71835723e-04, 1.98238064e-04,\n",
      "        1.85574827e-04, 3.21865012e-03, 2.44044641e-04, 1.23984617e-04,\n",
      "        4.57951624e-04, 2.19172187e-04, 3.52427247e-04, 1.19260876e-04,\n",
      "        1.34647955e-04, 1.75227426e-04, 5.06184333e-05, 2.95301783e-04,\n",
      "        4.50352294e-04, 1.62975237e-04, 3.96613032e-05, 6.11184223e-05,\n",
      "        1.44728518e-04, 2.32782077e-05, 1.29855849e-04, 1.90037317e-04,\n",
      "        1.39904820e-04, 1.23385922e-04, 1.77515933e-04, 2.21665017e-02]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "img = np.random.random((1, 224, 224, 3)).astype('float32')\n",
    "extracted_features = feature_extraction_model(img)\n",
    "print(extracted_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T22:03:30.615260500Z",
     "start_time": "2023-08-13T22:03:30.347761200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: use the functional API more often to build models with non-linear topology, shared layers, and multiple inputs or outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T22:09:00.575339100Z",
     "start_time": "2023-08-13T22:09:00.485840900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# for serialization\n",
    "@keras.saving.register_keras_serializable()\n",
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "\n",
    "new_model = keras.Model.from_config(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T22:10:11.311106100Z",
     "start_time": "2023-08-13T22:10:11.225110500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sequential API, Functional API, and Subclass API are interoperable because they all produce Keras models. You can use them together seamlessly in the same project."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
